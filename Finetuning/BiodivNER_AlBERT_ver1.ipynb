{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"BiodivNER_AlBERT_ver1.ipynb\"\n",
    "batch_size = 4\n",
    "dataset = \"BiodivNER\"\n",
    "data_directory = \"../Datasets/NER/COPIOUS-txt/\"\n",
    "model_src = \"albert-base-v2\"\n",
    "model_name = \"biodivner_albert-base-v2\" # (wandb project name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install seqeval\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshannen\u001b[0m (\u001b[33mshannen-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up experiment and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nlpbiodiv2023/CS198Repository/Finetuning/wandb/run-20240113_135056-9mytu8yk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shannen-team/biodivner_albert-base-v2/runs/9mytu8yk' target=\"_blank\">peach-water-1</a></strong> to <a href='https://wandb.ai/shannen-team/biodivner_albert-base-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shannen-team/biodivner_albert-base-v2' target=\"_blank\">https://wandb.ai/shannen-team/biodivner_albert-base-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shannen-team/biodivner_albert-base-v2/runs/9mytu8yk' target=\"_blank\">https://wandb.ai/shannen-team/biodivner_albert-base-v2/runs/9mytu8yk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shannen-team/biodivner_albert-base-v2/runs/9mytu8yk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f58ea02f670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=model_name,\n",
    "    config={\n",
    "        \"batch_size\": batch_size,\n",
    "        \"dataset\": dataset,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the dataset to CoNLL2003 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_CoNLL2003_format(filename, idx=3):\n",
    "#     \"\"\"Read file in CoNLL-2003 shared task format\"\"\"\n",
    "\n",
    "#     # read file\n",
    "#     lines =  open(filename, encoding=\"utf-8\").read().strip()\n",
    "\n",
    "#     # find sentence-like boundaries\n",
    "#     lines = lines.split(\"\\n\\n\")\n",
    "\n",
    "#      # split on newlines\n",
    "#     lines = [line.split(\"\\n\") for line in lines]\n",
    "\n",
    "#     # get tokens\n",
    "#     tokens = [[l.split()[0] for l in line] for line in lines]\n",
    "\n",
    "#     # get labels/tags\n",
    "#     labels = [[l.split()[idx] for l in line] for line in lines]\n",
    "\n",
    "#     #convert to df\n",
    "#     data= {'tokens': tokens, 'labels': labels}\n",
    "#     df=pd.DataFrame(data=data)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten(l):\n",
    "#     return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATADIR = data_directory\n",
    "\n",
    "# def get_data(trainfile=DATADIR + \"train.txt\",\n",
    "#              devfile=DATADIR + \"dev.txt\",\n",
    "#              testfile=DATADIR + \"test.txt\"):\n",
    "\n",
    "#     train = read_CoNLL2003_format(trainfile, idx=3)\n",
    "#     dev = read_CoNLL2003_format(devfile, idx=3)\n",
    "#     print(\"Train data: %d sentences, %d tokens\"%(len(train),len(flatten(train.tokens))))\n",
    "\n",
    "#     print(\"Dev data: %d sentences, %d tokens\"%(len(dev),len(flatten(dev.tokens))))\n",
    "\n",
    "#     test = read_CoNLL2003_format(testfile, idx=3)\n",
    "#     print(\"Test data: %d sentences, %d tokens\"%(len(test),len(flatten(test.tokens))))\n",
    "\n",
    "#     return train, test, dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, dev = get_data()\n",
    "\n",
    "# train_dataset = Dataset.from_pandas(train)\n",
    "# dev_dataset = Dataset.from_pandas(dev)\n",
    "# test_dataset = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = \"../Datasets/NER/BiodivNER/\"\n",
    "\n",
    "biodivner_dataset = \"train\"\n",
    "train_csv_file_path = \"train.csv\"\n",
    "val_csv_file_path = \"dev.csv\"\n",
    "test_csv_file_path = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(csv_file_path):\n",
    "  dataset_path = os.path.join(root_data_dir, csv_file_path)\n",
    "  data = pd.read_csv(dataset_path, encoding=\"latin1\")\n",
    "  data = data.fillna(method=\"ffill\")\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640852/3117403119.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method=\"ffill\")\n",
      "/tmp/ipykernel_1640852/3117403119.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method=\"ffill\")\n",
      "/tmp/ipykernel_1640852/3117403119.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "data = loadData(train_csv_file_path)\n",
    "val_data = loadData(val_csv_file_path)\n",
    "test_data = loadData(test_csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>Samplenr</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>Seedlingnr</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>Plot</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>Record</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>Date</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>frames</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>landing</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>platforms</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence #        Word Tag\n",
       "0    Sentence: 0    Samplenr   O\n",
       "1    Sentence: 0  Seedlingnr   O\n",
       "2    Sentence: 0        Plot   O\n",
       "3    Sentence: 0      Record   O\n",
       "4    Sentence: 0        Date   O\n",
       "..           ...         ...  ..\n",
       "100  Sentence: 1           ,   O\n",
       "101  Sentence: 1      frames   O\n",
       "102  Sentence: 1           ,   O\n",
       "103  Sentence: 1     landing   O\n",
       "104  Sentence: 1   platforms   O\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert(orig):\n",
    "\n",
    "    df = pd.DataFrame(orig)\n",
    "\n",
    "    # Extract the integer from 'Sentence #'\n",
    "    df['Sentence #'] = df['Sentence #'].apply(lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "    # Add a column representing the original order\n",
    "    df['Original Order'] = range(len(df))\n",
    "\n",
    "    # Group by 'Sentence #' and aggregate 'Word' and 'Tag' into lists\n",
    "    grouped = df.groupby('Sentence #').agg({'Word': list, 'Tag': list, 'Original Order': 'first'}).reset_index()\n",
    "\n",
    "    # Sort the DataFrame based on the original order\n",
    "    grouped = grouped.sort_values(by='Original Order').drop('Original Order', axis=1)\n",
    "\n",
    "    grouped = grouped.rename(columns={'Word': 'tokens'})\n",
    "    grouped = grouped.rename(columns={'Tag': 'labels'})\n",
    "    grouped = grouped.drop('Sentence #', axis=1)\n",
    "    # print(grouped)\n",
    "    return grouped\n",
    "\n",
    "# print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = convert(data)\n",
    "val_df = convert(val_data)\n",
    "test_df = convert(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_df)):\n",
    "    # print(len(train_df['tokens'][i]), len(train_df['labels'][i]))\n",
    "    if len(train_df['tokens'][i]) != len(train_df['labels'][i]):\n",
    "        print(\"lol\")\n",
    "# print(train_df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'labels'],\n",
      "    num_rows: 1918\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-Phenomena': 0, 'I-Phenomena': 1, 'B-Quality': 2, 'I-Quality': 3, 'B-Location': 4, 'I-Location': 5, 'B-Environment': 6, 'I-Environment': 7, 'B-Matter': 8, 'I-Matter': 9, 'B-Organism': 10, 'I-Organism': 11, 'O': 12}\n",
      "{0: 'B-Phenomena', 1: 'I-Phenomena', 2: 'B-Quality', 3: 'I-Quality', 4: 'B-Location', 5: 'I-Location', 6: 'B-Environment', 7: 'I-Environment', 8: 'B-Matter', 9: 'I-Matter', 10: 'B-Organism', 11: 'I-Organism', 12: 'O'}\n"
     ]
    }
   ],
   "source": [
    "label_list = ['B-Phenomena', 'I-Phenomena', 'B-Quality', 'I-Quality', 'B-Location', 'I-Location', 'B-Environment', 'I-Environment', 'B-Matter', 'I-Matter', 'B-Organism', 'I-Organism', 'O']\n",
    "label2id = {k: v for v, k in enumerate(label_list)}\n",
    "id2label = {v: k for v, k in enumerate(label_list)}\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 684/684 [00:00<00:00, 1.09MB/s]\n",
      "spiece.model: 100%|██████████| 760k/760k [00:00<00:00, 1.61MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.31M/1.31M [00:01<00:00, 1.29MB/s]\n"
     ]
    }
   ],
   "source": [
    "task = \"ner\"\n",
    "model_checkpoint = model_src\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1918/1918 [00:01<00:00, 1769.25 examples/s]\n",
      "Map: 100%|██████████| 240/240 [00:00<00:00, 1560.81 examples/s]\n",
      "Map: 100%|██████████| 240/240 [00:00<00:00, 1071.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    label_all_tokens = True\n",
    "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]), max_length= 512, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif label[word_idx] == '0':\n",
    "                label_ids.append(0)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label2id[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(label2id[label[word_idx]] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "train_tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "dev_tokenized_datasets = dev_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_tokenized_datasets = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 1918\n",
      "})\n",
      "97\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "print(train_tokenized_datasets)\n",
    "print(len(train_tokenized_datasets['tokens'][0]))\n",
    "print(len(train_tokenized_datasets['labels'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 47.4M/47.4M [00:03<00:00, 13.1MB/s]\n",
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_1640852/547268042.py:16: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "model =  AutoModelForTokenClassification.from_pretrained(model_checkpoint,id2label=id2label, label2id=label2id)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"test-{task}\",\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \"f1\": results[\"overall_f1\"], \"accuracy\": results[\"overall_accuracy\"]}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_tokenized_datasets,\n",
    "    eval_dataset=dev_tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear model directory if it hasn't been cleared yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './ner.model' removed successfully.\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"./ner.model\"\n",
    "\n",
    "if os.path.exists(directory_path):\n",
    "    try:\n",
    "        # Remove the directory\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Directory '{directory_path}' removed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing directory '{directory_path}': {e}\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 02:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.192160</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.347048</td>\n",
       "      <td>0.430872</td>\n",
       "      <td>0.938545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.171880</td>\n",
       "      <td>0.563367</td>\n",
       "      <td>0.544723</td>\n",
       "      <td>0.553888</td>\n",
       "      <td>0.945318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.130588</td>\n",
       "      <td>0.675918</td>\n",
       "      <td>0.675313</td>\n",
       "      <td>0.675615</td>\n",
       "      <td>0.956316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "trainer.save_model('ner.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an inference with the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change model_checkpoint as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"./ner.model\"\n",
    "\n",
    "# artifact = wandb.use_artifact(\"electra-small-discriminator:latest\")\n",
    "# model_checkpoint = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classifier = pipeline(\"token-classification\", model=model_checkpoint, aggregation_strategy=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:393: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'Matter',\n",
       "  'score': 0.95551485,\n",
       "  'word': 'carbon',\n",
       "  'start': 46,\n",
       "  'end': 52},\n",
       " {'entity_group': 'Environment',\n",
       "  'score': 0.7179568,\n",
       "  'word': 'coastalecosystems',\n",
       "  'start': 159,\n",
       "  'end': 177},\n",
       " {'entity_group': 'Matter',\n",
       "  'score': 0.90908253,\n",
       "  'word': 'salt',\n",
       "  'start': 205,\n",
       "  'end': 209}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier(\"The cbbL form IA and IC genes associated with carbon fixation were analyzed to gain insight into metabolic potential of chemolithoautotrophs in three types of coastal ecosystems which had a very different salt load and .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get precision, f1-score, and recall for each entity group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Environment': {'precision': 0.6417910447761194,\n",
       "  'recall': 0.6861702127659575,\n",
       "  'f1': 0.6632390745501285,\n",
       "  'number': 188},\n",
       " 'Location': {'precision': 0.44871794871794873,\n",
       "  'recall': 0.49295774647887325,\n",
       "  'f1': 0.46979865771812085,\n",
       "  'number': 71},\n",
       " 'Matter': {'precision': 0.6950354609929078,\n",
       "  'recall': 0.49246231155778897,\n",
       "  'f1': 0.5764705882352941,\n",
       "  'number': 199},\n",
       " 'Organism': {'precision': 0.7565392354124748,\n",
       "  'recall': 0.7673469387755102,\n",
       "  'f1': 0.7619047619047619,\n",
       "  'number': 490},\n",
       " 'Phenomena': {'precision': 0.8214285714285714,\n",
       "  'recall': 0.6133333333333333,\n",
       "  'f1': 0.7022900763358778,\n",
       "  'number': 75},\n",
       " 'Quality': {'precision': 0.7849462365591398,\n",
       "  'recall': 0.7572614107883817,\n",
       "  'f1': 0.7708553326293558,\n",
       "  'number': 482},\n",
       " 'overall_precision': 0.7294853963838664,\n",
       " 'overall_recall': 0.6970099667774087,\n",
       " 'overall_f1': 0.7128780156303093,\n",
       " 'overall_accuracy': 0.9433206106870229}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_tokenized_datasets)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./ner.model)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done. 0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact biodivner_albert-base-v2>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact = wandb.Artifact(name=model_name, type=\"model\")\n",
    "artifact.add_dir(local_path=\"./ner.model\")  # Add dataset directory to artifact\n",
    "wandb.log(results, commit=True)\n",
    "wandb.log_artifact(artifact)  # Logs the artifact version \"my_data:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄██</td></tr><tr><td>eval/f1</td><td>▁▅██</td></tr><tr><td>eval/loss</td><td>█▆▁▁</td></tr><tr><td>eval/precision</td><td>▁▁██</td></tr><tr><td>eval/recall</td><td>▁▅██</td></tr><tr><td>eval/runtime</td><td>▁▆█▅</td></tr><tr><td>eval/samples_per_second</td><td>█▃▁▃</td></tr><tr><td>eval/steps_per_second</td><td>█▃▁▃</td></tr><tr><td>overall_accuracy</td><td>▁</td></tr><tr><td>overall_f1</td><td>▁</td></tr><tr><td>overall_precision</td><td>▁</td></tr><tr><td>overall_recall</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/learning_rate</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███▇▆▆▅▅▄▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▄▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.95632</td></tr><tr><td>eval/f1</td><td>0.67562</td></tr><tr><td>eval/loss</td><td>0.13059</td></tr><tr><td>eval/precision</td><td>0.67592</td></tr><tr><td>eval/recall</td><td>0.67531</td></tr><tr><td>eval/runtime</td><td>3.0429</td></tr><tr><td>eval/samples_per_second</td><td>78.872</td></tr><tr><td>eval/steps_per_second</td><td>0.657</td></tr><tr><td>overall_accuracy</td><td>0.94332</td></tr><tr><td>overall_f1</td><td>0.71288</td></tr><tr><td>overall_precision</td><td>0.72949</td></tr><tr><td>overall_recall</td><td>0.69701</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>720</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1264</td></tr><tr><td>train/total_flos</td><td>47390519422260.0</td></tr><tr><td>train/train_loss</td><td>0.36578</td></tr><tr><td>train/train_runtime</td><td>152.1726</td></tr><tr><td>train/train_samples_per_second</td><td>37.812</td></tr><tr><td>train/train_steps_per_second</td><td>4.731</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-water-1</strong> at: <a href='https://wandb.ai/shannen-team/biodivner_albert-base-v2/runs/9mytu8yk' target=\"_blank\">https://wandb.ai/shannen-team/biodivner_albert-base-v2/runs/9mytu8yk</a><br/> View job at <a href='https://wandb.ai/shannen-team/biodivner_albert-base-v2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTgyOTI1Nw==/version_details/v0' target=\"_blank\">https://wandb.ai/shannen-team/biodivner_albert-base-v2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTgyOTI1Nw==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240113_135056-9mytu8yk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
