{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"t5-small\"\n",
        "model_path = \"../Model Data/t5-small/t5-small_001/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Vslp-YSsLj"
      },
      "source": [
        "# Libraries installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4X12ofdmpgv"
      },
      "source": [
        "Install Transformers libaries, framework seqeval, some extensions: unidecode for formatting accent language, datasets for creating a Dataset,..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TEFje_FCy_hh"
      },
      "outputs": [],
      "source": [
        "# #Install required libraries\n",
        "# !pip install datasets transformers evaluate seqeval unidecode google.colab\n",
        "# !pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJnMSNd7Zsjg"
      },
      "source": [
        "## WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sKgmGqjWsDD",
        "outputId": "6bcfc052-ae70-4092-d72d-d80c0a14333f"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb\n",
        "# !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUvcGfo9ZGZU",
        "outputId": "3efa92b4-6232-4225-933f-899830fb56ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-11 20:23:33--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 OK\n",
            "Length: 28335 (28K) [text/plain]\n",
            "Saving to: ‘run_glue.py.2’\n",
            "\n",
            "run_glue.py.2       100%[===================>]  27.67K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-12-11 20:23:34 (2.24 MB/s) - ‘run_glue.py.2’ saved [28335/28335]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VK3L9ZKZJuK",
        "outputId": "62a2c2e4-9b67-4429-e0c6-5fd8289bc7dd"
      },
      "outputs": [],
      "source": [
        "# !pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xr1TdcUHZOQT"
      },
      "outputs": [],
      "source": [
        "# import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxYN1xRnZXwY",
        "outputId": "dd67e053-8a22-492e-c282-db913bdacd90"
      },
      "outputs": [],
      "source": [
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8ickZFYZgPJ",
        "outputId": "9ffa9e35-04e3-4d1e-927c-dc2f7e4d45b8"
      },
      "outputs": [],
      "source": [
        "# %env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyIQ855Mm6hO"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nYQ2MGLYW6-X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#Import libraries to project\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "import os\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7TIOIRBnCJj"
      },
      "source": [
        "Mount Google Drive to Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we3vliI84wF9",
        "outputId": "17840ab4-b983-4b53-ff39-4f9c0a184e3c"
      },
      "outputs": [],
      "source": [
        "# #Mount Drive to Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jWsOi2IS56c"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A34esVOtGjO"
      },
      "source": [
        "Read training set from dataset stored in Google Drive.\n",
        "Create a list of input and output sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aPW44SkrzZTe"
      },
      "outputs": [],
      "source": [
        "#Read datasets\n",
        "\n",
        "root_data_dir = \"../Datasets/NER/BiodivNER\"\n",
        "\n",
        "dataset = \"train\"\n",
        "train_csv_file_path = \"train.csv\"\n",
        "val_csv_file_path = \"dev.csv\"\n",
        "test_csv_file_path = \"test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UEKJDG3_qlIY"
      },
      "outputs": [],
      "source": [
        "def loadData(csv_file_path):\n",
        "  dataset_path = os.path.join(root_data_dir, csv_file_path)\n",
        "  data = pd.read_csv(dataset_path, encoding=\"utf-8\")\n",
        "  data = data.fillna(method=\"ffill\")\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aKclhjBhqprC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_393286/1497070395.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = data.fillna(method=\"ffill\")\n",
            "/tmp/ipykernel_393286/1497070395.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = data.fillna(method=\"ffill\")\n",
            "/tmp/ipykernel_393286/1497070395.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = data.fillna(method=\"ffill\")\n"
          ]
        }
      ],
      "source": [
        "data = loadData(train_csv_file_path)\n",
        "val_data = loadData(val_csv_file_path)\n",
        "test_data = loadData(test_csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U8FCpm3Kqoxm"
      },
      "outputs": [],
      "source": [
        "class SentenceGetter(object):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                        s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbdAPQtzsLJp",
        "outputId": "6ceed375-be32-44e0-bd19-03cf38e46087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('bottom', 'O'), ('board', 'O'), ('debris', 'O'), (',', 'O'), ('frames', 'O'), (',', 'O'), ('landing', 'O'), ('platforms', 'O'), (')', 'O'), (',', 'O'), ('and', 'O'), ('isolates', 'O'), ('of', 'O'), ('microbes', 'O'), (',', 'O'), ('parasites', 'O'), ('and', 'O'), ('pathogens', 'O'), ('from', 'O'), ('honey', 'B-Organism'), ('bees', 'I-Organism'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxEW9UXosLxX",
        "outputId": "9540bba9-343d-4489-9aaa-6395f74e1803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('However', 'O'), (',', 'O'), ('the', 'O'), ('lack', 'O'), ('of', 'O'), ('correlation', 'O'), ('between', 'O'), ('dung', 'O'), ('beetle', 'O'), ('community', 'B-Environment'), ('characteristics', 'O'), ('and', 'O'), ('dung', 'O'), ('removal', 'O'), ('highlights', 'O'), ('the', 'O'), ('need', 'O'), ('for', 'O'), ('further', 'O'), ('research', 'O'), ('into', 'O'), ('spatial', 'O'), ('variation', 'O'), ('in', 'O'), ('biodiversityÃ¢â\\x82¬â\\x80\\x9cecosystem', 'O'), ('function', 'O'), ('relationships', 'O'), ('and', 'O'), ('how', 'O'), ('the', 'O'), ('results', 'O'), ('of', 'O'), ('such', 'O'), ('studies', 'O'), ('are', 'O'), ('affected', 'O'), ('by', 'O'), ('methodological', 'O'), ('choices', 'O'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter_val = SentenceGetter(val_data)\n",
        "sentences_val = getter_val.sentences\n",
        "sent_val = getter_val.get_next()\n",
        "print(sent_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMgWbWdusNmT",
        "outputId": "67729016-9793-4e40-db80-f71be1113bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('The', 'O'), ('primacy', 'O'), ('of', 'O'), ('either', 'O'), ('species', 'B-Quality'), ('or', 'O'), ('functional', 'O'), ('group', 'O'), ('richness', 'B-Quality'), ('effects', 'O'), ('depended', 'O'), ('on', 'O'), ('the', 'O'), ('sequence', 'O'), ('of', 'O'), ('testing', 'O'), ('these', 'O'), ('terms', 'O'), (',', 'O'), ('indicating', 'O'), ('that', 'O'), ('both', 'O'), ('aspects', 'O'), ('of', 'O'), ('richness', 'B-Quality'), ('were', 'O'), ('congruent', 'O'), ('and', 'O'), ('complementary', 'O'), ('to', 'O'), ('expected', 'O'), ('strong', 'O'), ('effects', 'O'), ('of', 'O'), ('legume', 'O'), ('presence', 'O'), ('and', 'O'), ('grass', 'B-Organism'), ('presence', 'O'), ('on', 'O'), ('plant', 'B-Organism'), ('chemical', 'B-Quality'), ('composition', 'I-Quality'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter_test = SentenceGetter(test_data)\n",
        "sentences_test = getter_test.sentences\n",
        "sent_test = getter_test.get_next()\n",
        "print(sent_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z437Qz_ksYiu"
      },
      "outputs": [],
      "source": [
        "def get_text_tags_lists(sentences):\n",
        "  texts = []\n",
        "  tags = []\n",
        "  for sent in sentences: #list of tuples\n",
        "    sent_texts = []\n",
        "    sent_tags = []\n",
        "    for tuple1 in sent:\n",
        "      sent_texts.append(tuple1[0])\n",
        "      sent_tags.append(tuple1[1])\n",
        "\n",
        "    texts.append(sent_texts)\n",
        "    tags.append(sent_tags)\n",
        "  return texts, tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fNuvDHsZsZND"
      },
      "outputs": [],
      "source": [
        "train_texts, train_tags = get_text_tags_lists(sentences)\n",
        "val_texts, val_tags = get_text_tags_lists(sentences_val)\n",
        "test_texts, test_tags = get_text_tags_lists(sentences_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dRsnSPfKIADP"
      },
      "outputs": [],
      "source": [
        "#Create a list of texts\n",
        "def create_input_seq(texts):\n",
        "  inputs = texts\n",
        "  input_sequences = []\n",
        "\n",
        "  for sentence in inputs:\n",
        "    input_sequences.append(' '.join(sentence))\n",
        "\n",
        "  return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q2-7zvDOv_90"
      },
      "outputs": [],
      "source": [
        "train_inputs_raw = create_input_seq(train_texts)\n",
        "val_inputs_raw = create_input_seq(val_texts)\n",
        "test_inputs_raw = create_input_seq(test_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmZmuZcCtUNf"
      },
      "source": [
        "Convert problem into text-to-text format by formatting an output which is a sequence of class:entity pairs separated by a semicolon ';'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TYTj6WzxcCIK"
      },
      "outputs": [],
      "source": [
        "def format_targets(text, label):\n",
        "  s = \"\"\n",
        "  texts = []\n",
        "  for i in range(len(text)-1):\n",
        "    if label[i] != 'O':\n",
        "      s += text[i] + \" \"\n",
        "      if label[i+1] == 'O' or label[i+1][0:1] == 'B':\n",
        "        s = label[i][2:] + \": \" + s\n",
        "        texts.append(s.strip())\n",
        "        s = \"\"\n",
        "  texts = \"; \".join(texts)\n",
        "  return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "UGzd5z73Igxn",
        "outputId": "143db8b7-9e61-4d27-b0e8-c33694b9642c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Quality: Density; Phenomena: Treatment; Quality: Dead; Environment: Garden; Organism: Seedling; Phenomena: growth; Quality: biomass; Environment: plant communities; Quality: species richness; Environment: tropical forest ecosystems'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str1 = format_targets(train_texts[0], train_tags[0])\n",
        "str1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llZv3PEKtm_N"
      },
      "source": [
        " Convert them back to sentence format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GNwHXjj2udeJ"
      },
      "outputs": [],
      "source": [
        "def create_output_seq(texts, tags):\n",
        "  output_sequences = []\n",
        "\n",
        "  for i in range(len(texts)):\n",
        "    text = texts[i]\n",
        "    label = tags[i]\n",
        "\n",
        "    target = format_targets(text, label)\n",
        "    output_sequences.append(target)\n",
        "\n",
        "  return output_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u9rBXsn0urFM"
      },
      "outputs": [],
      "source": [
        "train_outputs_raw = create_output_seq(train_texts, train_tags)\n",
        "val_outputs_raw = create_output_seq(val_texts, val_tags)\n",
        "test_outputs_raw = create_output_seq(test_texts, test_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def has_non_ascii(sentence):\n",
        "    return any(ord(char) > 127 for char in sentence)\n",
        "\n",
        "def clean_non_ascii(inputs, labels):\n",
        "    clean_inputs = []\n",
        "    clean_labels = []\n",
        "\n",
        "    for sentence, label in zip(inputs, labels):\n",
        "        if has_non_ascii(sentence):\n",
        "            continue\n",
        "        \n",
        "        clean_inputs.append(sentence)\n",
        "        clean_labels.append(label)\n",
        "\n",
        "    return clean_inputs, clean_labels\n",
        "\n",
        "def clean_non_ascii_test(texts, tags):\n",
        "    clean_inputs = []\n",
        "    clean_labels = []\n",
        "\n",
        "    for sentence, label in zip(texts, tags):\n",
        "        sentence2 = ' '.join(sentence)\n",
        "        if has_non_ascii(sentence2):\n",
        "            continue\n",
        "        \n",
        "        clean_inputs.append(sentence)\n",
        "        clean_labels.append(label)\n",
        "\n",
        "    return clean_inputs, clean_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_inputs, train_outputs = clean_non_ascii(train_inputs_raw, train_outputs_raw)\n",
        "val_inputs, val_outputs = clean_non_ascii(val_inputs_raw, val_outputs_raw)\n",
        "test_texts_c, test_tags_c = clean_non_ascii_test(test_texts, test_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Combining', 'metabolic', 'and', 'food-', 'web', 'theory', ',', 'we', 'calculate', 'annual', 'energy', 'fluxes', 'to', 'model', 'impacts', 'of', 'land-use', 'intensification', 'on', 'multitrophic', 'ecosystem', 'functioning', '.'], ['The', 'primacy', 'of', 'either', 'species', 'or', 'functional', 'group', 'richness', 'effects', 'depended', 'on', 'the', 'sequence', 'of', 'testing', 'these', 'terms', ',', 'indicating', 'that', 'both', 'aspects', 'of', 'richness', 'were', 'congruent', 'and', 'complementary', 'to', 'expected', 'strong', 'effects', 'of', 'legume', 'presence', 'and', 'grass', 'presence', 'on', 'plant', 'chemical', 'composition', '.'], ['Full', 'ant', 'species', 'name', '.'], ['If', 'it', 'would', 'not', 'be', 'considered', 'greater', 'than', '10', ',', 'it', 'would', 'not', 'be', 'considered', 'in', 'the', 'outer', 'subplots.Helper', ';', 'Datagroup', 'description', ':', 'Helper', ')', 'dimensionless', 'real', 'Helper', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Probability', 'that', 'a', 'stem', 'would', 'be', 'considerd', 'greater', 'or', 'equal', 'than', '10', 'given', 'it', 's', 'basal', 'diameter', '.'], ['117.8998', '118.1483', '29.2852', '29.10178', '########', '########', 'Fungal', 'communities', 'based', 'on', 'fungal', 'IST', 'rDNA', 'pyrosequencing', '.'], ['4', '79106', 'Freiburg', 'im', 'Breisgau', 'Germany', '49', '(', '0', ')', '761', '203', '-', '67787', 'Alexandra-Maria', 'Klein', 'Institute', 'of', 'Ecology', 'and', 'Environmental', 'Chemistry', ',', 'Section', 'Ecosystem', 'Functions', ',', 'Leuphana', 'University', 'of', 'Lueneburg', 'Scharnhorststr', '.'], ['There', 'are', 'three', 'main', 'sites', 'for', 'research', 'plots', 'in', 'the', 'BEF', 'Experiment', ':', 'Comparative', 'Study', 'Plots', '(', 'CSP', ')', 'in', 'the', 'Gutianshan', 'Nature', 'Reserve', ',', 'having', 'a', 'size', 'of', '30x30m^2', ',', 'measured', 'on', 'the', 'ground', '.'], ['Number', 'of', 'individuals', 'Organism', 'count', '(', 'Hemiptera_sum', ')', ',', 'Hemiptera_sum', 'Counting', 'the', 'individuals', 'of', 'a', 'given', 'taxon', ',', 'also', 'called', 'abundance', '.'], ['Or', 'the', 'allometries', 'are', 'not', 'used', 'to', 'extrapolate', 'the', 'biomass', 'of', 'the', 'first', 'item', '(', 'for', 'example', 'a', 'tree', 'dbh', ')', '.', ')'], ['The', 'vector', 'data', 'file', 'is', 'included', 'in', '``', 'Habitat_OffshorePigeonPoint.zip', ',', ',', 'which', 'is', 'accessible', 'from', 'Using', 'multibeam', 'echosounder', '(', 'MBES', ')', 'bathymetry', 'and', 'backscatter', 'data', ',', 'potential', 'marine', 'benthic', 'habitat', 'maps', 'were', 'constructed', '.'], ['MMMTAV', ',', 'the', 'toxicokinetic', 'properties', 'of', 'which', 'are', 'not', 'well', 'known', ',', 'was', 'in', 'many', 'cases', 'a', 'major', 'metabolite', '.'], ['The', 'vaginal', 'microbiota', 'of', 'the', 'guinea', 'pig', 'differs', 'from', 'that', 'of', 'humans', 'and', 'can', 'not', 'prevent', 'chlamydial', 'infections', 'efficiently', '.'], ['These', 'covariations', 'were', 'inconsistent', 'at', 'the', 'within-species', 'level', '.'], ['Higher', 'arthropod', 'taxa', '(', 'Genus', ')', ',', 'Genus', 'Higher', 'arthropod', 'taxa', '(', 'Genus', ':', 'Genus', 'of', 'the', 'species', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP19', ')', ',', 'CSP19', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['We', 'used', 'R', 'to', 'carry', 'out', 'different', 'multivariate', 'tests', '.'], ['on', 'the', 'ground', 'area', 'of', 'circular', 'plot', 'of', 'neighbour', 'evaluation', ',', 'used', 'as', 'area', 'basis', 'for', 'determination', 'of', 'neighbour', 'indices', 'Density', 'measure', '(', 'neigh_a', ')', ',', 'neigh_a', 'Measure', 'of', 'density', ',', 'i.e', '.'], ['Leaf', 'traits', 'and', 'chemicals', 'from', 'tree', 'species', 'in', 'the', 'Main', 'Experimental', 'sites', ',', 'including', 'secondary', 'compound', '(', 'total', 'phenolic', 'and', 'tannin', 'concentrations', ')', 'and', 'information', 'on', 'stomata', '.'], ['Most', 'species', 'had', 'a', 'significant', 'range', 'contraction', '(', 'up', 'to', '72', '%', ')', 'and', '12', '%', 'of', 'species', 'were', 'projected', 'to', 'be', 'regionally', 'extinct', '.'], ['Unexpectedly', ',', 'resource', 'acquisition', '(', 'growth', ',', 'recruitment', ')', 'and', 'conservation', '(', 'mortality', ',', 'turnover', ')', 'played', 'an', 'equally', 'important', 'role', 'throughout', 'the', 'succession', '.'], ['A', 'global', 'model', 'of', 'the', 'response', 'of', 'tropical', 'and', 'sub-tropical', 'forest', 'biodiversity', 'to', 'anthropogenic', 'pressures', 'Habitat', 'loss', 'and', 'degradation', ',', 'driven', 'largely', 'by', 'agricultural', 'expansion', 'and', 'intensification', ',', 'present', 'the', 'greatest', 'immediate', 'threat', 'to', 'biodiversity', '.'], ['We', 'show', 'that', 'in', 'contrast', 'to', 'what', 'was', 'expected', 'from', 'the', 'sharp', 'decrease', 'in', 'organic', 'carbon', 'fluxes', 'and', 'reduced', 'faunal', 'abundance', ',', 'the', 'deep-sea', 'biodiversity', 'of', 'both', 'the', 'eastern', 'and', 'the', 'western', 'basins', 'of', 'the', 'Mediterranean', 'Sea', 'is', 'similarly', 'high', '.'], ['Ways', 'to', 'quantify', 'precipitation', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mmmeasured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ';', 'rainfall', 'amount', 'open', 'field', '(', 'vaisala', ')', 'mmmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'peak', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'of', 'the', 'five', 'highest', 'five', 'minute', 'intensities', 'open', 'field', '(', 'vaisala', ')', 'measured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mmmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'peak', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '(', 'int_t', ':', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/h', '--', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', '--', 'measured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', ')', 'dimensionless', 'real', 'Precipitation', 'Precipitation', 'measured', 'at', 'the', 'climate', 'station', 'or', 'locally', 'within', 'sites', '.'], ['HoloBee-Mop', 'is', 'a', 'database', 'comprised', 'mostly', 'of', 'chro', 'mosomal', ',', 'mitochondrial', 'and', 'plasmid', 'genome', 'assemblies', 'in', 'order', 'to', 'aggregate', 'as', 'much', 'honey', 'bee', 'holobiont', 'genomic', 'sequence', 'information', 'as', 'possible', '.'], ['woody', 'debris', ')', 'is', 'measured', 'as', 'an', 'indication', 'of', 'its', 'position', '(', 'direction', 'CWD', ':', 'Direction', 'to', 'woody', 'debris', 'item', ':', 'The', 'direction', 'a', 'woody', 'debris', 'is', 'aligned', 'from', 'the', 'thick', 'to', 'the', 'thin', 'part', 'of', 'the', 'debris', 'object', ')', 'dimensionless', 'real', 'Angle', 'the', 'angle', 'from', 'the', 'base', 'along', 'an', 'object', 'to', 'its', 'top', '(', 'e.g', '.'], ['An', 'Assessment', 'of', 'the', 'Amount', 'and', 'Extent', 'of', 'Plant', 'Collection', 'Records', 'and', 'Census', 'Data', 'Available', 'for', 'Tropical', 'South', 'America', 'Large-scale', 'studies', 'are', 'needed', 'to', 'increase', 'our', 'understanding', 'of', 'how', 'large-scale', 'conservation', 'threats', ',', 'such', 'as', 'climate', 'change', 'and', 'deforestation', ',', 'are', 'impacting', 'diverse', 'tropical', 'ecosystems', '.'], ['This', 'shift', 'offers', 'opportunities', 'for', 'a', 'deeper', 'mechanistic', 'understanding', 'of', 'the', 'role', 'of', 'biodiversity', 'in', 'maintaining', 'multiple', 'ecosystem', 'processes', 'and', 'services', '.'], ['The', 'spatial', 'identification', 'of', 'hot', 'spots', 'highlighted', 'the', 'ecological', 'importance', 'of', 'most', 'of', 'the', 'western', 'Mediterranean', 'shelves', '(', 'and', 'in', 'particular', ',', 'the', 'Strait', 'of', 'Gibraltar', 'and', 'the', 'adjacent', 'Alboran', 'Sea', ')', ',', 'western', 'African', 'coast', ',', 'the', 'Adriatic', ',', 'and', 'the', 'Aegean', 'Sea', ',', 'which', 'show', 'high', 'concentrations', 'of', 'endangered', ',', 'threatened', ',', 'or', 'vulnerable', 'species', '.'], ['In', 'order', 'to', 'test', 'for', 'effects', 'of', 'density-dependence', ',', 'each', 'subplot', ',', 'was', 'then', 'subdivided', 'in', 'split-plots', 'where', 'tree', 'seedlings', 'were', 'planted', 'in', 'conspecific', 'communities', 'at', 'different', 'density', 'levels', 'of', '4', ',', '9', 'and', '25', 'individuals', 'each', '.'], ['Here', ',', 'we', 'report', 'unprecedented', 'rates', 'of', 'local', 'extinctions', 'of', 'medium', 'to', 'large-bodied', 'mammals', 'in', 'one', 'of', 'the', 'world', 's', 'most', 'important', 'tropical', 'biodiversity', 'hotspots', '.'], ['CSPs', ':', 'Ants', '(', 'Formicidae', ')', 'of', 'pitfall', 'traps', 'in', 'the', 'CSPs', '2009', 'Alexandra-Maria', 'Klein', 'Institute', 'of', 'Ecology', 'and', 'Environmental', 'Chemistry', ',', 'Section', 'Ecosystem', 'Functions', ',', 'Leuphana', 'University', 'of', 'Lueneburg', 'Scharnhorststr', '.'], ['The', 'scientific', 'species', 'fullnames', 'are', 'based', 'on', 'the', '``', 'Flora', 'of', 'China', 'China', '.'], ['(', 'rot', ':', 'presence', 'of', 'red', 'mould', ')', 'Organisms', 'found', 'in', 'the', 'specimen', 'under', 'study', '.'], ['Number', 'of', 'individuals', 'Organism', 'count', '(', 'Tetramorium.wroughtonii', ')', ',', 'Tetramorium.wroughtonii', 'Counting', 'the', 'individuals', 'of', 'a', 'given', 'taxon', ',', 'also', 'called', 'abundance', '.'], ['Primary', 'production', 'and', 'export', 'flux', 'over', 'the', 'MAR', 'were', 'not', 'enhanced', 'compared', 'with', 'a', 'nearby', 'reference', 'station', 'over', 'the', 'Porcupine', 'Abyssal', 'Plain', '.'], ['nz-waikato_0808cb5e-1fc2-4be7-b92e-2e8a7e548fdb', 'Environmental', 'indicators', '-', 'Land', 'and', 'soil', '(', 'Waikato', ')', 'Environmental', 'indicators', '-', 'Land', 'and', 'soil', '(', 'Waikato', ')', 'The', 'indicators', 'for', 'the', 'quality', 'of', 'the', 'Waikato', 'region', 's', 'land', ',', 'soil', 'and', 'native', 'vegetation', 'and', 'how', 'it', 'changes', '.'], ['117.8998', '118.1483', '29.2852', '29.10178', '1/7/2008', '########', 'no', 'organisms', ',', 'only', 'vegetated', 'and', 'bare', 'plots', 'no', 'organisms', ',', 'only', 'vegetated', 'and', 'bare', 'plots', 'tscholten', 'pkuehn', 'cgeissler', 'CSPs', ':', 'Kinetic', 'energy', 'of', 'raindrops', 'in', 'the', 'CSPs', ':', 'characteristics', 'of', 'rain', 'events', 'Rain', 'was', 'captured', 'in', 'open', 'field', 'and', 'in', 'vegetated', 'conditions', 'parallel', 'to', 'measurements', 'in', 'the', 'Comparative', 'study', 'plots', '(', 'CSPs', ')', '.'], ['Our', 'meta-analysis', 'shows', 'a', 'significant', 'decline', 'of', 'the', 'diversity', 'and', 'density', 'of', 'soil', 'invertebrates', 'in', 'response', 'to', 'earthworm', 'invasion', 'with', 'anecic', 'and', 'endogeic', 'earthworms', 'causing', 'the', 'strongest', 'effects', '.'], ['Most', 'participants', 'wanted', '1', ')', 'a', 'monitoring', 'design', 'covering', 'the', 'entire', 'territory', 'and', 'focusing', 'on', 'natural', 'habitats', ';', '2', ')', 'a', 'focus', 'on', 'species', 'related', 'to', 'ecosystem', 'services', ',', 'on', 'threatened', 'and', 'on', 'invasive', 'species', '.'], ['--', 'd', ')', 'Compare', 'species-specific', 'sensitivities', 'to', 'snow', 'break', 'as', 'a', 'trait', 'i', ')', 'Calculate', 'the', 'likelihood', 'of', 'being', 'subject', 'to', 'snowbreak', 'given', 'the', 'species', ',', 'size', 'and', 'potentially', 'the', 'relative', 'position', 'using', 'logistic', 'regression', 'ii', ')', 'Calculate', 'the', 'likelihood', 'of', 'snag', 'survival', ';', 'this', 'requires', 're-sampling', 'iii', ')', 'Estimate', 'the', 'down-slope', 'transport', 'of', 'deadwood', 'pieces', 'iv', ')', 'Estimate', 'the', 'time', 'it', 'takes', 'for', 'deadwood', 'to', 'collapse', 'and', 'touch', 'the', 'forest', 'floor', '--', '--', '-', 'File', 'asset', 'Plot_skizze.pdf', ':', 'plot', 'sketch', 'how', 'the', 'debris', 'objects', 'are', 'selected', '-', 'File', 'asset', 'sp10', 'CWD_protocol_Gutianshan_AF_20081215_kn.doc', ':', 'Inventory', 'protocol', ',', 'should', 'be', 'included', 'into', 'methods', '--', '--', '-', '2', ')', 'Objective', 'allometries', ':', 'use', 'some', 'of', 'the', 'downed', 'or', 'alive', 'trees', 'to', 'establish', 'coarse', 'allometries', 'to', 'estimate', 'volume', 'of', 'the', 'remaining', 'intems', 'allometries', 'basal', 'diameter', 'coarse', 'woody', 'debris', 'co-variable', 'CSP', 'date', 'dbh', 'dead', 'wood', 'decomposition', 'fungi', 'ice', 'storm', 'location', 'mortality', 'object', 'red', 'mould', 'response', 'variable', 'size', 'snag', 'height', 'soil', 'species', 'stem', 'termites', 'weather', 'woody', 'debris', 'Find', 'the', 'list', 'of', 'keywords', 'here', ':', 'rownr', 'date', 'Date', 'start', 'end', 'plotignore', 'CSP', 'working', 'condition', 'protoc.first', 'protoc.sur', 'meas.first', 'meas.sur', 'entered.first', 'entered.sur', 'entered.date', 'page', 'Central_subplot', 'CWD-Id', 'CWD_CSP_original', 'Idaddon', 'CWD_CSP', 'Species', 'specunpolished', 'TagAFCW', 'TagMBa', 'TagAFCW', 'original', 'TagMBa', 'original', 'DBH', 'dbh.comment', 'dbhpostmean', 'dbhpostsd', 'stemsGrEq10', 'stemsCnSm10', 'height', 'BD', 'lookup', 'tag', 'dbase.remark.kn', 'dtop', 'dtop.remark.kn', 'length', 'len.rem.kn', 'height_length', 'hei.len.rem.kn', 'broken', 'at', 'broken', 'diam', 'neigh.label', 'reference', 'is', 'self', 'neigh.dist', 'neigh.azimut', 'direction', 'CWD', 'pos.cw', 'pos.af_original', 'plot', 'estimate', 'pos.af', 'alive', 'sc', 'mc', 'dc', 'ter', 'rot', 'fungi', 'valid', 'crown_origin', 'remark', 'vol_factor', 'Allometrie', 'comment', 'Karin', 'meandbh', 'meanGr10', 'meanSm10Cn', 'ice_storm_representative', 'List', 'of', 'headers', 'of', 'the', 'data', 'columns', 'in', 'this', 'dataset', 'Permission', 'is', 'granted', 'to', 'anybody', 'to', 'access', ',', 'use', 'and', 'publish', 'all', 'open', 'for', 'public', 'data', 'freely', '.'], ['DESCRIPTION', 'Life', 'expectancy', 'estimates', 'for', 'North', 'American', 'zoo', 'and', 'aquarium', 'vertebrate', 'animals', 'SUMMARY', 'Data', 'behind', 'the', 'article', 'Sex-specific', 'median', 'life', 'expectancies', 'from', 'ex', 'situ', 'populations', 'for', '330', 'animal', 'species', '.'], ['dimensionless', 'real', 'Woody', 'debris', 'dimensions', 'Woody', 'debris', 'dimensions', 'consist', 'of', 'base', 'diameter', ',', 'top', 'diameter', ',', 'and', 'length', '.'], ['In', '16S', 'rRNA', 'clone', 'libraries', ',', 'the', 'agricultural', 'soil', 'was', 'dominated', 'by', 'chemolithoautotrophs', '(', 'Betaproteobacteria', ')', 'whereas', 'photoautotrophic', 'Chloroflexi', 'and', 'sulphide', 'oxidizers', 'dominated', 'saline', 'ecosystems', '.'], ['We', 'hypothesize', 'that', ',', 'after', 'extraction', 'of', 'variation', 'that', 'is', 'explained', 'by', 'location', 'and', 'land-use', 'type', ',', 'soil', 'properties', 'still', 'explain', 'significant', 'proportions', 'of', 'variation', 'in', 'the', 'abundance', 'and', 'diversity', 'of', 'soil', 'biota', '.'], ['Our', 'checklist', 'will', 'set', 'a', 'baseline', 'against', 'which', 'future', 'environmental', 'changes', 'can', 'be', 'tracked', '.'], ['5-Jan', ',', 'Chaoyang', 'District', 'Beijing', 'China', '008610-64807085', '########', 'en_US', 'We', 'integrated', 'multiple', 'components', 'of', 'plant', 'and', 'herbivore', 'diversity', 'to', 'unravel', 'the', 'linkages', 'that', 'drive', 'biodiversity', 'relationships', 'and', 'determine', 'the', 'consequences', 'of', 'biodiversity', 'loss', 'across', 'trophic', 'levels', '.'], ['Commands', ':', 'as.taxo', '(', ')', ',', 'divc', '(', ')', '(', 'shannon', ':', 'shannon', 'index', 'of', 'target', 'groups', ')', 'dimensionless', 'real', 'Taxonomic', 'biodiversity', 'Taxon', 'diversity', 'can', 'be', 'given', 'as', 'species', 'richness', ',', 'or', 'other', 'diversity', 'indices', '.'], ['Chlamydia', 'caviae', 'infection', 'alters', 'abundance', 'but', 'not', 'composition', 'of', 'the', 'guinea', 'pig', 'vaginal', 'microbiota', 'In', 'humans', ',', 'the', 'vaginal', 'microbiota', 'is', 'thought', 'to', 'be', 'the', 'first', 'line', 'of', 'defense', 'again', 'pathogens', 'including', 'Chlamydia', 'trachomatis', '.'], ['For', 'the', 'ease', 'of', 'analysis', ',', 'words', 'have', 'been', 'spearated', 'by', '``', '_', '_', '.'], ['In', 'a', 'grassland', 'biodiversity', 'experiment', ',', 'we', 'addressed', 'this', 'gap', 'by', 'assessing', 'aboveground', 'decomposer', 'and', 'herbivore', 'communities', 'and', 'linking', 'their', 'abundance', 'and', 'diversity', 'to', 'rates', 'of', 'decomposition', 'and', 'herbivory', '.'], ['Inclusion', 'of', 'intraspecific', 'trait', 'variability', 'significantly', 'decreased', 'the', 'strength', 'of', 'these', 'covariations', '.'], ['Mass-', '%', 'of', '8', 'grain', 'size', 'classes', 'of', 'fine', 'earth', '<', '2', 'mm', 'from', 'soil', 'horizons', 'of', 'each', 'soil', 'profile', 'per', 'CSP', '.'], ['Earthworms', 'decreased', 'total', 'shoot', 'biomass', 'in', 'mesocosms', 'with', 'more', 'plant', 'species', 'but', 'did', 'not', 'affect', 'biomass', 'production', 'of', 'individual', 'functional', 'groups', '.'], ['Decision-makers', 'need', 'to', 'know', 'which', 'of', 'the', 'remaining', 'forests', 'to', 'prioritize', 'for', 'conservation', ',', 'but', 'the', 'only', 'spatial', 'information', 'on', 'forest', 'biodiversity', 'has', ',', 'until', 'recently', ',', 'come', 'from', 'a', 'sparse', 'network', 'of', 'ground-based', 'plots', '.'], ['Height', 'is', 'for', 'a', 'standing', 'tree', ',', 'length', 'for', 'a', 'tree', 'lying', 'on', 'the', 'ground', '.'], ['CSPs', ':', 'Coarse', 'woody', 'debris', '(', 'CWD', ')', '.'], ['While', 'the', 'wildlife', 'trade', 'may', 'put', 'additional', 'stress', 'on', 'coral', 'reefs', ',', 'it', 'brings', 'income', 'into', 'impoverished', 'parts', 'of', 'the', 'world', 'and', 'may', 'stimulate', 'interest', 'in', 'marine', 'conservation', '.'], ['(', 'rock_artefacts49', ':', 'Features', 'of', 'sediment', '/', 'Primary', 'constituents', '/', 'Rock', 'fragments', 'and', 'artefacts', ':', 'Soil', 'horizon', 'description', 'II', ';', 'rock_artefacts49', ')', 'Basic', 'information', 'on', 'soil', 'properties', ',', 'according', 'to', '``', 'Eckelmann', ',', 'W.', ',', 'Sponagel', ',', 'H.', ',', 'Grottenthaler', ',', 'W.', ',', 'Hartmann', ',', 'J.', 'K.', ',', 'Hartwich', ',', 'R.', ',', 'Janetzko', ',', 'P.', ',', '...', '&', 'Traidl', ',', 'R.', '(', '2005', ')', '.'], ['The', 'aim', 'of', 'our', 'study', 'was', 'to', 'conduct', 'a', 'rRNA-targeted', 'metagenomic', 'analysis', 'on', 'amoebae', 'and', 'intra-amoebal', 'bacteria', 'found', 'in', 'drinking', 'water', 'network', ',', 'to', 'provide', 'the', 'first', 'FLA', 'microbiome', 'in', 'environmental', 'strains', '.'], ['nawai', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Camponotus', 'vitiosus', ')', ',', 'Camponotus', 'vitiosus', '(', 'Camponotus', 'vitiosus', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Pristomyrmex', 'punctatus', ')', ',', 'Pristomyrmex', 'punctatus', '(', 'Pristomyrmex', 'punctatus', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Alticinae', 'sp.1', ')', ',', 'Alticinae', 'sp.1', '(', 'Alticinae', 'sp.1', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Crematogaster', 'cf', '.'], [';', 'Comparative', 'Study', 'Plots', '(', 'CSP', ')', 'in', 'the', 'Gutianshan', 'Nature', 'Reserve', ',', 'having', 'a', 'size', 'of', '30x30m^2', ',', 'measured', 'on', 'the', 'ground', '.', ')'], ['The', 'finding', 'that', 'intraspecific', 'trait', 'variation', 'contributed', 'less', 'to', 'this', 'relationship', 'suggests', 'that', 'the', 'trade-off', 'is', 'dominated', 'by', 'evolutionary', 'constraints', 'rather', 'than', 'by', 'carbon', 'allocation', 'constraints', '.'], ['For', 'each', 'compound', ',', 'the', 'target', 'pathogen', 'and', 'biochemical', 'mode', 'of', 'action', 'are', 'described', ',', 'in', 'order', 'to', 'draw', 'attention', 'to', 'the', 'complexity', 'of', 'these', 'phenomena', '.'], ['The', 'aim', 'of', 'this', 'study', 'was', 'to', 'test', 'whether', 'species', 'contributions', 'to', 'community', 'biomass', 'can', 'be', 'used', 'as', 'surrogate', 'measures', 'of', 'their', 'contribution', 'to', 'ecosystem', 'processes', '.'], ['From', '27', 'comparative', 'study', 'plots', '(', 'CSPs', ')', 'soil', 'samples', 'were', 'taken', 'horizonwise', 'from', '1', 'soil', 'profile', 'per', 'CSP', 'Soil', 'profiles', 'are', 'located', 'directly', 'adjacent', 'to', 'the', 'CSPs', '.'], ['string', '#', 'string', 'qscore', 'data/nfa_2018_edition.csv', 'csv', 'original/GFN', 'Country', 'code', 'concordance', 'table.csv', 'original/GFN', 'Country', 'code', 'concordance', 'table.csv', 'csv', 'text/csv', '5699', 'original/NFA', '2018', 'Edition.csv', 'original/NFA', '2018', 'Edition.csv', 'csv', 'text/csv', '7132699', 'science', 'earth', 'one', 'planet', 'sustainability', 'earth', 'science', 'international', 'government', 'carbon', 'forest', 'infrastructure', 'anthropogenic'], ['These', 'surficial', 'lithology', 'classes', 'were', 'derived', 'from', 'the', 'USGS', 'map', '``', 'Surficial', 'Materials', 'in', 'the', 'Conterminous', 'United', 'States', 'States', ',', 'which', 'was', 'based', 'on', 'texture', ',', 'internal', 'structure', ',', 'thickness', 'and', 'environment', 'of', 'deposition', 'or', 'formation', 'of', 'materials', '(', 'Soller', 'and', 'Reheis', ',', '2004', ')', '.'], ['Rainevent', 'for', 'determinig', 'kinetic', 'energy', 'of', 'rainfalls', 'Splashcups', 'were', 'collected', 'after', 'certain', 'rain', 'events', '.'], ['(', 'CSP20', ':', 'BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', ')', 'dimensionless', 'real', 'Abundance', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['The', 'Directive', 'was', 'transposed', 'into', 'Irish', 'Law', 'by', 'the', 'European', 'Communities', '(', 'Health', 'of', 'Aquaculture', 'Animals', 'and', 'Products', ')', 'Regulations', '2008', '(', 'SI', 'No', '.'], ['The', 'abundance', 'of', 'tree', 'species', 'were', 'collected', 'from', '64', 'plots', '(', 'each', '1250', 'm2', 'in', 'size', ')', 'within', 'a', 'Sierra', 'Leonean', 'national', 'park', ',', 'and', 'Shannon-Wiener', 'biodiversity', 'indices', 'were', 'calculated', '.'], ['(', 'Fungi', ':', 'sum', '18:01', 'w9c', ',', '18:02', 'w6,9c', ';', ';', 'Wu', 'et', 'al.', ',', '2012', '(', 'see', 'metadata', 'sheet', ',', 'doi:10.1007/s10021-012-9533-3', ')', '(', 'derived', 'from', 'datagroup', ')', ')', 'dimensionless', 'real', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', '.'], ['To', 'estimate', 'habitat', 'favorability', 'to', 'fungi', ',', 'we', 'examined', 'the', 'relationship', 'of', 'fungal', 'abundance', 'and', 'species', 'richness', 'to', 'various', 'weather', 'and', 'environmental', 'parameters', 'in', 'the', 'Intermountain', 'West', '.'], ['The', 'greatest', 'changes', 'were', 'seen', 'for', 'early', 'stage', 'transitions', ',', 'such', 'as', 'introduction', 'of', 'reduced', 'tillage', 'regimes', 'and', 'conversion', 'to', 'grassland', 'from', 'arable', 'land', '.'], ['On', 'each', 'tree', ',', 'a', 'total', 'of', '20', 'young', 'leaves', 'and', 'the', 'attached', 'branch', 'sections', 'of', 'three', 'randomly', 'selected', 'branches', 'were', 'visually', 'inspected', 'for', 'the', 'occurrence', 'and', 'the', 'number', 'of', 'sap-sucking', 'Hemiptera', 'and', 'honeydew-collecting', 'ants', '.'], ['The', 'Levantine', 'Basin', ',', 'severely', 'impacted', 'by', 'the', 'invasion', 'of', 'species', ',', 'is', 'endangered', 'as', 'well', '.'], ['Ant', 'species', 'name', '(', 'Species_Tax', ')', ',', 'Species_Tax', 'Ants', 'were', 'identified', 'to', 'species', 'level', 'with', 'primary', 'taxonomic', 'literature', 'whenever', 'possible', '.'], ['Based', 'on', 'community-weighted', 'mean', 'calculations', 'for', 'each', 'functional', 'trait', ',', 'we', 'figured', 'out', 'that', 'the', 'traits', 'N-fixation', 'and', 'species', 'origin', ',', 'i.e', '.'], ['Here', 'we', 'provide', 'an', 'overview', 'of', 'important', 'considerations', 'related', 'to', 'forest', 'restoration', 'that', 'can', 'be', 'inferred', 'from', 'this', 'BEF-perspective', '.'], ['Recent', 'community', 'evolution', 'models', 'are', 'a', 'promising', 'step', 'in', 'that', 'direction', '.'], ['HoloBee-Barcode', 'is', 'intended', 'to', 'improve', 'and', 'standardize', 'quantitative', 'and', 'qualitative', 'metagenomic', 'descriptions', 'of', 'holobiont', 'communities', 'associated', 'with', 'honey', 'bees', 'by', 'providing', 'a', 'curated', 'set', 'of', 'barcode', 'sequences', '.'], ['Growing', 'human', 'population', 'densities', ',', 'intensified', 'land-use', ',', 'invasive', 'species', 'and', 'increasing', 'habitat', 'fragmentation', 'threaten', 'ecosystems', 'worldwide', 'and', 'protected', 'areas', 'are', 'often', 'the', 'only', 'refuge', 'for', 'endangered', 'species', '.'], ['In', 'a', 'series', 'of', 'experiments', 'replicated', 'at', 'a', 'global', 'scale', 'we', 'translocated', 'several', 'hundred', 'marine', 'hard', 'bottom', 'communities', 'to', 'new', 'environments', 'simulating', 'a', 'rapid', 'but', 'moderate', 'environmental', 'change', '.'], ['With', 'this', 'data', ',', 'herb', 'community', 'analysis', 'from', 'the', 'CSPs', 'can', 'be', 'performed', '.'], ['(', 'Ants_sum', ':', 'Total', 'number', 'of', 'individuals', 'of', 'ants', ')', 'dimensionless', 'real', 'Organism', 'count', 'Counting', 'the', 'individuals', 'of', 'a', 'given', 'taxon', ',', 'also', 'called', 'abundance', '.'], ['Our', 'findings', 'compromise', 'the', 'validity', 'of', 'the', 'guinea', 'pig-C.', 'caviae', 'model', 'to', 'study', 'the', 'role', 'of', 'the', 'vaginal', 'microbiota', 'during', 'the', 'early', 'steps', 'of', 'sexually', 'transmitted', 'infection', '.'], ['The', 'community', 'composition', 'of', 'the', 'riparian', 'reserves', 'was', 'more', 'similar', 'to', 'logged', 'forest', 'than', 'oil', 'palm', '.'], ['Using', 'monocultures', 'of', 'ten', 'and', 'seven', 'tree', 'species', ',', 'respectively', 'planted', 'at', 'two', 'different', 'sites', ',', 'juveniles', 'of', 'all', 'species', 'were', 'grown', 'in', 'their', 'own', '(', 'home', ')', 'and', 'in', 'all', 'other', 'monocultures', '(', 'away', ')', ',', 'thereby', 'testing', 'for', 'distance', 'effect', ',', 'just', 'as', 'in', 'three', 'different', 'levels', 'of', 'planting', 'density', ',', 'testing', 'for', 'density', 'effects', '(', 'see', '``', 'Main', 'Experiment', ':', 'Seedling', 'addition', 'experiment', '-', 'growth', 'and', 'biomass', 'data', 'data', 'for', 'further', 'details', ')', 'In', 'addition', ',', 'we', 'repeated', 'a', 'similar', 'set-up', 'in', 'a', 'nearby', 'common', 'garden', 'experiment', ',', 'where', 'we', 'added', 'a', 'shadow', 'shadow', 'treatment', 'to', 'simulate', 'different', 'light', 'conditions', 'induced', 'by', 'the', 'canopy', 'layer', '.'], ['Sand-filled', 'splash', 'cups', 'were', 'used', 'to', 'study', 'the', 'erosivity', 'of', 'rainfall', 'and', 'throughfall', 'in', 'the', 'humid', 'subtropics', 'of', 'southeast', 'China', 'in', 'spring', 'and', 'summer', '2010', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP26', ')', ',', 'CSP26', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['Even', 'if', 'species', 'can', 'migrate', 'in', 'response', 'to', 'climate', 'change', ',', 'if', 'ecotones', 'do', 'not', 'they', 'can', 'function', 'as', 'hard', 'barriers', 'to', 'species', 'migrations', ',', 'making', 'ecotone', 'migrations', 'central', 'to', 'understanding', 'species', 'persistence', 'under', 'scenarios', 'of', 'climate', 'change', '.'], ['(', 'BA17', ':', 'basal', 'area', 'in', '2017', ')', 'dimensionless', 'real', 'Basal', 'area', 'Basal', 'area', 'is', 'calculated', 'as', 'the', 'area', 'at', 'breastheight', 'of', 'a', 'given', 'tree', 'and', 'can', 'be', 'summed', 'up', 'to', 'estimate', 'the', 'tree', 'mass', 'in', 'a', 'given', 'plot', '.'], ['Insect', 'pollination', 'and', 'self-incompatibility', 'in', 'edible', 'and/or', 'medicinal', 'crops', 'in', 'southwestern', 'China', ',', 'a', 'global', 'hotspot', 'of', 'biodiversity', '.'], ['Forest', 'Ecology', 'and', 'Management', '261', '(', '3', ')', ':', '499-507', '(', 'derived', 'from', 'datagroup', ')', '(', 'CI_ME', ':', 'competition', 'index', '(', 'Martin', 'and', 'Ek', '1984', ')', ')', 'dimensionless', 'real', 'Competition', 'index', 'Individual', 'tree', 'competition', 'index', '.'], ['Besides', 'the', 'formation', 'of', 'monomethylarsonic', 'acid', '(', 'MMAV', ')', ',', 'we', 'detected', 'the', 'highly', 'toxic', 'monomethylarsonous', 'acid', '(', 'MMAIII', ')', '.'], ['Corrections', 'are', 'in', 'pos.af', ';', 'Datagroup', 'description', ':', 'Helper', 'Allometries', '(', 'plot', 'estimate', ')', ',', 'dimensionless', 'plot', 'estimate', 'Data', 'to', 'derive', 'tree', 'or', 'sapling', 'allometries', ',', 'as', 'well', 'as', 'allometric', 'equations', '.'], ['Another', 'definition', ':', '``', 'Operational', 'taxonomic', 'unit', ',', 'species', 'distinction', 'in', 'microbiology', '.'], ['The', 'NNR', 'comprises', 'a', 'large', 'portion', 'of', 'broad-leaved', 'forests', 'of', 'advanced', 'successional', 'stages', '(', 'Hu', '&', 'Yu', '2008', ')', ',', 'which', 'have', 'not', 'been', 'managed', 'since', 'the', 'beginning', 'of', 'the', '1990ies', ',', 'as', 'well', 'as', 'young', 'successional', 'stages', 'and', 'conifer', 'plantations', ',', 'mainly', 'of', 'Cunninghamia', 'lanceolata', 'and', 'Pinus', 'massoniana', '.'], ['Here', ',', 'we', 'asked', 'to', 'which', 'degree', 'physical', 'and', 'chemical', 'carbon-based', 'leaf', 'defence', 'traits', 'covary', 'within', 'and', 'across', 'species', '.'], ['information', 'on', 'data', 'analysis', 'Main', 'Experiment', ':', 'Leaf', 'traits', 'and', 'chemicals', 'from', 'individual', 'trees', 'in', 'the', 'Main', 'Experiment', '(', 'Site', 'A', '&', 'B', ')', '/datasets/323', 'ASCII', '1', 'column', ',', 'Identifier', '(', 'Samplecode', ')', ',', 'Samplecode', 'An', 'unabiguous', 'identifier', 'that', 'refers', 'to', 'a', 'specific', 'sample', '(', 'Samplecode', ':', 'Identifier', ';', 'Combination', 'of', 'characters', 'and', 'number', 'allowing', 'a', 'specific', 'identification', 'of', 'the', 'respective', 'specimen', ')', 'An', 'unabiguous', 'identifier', 'that', 'refers', 'to', 'a', 'specific', 'sample', 'Identifier', 'An', 'unabiguous', 'identifier', 'that', 'refers', 'to', 'a', 'specific', 'sample', 'Identifier', ';', 'Combination', 'of', 'characters', 'and', 'number', 'allowing', 'a', 'specific', 'identification', 'of', 'the', 'respective', 'specimen', 'Helper', '(', 'Sample.Collector', ')', ',', 'Sample.Collector', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', '(', 'Sample.Collector', ':', 'Sample.Collector', ')', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Helper', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Sample.Collector', 'Scientific', 'plant', 'species', 'name', '(', 'Species', ')', ',', 'Species', 'The', 'scientific', 'species', 'fullnames', 'are', 'based', 'on', 'the', '``', 'Flora', 'of', 'China', 'China', 'identified', 'by', 'Teng', 'Fang', 'and', 'verified', 'by', 'Helge', 'Bruelheide', '(', 'trees', ')', 'and', 'Alexandra', 'Erfmeier', '(', 'herbs', ')', '.'], ['The', 'contrast', 'in', 'diversity-multi-functionality', 'relationships', 'among', 'fallow', 'types', 'appears', 'related', 'to', 'differences', 'in', 'management', 'and', 'associated', 'factors', 'including', 'disturbance', 'and', 'species', 'composition', '.'], ['Here', 'we', 'combined', 'an', 'extensive', 'literature', 'analysis', 'with', 'expert', 'opinions', 'to', 'update', 'publicly', 'available', 'estimates', 'of', 'major', 'taxa', 'in', 'this', 'marine', 'ecosystem', 'and', 'to', 'revise', 'and', 'update', 'several', 'species', 'lists', '.'], ['This', 'system', 'is', 'an', 'important', 'model', 'for', 'understanding', 'how', 'microbial', 'communities', 'degrade', 'plant', 'biomass', 'in', 'natural', 'systems', 'and', 'has', 'direct', 'relevancy', 'for', 'bioenergy', ',', 'given', 'recent', 'interest', 'in', 'cellulosic', 'biofuels', '.'], ['Assessing', 'biodiversity', 'of', 'a', 'freshwater', 'benthic', 'macroinvertebrate', 'community', 'through', 'non-destructive', 'environmental', 'barcoding', 'of', 'DNA', 'from', 'preservative', 'ethanol', 'Background', 'Characterizing', 'biodiversity', 'in', 'a', 'habitat', 'or', 'in', 'targeted', 'taxonomically', 'or', 'socioeconomically', 'important', 'groups', 'remains', 'a', 'challenge', '.'], [';', 'Datagroup', 'description', ':', 'Organism', 'count', 'yes', '1224'], ['DESCRIPTION', 'Fish', 'Health', 'Unit', 'Authorised', 'Sites', 'SUMMARY', 'Fish', 'Health', 'Unit', 'registered', 'finfish', 'sites', 'in', 'Ireland', 'where', 'Fish', 'Health', 'regulations', 'and', 'Fish', 'Health', 'monitoring', 'on', 'finfish', 'are', 'applied', '.'], ['Of', 'other', 'trophobioses', ',', 'voucher', 'specimens', 'were', 'collected', '(', 'stored', 'in', '99', '%', 'ethanol', ')', '.'], ['Patterns', 'and', 'Perceptions', 'of', 'Climate', 'Change', 'in', 'a', 'Biodiversity', 'Conservation', 'Hotspot', 'Quantifying', 'local', 'people', 's', 'perceptions', 'to', 'climate', 'change', ',', 'and', 'their', 'assessments', 'of', 'which', 'changes', 'matter', ',', 'is', 'fundamental', 'to', 'addressing', 'the', 'dual', 'challenge', 'of', 'land', 'conservation', 'and', 'poverty', 'alleviation', 'in', 'densely', 'populated', 'tropical', 'regions', 'To', 'develop', 'appropriate', 'policies', 'and', 'responses', ',', 'it', 'will', 'be', 'important', 'not', 'only', 'to', 'anticipate', 'the', 'nature', 'of', 'expected', 'changes', ',', 'but', 'also', 'how', 'they', 'are', 'perceived', ',', 'interpreted', 'and', 'adapted', 'to', 'by', 'local', 'residents', '.'], ['Biotic', 'variables', 'included', 'species', 'richness', ',', 'functional', 'diversity', ',', 'competition', 'index', ',', 'the', 'dbh', 'of', 'the', 'target', 'tree', 'and', 'mean', 'upper', 'canopy', 'height', ',', 'while', 'the', 'abiotic', 'variables', 'were', 'slope', 'inclination', ',', 'slope', 'aspect', 'and', 'soil', 'depth', '.'], ['Strong', 'negative', 'covariations', 'were', 'detected', 'between', 'physical', 'and', 'chemical', 'defence', 'trait', 'when', 'phylogenetic', 'non-independence', 'was', 'accounted', 'for', '.'], ['Location', 'of', 'the', 'pitfall', 'trap', 'Helper', '(', 'Species', ')', ',', 'Species', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', '(', 'Species', ':', 'Species', 'name', '.'], ['basal', 'area', 'in', '2013', 'Basal', 'area', '(', 'BA14', ')', ',', 'BA14', 'Basal', 'area', 'is', 'calculated', 'as', 'the', 'area', 'at', 'breastheight', 'of', 'a', 'given', 'tree', 'and', 'can', 'be', 'summed', 'up', 'to', 'estimate', 'the', 'tree', 'mass', 'in', 'a', 'given', 'plot', '.'], ['us-vcgi-org_dd789af6-cdcc-4380-a40b-d407d1243adc', 'VT', 'Biodiversity', 'Project', '-', 'Plant', 'and', 'Animal', 'Species', 'Atlas', 'VT', 'Biodiversity', 'Project', '-', 'Plant', 'and', 'Animal', 'Species', 'Atlas', '(', '[', 'Link', 'to', 'Metadata', ']', '(', 'This', 'database', 'contains', 'town-level', 'totals', 'of', 'documented', 'species', 'records', 'for', 'several', 'plant', 'and', 'animal', 'taxa', 'including', 'vascular', 'plants', ',', 'trees', ',', 'bryophytes', ',', 'ferns', ',', 'fish', ',', 'mammals', ',', 'and', 'reptiles', '&', 'amphibians', '.'], ['An', 'Insect', 'Herbivore', 'Microbiome', 'with', 'High', 'Plant', 'Biomass-Degrading', 'Capacity', 'Herbivores', 'can', 'gain', 'indirect', 'access', 'to', 'recalcitrant', 'carbon', 'present', 'in', 'plant', 'cell', 'walls', 'through', 'symbiotic', 'associations', 'with', 'lignocellulolytic', 'microbes', '.'], ['Common', 'measures', 'are', 'functional', 'diversity', ',', 'eveness', ',', 'dissimilarity', '.'], ['Woody', 'debris', 'type', 'Woody', 'debris', 'type', 'is', 'a', 'positioning', 'information', 'in', 'categories', '11-Jan', ',', 'plus', 'diverse', 'other', 'information', '.'], ['The', 'results', 'revealed', 'that', 'the', 'frequency', 'of', 'drought', 'has', 'increased', 'in', 'the', '21st', 'century', 'with', 'the', 'drying', 'trend', 'occurring', 'in', 'most', 'of', 'China', '.'], ['From', 'a', 'spatial', 'point', 'of', 'view', ',', 'all', 'indices', 'clearly', 'singled', 'out', 'Corsica', 'Island', 'as', 'having', 'higher', 'average', 'originality', 'and', 'specialization', '.'], ['Effective', 'global', 'stewardship', 'of', 'plant', 'biodiversity', 'in', 'the', 'Anthropocene', 'will', 'require', 'integrated', 'frameworks', 'for', 'observing', ',', 'modeling', 'and', 'forecasting', 'the', 'different', 'forms', 'of', 'anthropogenic', 'biodiversity', 'change', 'processes', 'at', 'regional', 'landscape', 'scales', ',', 'towards', 'conserving', 'biodiversity', 'within', 'the', 'novel', 'plant', 'communities', 'created', 'and', 'sustained', 'by', 'human', 'systems', '.'], ['A', 'subset', 'of', '12', 'CSPs', 'were', 'selected', 'according', 'to', 'an', 'successional', 'age', 'and', 'a', 'diversity', 'gradient', ';', 'based', 'on', 'the', 'original', 'age', 'classifications', ':', 'young', '(', 'CSPs', '16,17,25,26', ')', ',', 'medium', '(', 'CSPs', '1,5,8,9', ')', 'and', 'old', '(', 'CSPs', '2,4,12,13', ')', '.'], ['city-of-ny_fuhs-xmg2', 'Urban', 'Park', 'Ranger', 'Animal', 'Condition', 'Response', 'This', 'dataset', 'contains', 'information', 'about', 'requests', 'for', 'animal', 'assistance', ',', 'relocation', ',', 'and/or', 'rescue', 'completed', 'by', 'the', '...'], ['The', 'expression', 'of', 'fetidin/lysenins', 'in', 'E.', 'fetida', 'was', 'not', 'affected', 'upon', 'the', 'challenge', 'with', 'compost', 'microbiota', ',', 'suggesting', 'more', 'substantial', 'changes', 'in', 'the', 'regulation', 'of', 'the', 'gene', 'expression', '.'], ['R', 'uses', 'rarefy', '(', ')', 'from', 'the', 'package', 'vegan', 'to', 'estimated', 'species', 'number', 'for', 'a', 'given', 'number', 'of', 'individuals', '.'], ['Commands', ':', 'as.taxo', '(', ')', ',', 'divc', '(', ')', 'Estimated', 'number', 'of', 'caterpillar', 'OTUs', '(', 'Hill', 'number', '2', ')', 'Phylogenetic', 'biodiversity', '(', 'PD_boot', ')', ',', 'PD_boot', 'Phylogenetic', 'biodiversity', '(', 'PD_boot', ':', 'bootstrapped', 'PD', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'bootstrapped', 'PD', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MPD_boot', ')', ',', 'MPD_boot', 'Phylogenetic', 'biodiversity', '(', 'MPD_boot', ':', 'bootstrapped', 'MPD', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'bootstrapped', 'MPD', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MNTD_boot', ')', ',', 'MNTD_boot', 'Phylogenetic', 'biodiversity', '(', 'MNTD_boot', ':', 'bootstrapped', 'MNTD', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'bootstrapped', 'MNTD', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'PD', ')', ',', 'PD', 'Phylogenetic', 'biodiversity', '(', 'PD', ':', 'phylogenetic', 'diversity', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'phylogenetic', 'diversity', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MPD', ')', ',', 'MPD', 'Phylogenetic', 'biodiversity', '(', 'MPD', ':', 'mean', 'phylogenetic', 'diversity', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'mean', 'phylogenetic', 'diversity', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MNTD', ')', ',', 'MNTD', 'Phylogenetic', 'biodiversity', '(', 'MNTD', ':', 'mean', 'nearest', 'taxon', 'distance', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'mean', 'nearest', 'taxon', 'distance', 'of', 'caterpillars', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', '(', 'tree', 'richness', ')', ',', 'tree', 'richness', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', '(', 'tree', 'richness', ':', 'Tree', 'species', 'richness', ')', 'dimensionless', 'real', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', 'Tree', 'species', 'richness', 'Functional', 'biodiversity', '(', 'func_div_rao', ')', ',', 'func_div_rao', 'Functional', 'biodiversity', 'uses', 'functional', 'traits', 'of', 'organisms', 'as', 'a', 'basis', 'to', 'quantifying', 'biodiversity', '.'], ['Our', 'conversion', 'of', 'carbon', 'to', 'CO2', 'increased', 'in', 'precision', ',', 'which', 'increased', 'the', 'world', 's', 'carbon', 'footprint', 'by', 'approximately', '1', '%', '.'], ['In', 'the', 'Pilot', 'experiment', ',', 'vegetation', 'layer', 'is', 'referred', 'to', 'as', '``', 'stratum', 'stratum', 'and', 'is', 'measured', 'in', '50cm', 'thick', 'layers', 'above', 'ground', '.'], ['Yet', 'these', 'biodiversity', 'changes', 'and', 'others', 'caused', 'directly', 'by', 'human', 'populations', 'and', 'their', 'use', 'of', 'land', 'tend', 'to', 'co-occur', 'as', 'long-term', 'biodiversity', 'change', 'processes', 'in', 'the', 'Anthropocene', '.'], ['The', 'present', 'study', 'may', 'facilitate', 'a', 'better', 'understanding', 'of', 'the', 'toxicity', 'of', 'BDE-209', 'toward', 'the', 'soil', 'environment', '.'], ['Our', 'meta-analysis', 'provides', 'support', 'for', 'wider', 'use', 'of', 'retention', 'forestry', 'since', 'it', 'moderates', 'negative', 'harvesting', 'impacts', 'on', 'biodiversity', '.'], ['In', 'particular', ',', 'drought-sensitive', 'species', '(', 'i.e', '.'], ['rare', 'faction', 'of', 'functional', 'groups', 'of', 'target', 'group', '.'], ['For', 'this', 'purpose', 'we', 'classified', 'the', 'species', 'into', 'seven', 'functional', 'groups', '.'], ['(', 'Sub', ':', 'Species', 'binomial', ')', 'The', 'scientific', 'species', 'fullnames', 'are', 'based', 'on', 'the', '``', 'Flora', 'of', 'China', 'China', 'identified', 'by', 'Teng', 'Fang', 'and', 'verified', 'by', 'Helge', 'Bruelheide', '(', 'trees', ')', 'and', 'Alexandra', 'Erfmeier', '(', 'herbs', ')', '.'], ['Conclusion', 'This', 'study', 'may', 'provide', 'fundamentally', 'new', 'insights', 'into', 'the', 'role', 'of', 'chemolithoautotrophic', 'and', 'photoautotrophic', 'bacterial', 'diversity', 'in', 'biochemical', 'carbon', 'cycling', 'in', 'barren', 'saline', 'soils', '.'], ['Not', 'all', 'changes', ',', 'however', ',', 'result', 'in', 'positive', 'effects', 'on', 'the', 'assessed', 'community', 'metrics', '.'], ['rogenhoferi', ')', ',', 'Crematogaster', 'cf', '.'], ['Acta', 'Oecologica', '61', ':', '32-40', '.'], ['It', 'would', 'be', 'no', 'more', 'appropriate', 'to', 'ignore', 'barcode', 'data', 'in', 'a', 'species', 'inventory', 'than', 'it', 'would', 'be', 'to', 'ignore', 'adult', 'genitalia', 'variation', 'or', 'caterpillar', 'ecology', '.'], ['(', 'ppm', ')', 'number', '#', 'decimal', 'st_dev_p_bicar_ppm', 'data/p_bicar.csv', 'csv', 'ph', 'vegetation_class', 'Vegetation', 'Class', 'string', '#', 'string', 'vegetation_class', 'dir_quad', 'DIR', '.'], ['For', 'the', 'national', 'terrestrial', 'ecosystem', 'mapping', 'effort', ',', 'the', 'original', '28', 'lithology', 'classes', 'were', 'reclassified', 'into', 'a', 'set', 'of', '18', 'lithologies', 'that', 'typically', 'control', 'or', 'influence', 'the', 'distribution', 'of', 'vegetation', 'types', '(', 'Kruckeberg', ',', '2002', ')', '.'], ['mutualism', ',', 'predation', ')', 'might', 'be', 'an', 'important', 'moderator', 'of', 'biodiversity-ecosystem', 'function', 'relationships', '.'], ['Microbial', 'biomass', 'and', 'diversity', 'increased', 'in', 'mineral', 'soil', 'layers', ',', 'with', 'a', 'weak', 'negative', 'effect', 'in', 'organic', 'soil', 'layers', ',', 'indicating', 'that', 'the', 'mixing', 'of', 'soil', 'layers', 'by', 'earthworms', '(', 'bioturbation', ')', 'may', 'homogenize', 'microbial', 'communities', 'across', 'soil', 'layers', '.'], ['Trap', 'location', 'within', 'the', 'Comparative', 'Study', 'Sites', '.'], ['In', 'each', 'CSP', 'there', 'is', 'only', 'one', 'neighbourhood', 'per', 'species', '.'], ['--', '-', '6', 'digit', 'metal', 'tags', 'starting', 'with', '3', 'were', 'also', 'used', 'for', 'woody', 'debris', 'items', '--', 'the', 'reference', 'file', 'linking', 'metal', 'tags', 'to', 'tree', 'individual', 'tags', 'is', 'called', '``', 'Tree', 'stem', 'reference', 'list', 'for', 'the', 'Comparative', 'Study', 'Sites', '(', 'CSPs', ')', ')', 'Silver', 'ID', 'given', 'by', 'Anja', ',', 'can', 'be', 'given', 'to', 'a', 'woody', 'debris', 'item', 'or', 'to', 'a', 'standing', 'dead', 'tree', 'or', 'snagCSP', 'metal', 'tag', 'number', '(', 'trees', ',', 'woody', 'debris', ')', ';', 'Datagroup', 'description', ':', 'CSP', 'metal', 'tag', 'number', '(', 'trees', ',', 'woody', 'debris', ')', ';', 'Datagroup', 'description', ':', 'CSP', 'tree', 'individuals', 'were', 'marked', 'mostly', 'with', 'metal', 'tags', 'but', 'also', 'additional', 'tags', 'were', 'used', '.'], ['string', '#', 'string', 'dir_quad', 'int_ext', 'INT/EXT', 'string', '#', 'string', 'int_ext', 'a_b', 'A', '&', 'B', 'string', '#', 'string', 'a_b', 'data_labels', 'Data', 'Labels', 'string', '#', 'string', 'data_labels', 'series_name', 'Series', 'Name', 'string', '#', 'string', 'series_name', 'sample_1', 'Sample', '#', '1', 'number', '#', 'decimal', 'sample_1', 'sample_2', 'Sample', '#', '2', 'number', '#', 'decimal', 'sample_2', 'sample_3', 'Sample', '#', '3', 'number', '#', 'decimal', 'sample_3', 'sample_4', 'Sample', '#', '4', 'number', '#', 'decimal', 'sample_4', 'average_ca_total_bases', 'Average', 'Ca', 'Total', 'Bases', '(', '%', ')', 'number', '#', 'decimal', 'average_ca_total_bases', 'st_dev_ca_total_bases', 'St.', 'Dev', 'Ca', 'Total', 'Bases', '(', '%', ')', 'number', '#', 'decimal', 'st_dev_ca_total_bases', 'data/catotal_bases.csv', 'csv', 'cu', 'vegetation_class', 'Vegetation', 'Class', 'string', '#', 'string', 'vegetation_class', 'dir_quad', 'DIR', '.'], ['Our', 'results', 'indicate', 'substantial', 'differences', 'in', 'the', 'conservation', 'status', 'of', 'PNVs', '.'], ['This', 'highlights', 'the', 'imbalance', 'of', 'exploration', 'within', 'these', 'areas', 'rather', 'than', 'any', 'reduction', 'in', 'biodiversity', '.'], ['With', 'a', 'TCE', 'dose', 'increase', 'by', 'more', 'than', '10', 'mg/kg', ',', 'the', 'TCE', 'degradation', 'decreases', 'due', 'to', 'the', 'toxic', 'effect', 'of', 'this', 'pollutant', 'on', 'microbial', 'consortium', 'activity', '.'], ['Central', 'components', 'of', 'the', 'J-C', 'hypothesis', 'are', 'non-competitive', 'effects', 'of', 'density', '-', 'and', 'distance', '#NAME?', ',', 'thereby', 'two', 'drivers', 'that', 'contribute', 'independently', 'to', 'species', 'coexistence', ',', 'but', 'that', 'are', 'ultimately', 'linked', 'in', 'the', 'field', '.'], ['Our', 'species', 'set', 'represents', 'a', 'range', 'of', 'vertebrate', 'taxa', '(', 'primarily', 'mammals', ',', 'birds', ',', 'amphibians', ',', 'and', 'reptiles', ')', 'and', 'diverse', 'life', 'histories', '.'], ['2015', ':', 'Trade-offs', 'between', 'physical', 'and', 'chemical', 'carbon-based', 'leaf', 'defence', ':', 'Of', 'intraspecific', 'variation', 'and', 'trait', 'evolution', '(', 'Journal', 'of', 'Ecology', ')', 'David', 'Eichenberg', 'Botanik', 'Halle', 'Leipzig', 'Germany', 'Helge', 'Bruelheide', 'Christian', 'Ristok', 'Oliver', 'Purschke', 'German', 'Centre', 'for', 'Integrative', 'Biodiversity', 'Research', '(', 'iDiv', ')', 'Halle-Jena-Leipzig', 'Deutscher', 'Platz', '5e', 'Leipzig', 'Germany', '49', '(', '0', ')', '341-97-33121', '########', 'en_US', '1', '.'], ['Finally', ',', 'we', 'observed', 'that', 'the', 'originality', 'index', 'based', 'on', 'niche', 'traits', 'might', 'be', 'used', 'as', 'an', 'informative', 'biodiversity', 'indicator', 'because', 'we', 'showed', 'it', 'is', 'sensitive', 'to', 'different', 'land', 'use', 'classes', 'along', 'a', 'landscape', 'artificialization', 'gradient', '.'], ['Where', 'is', 'the', 'UK', 's', 'pollinator', 'biodiversity', '?'], ['The', 'respective', 'category', 'can', 'be', 'taxonomic', 'or', 'functional', ',', 'depending', 'on', 'the', 'subject', 'of', 'the', 'respective', 'study', '.'], ['I', 'show', 'that', 'there', 'are', 'large', 'and', 'growing', 'amounts', 'of', 'data', 'available', 'for', 'tropical', 'South', 'America', '.'], ['Here', 'we', 'summarize', 'the', 'various', 'topographical', ',', 'entomological', ',', 'parasitological', ',', 'human', 'ecological', 'and', 'socio-', 'economic', 'factors', ',', 'which', 'are', 'crucial', 'and', 'shape', 'malaria', 'transmission', 'in', 'forested', 'areas', '.'], ['number', '#', 'decimal', 'carbon', 'total', 'total', 'The', 'total', 'area', 'when', 'adding', 'cropland', ',', 'grazing', 'land', ',', 'forest', 'land', ',', 'fishing', 'ground', ',', 'built', 'up', 'land', 'and', 'carbon', 'footprints', 'together', 'number', '#', 'decimal', 'total', 'qscore', 'QScore', 'A', 'data', 'quality', 'scoring', 'system', 'to', 'show', 'a', 'country', 's', 'data', 'quality', 'which', 'is', 'comprised', 'of', 'two', 'components', ',', 'a', 'timeline', 'score', '(', 'excluding', 'latest', 'year', 'and', 'denoted', 'by', 'a', 'number', 'from', '1', 'to', '3', ')', 'and', 'a', 'latest', 'year', 'score', '(', 'denoted', 'by', 'a', 'letter', 'from', 'A', 'to', 'D', ')', '.'], ['The', 'vegetation', 'attributes', 'best', 'predicted', 'by', 'texture', 'are', 'relevant', 'in', 'the', 'face', 'of', 'two', 'of', 'the', 'gravest', 'threats', 'to', 'biosphere', 'integrity', ':', 'climate', 'change', 'and', 'biodiversity', 'loss', '.'], ['abundance', 'CSP', 'ectomycorrhiza', 'fungi', 'saprophytes', 'successional', 'age', 'Find', 'the', 'list', 'of', 'keywords', 'here', ':', 'Taxon', 'CSP', 'age', 'class', 'abundance', 'Taxonomic.assignment', 'List', 'of', 'headers', 'of', 'the', 'data', 'columns', 'in', 'this', 'dataset', 'Permission', 'is', 'granted', 'to', 'anybody', 'to', 'access', ',', 'use', 'and', 'publish', 'all', 'open', 'for', 'public', 'data', 'freely', '.'], ['Biodiversity', 'and', 'Ecosystem', 'Multi-Functionality', ':', 'Observed', 'Relationships', 'in', 'Smallholder', 'Fallows', 'in', 'Western', 'Kenya', 'Recent', 'studies', 'indicate', 'that', 'species', 'richness', 'can', 'enhance', 'the', 'ability', 'of', 'plant', 'assemblages', 'to', 'support', 'multiple', 'ecosystem', 'functions', '.'], ['Agricultural', 'expansion', 'and', 'intensification', 'are', 'major', 'threats', 'to', 'global', 'biodiversity', ',', 'ecological', 'functions', ',', 'and', 'ecosystem', 'services', '.'], ['Only', 'completely', 'developed', 'leaves', 'were', 'sampled', ',', 'without', 'visible', 'herbivore', 'damage', 'and', 'preferably', 'free', 'of', 'leaf', 'fungi', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP21', ')', ',', 'CSP21', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['DESCRIPTION', 'From', '2000-2011', ',', 'the', 'FAA', 'released', 'the', 'number', 'of', 'incidents', 'where', 'birds', 'have', 'struck', 'a', 'plane', '.'], ['Plant', 'Diversity', 'Impacts', 'Decomposition', 'and', 'Herbivory', 'via', 'Changes', 'in', 'Aboveground', 'Arthropods', 'Loss', 'of', 'plant', 'diversity', 'influences', 'essential', 'ecosystem', 'processes', 'as', 'aboveground', 'productivity', ',', 'and', 'can', 'have', 'cascading', 'effects', 'on', 'the', 'arthropod', 'communities', 'in', 'adjacent', 'trophic', 'levels', '.'], ['--', '--', 'For', 'general', 'comparisons', 'between', 'sites', 'subfamily', 'data', 'are', 'usefull', '.'], [')', ',', 'so', 'that', '6', 'samples', 'exist', 'per', 'CSP', '.'], ['life', 'form', 'Abundance', '(', 'CSP01', ')', ',', 'CSP01', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['The', 'direction', 'of', 'the', 'pendular', 'was', 'measured', 'by', 'means', 'of', 'a', 'compass.', '--', '-', 'Stem', 'slenderness', 'is', 'calculated', 'as', 'total', 'height', 'divided', 'by', 'stem', 'diameter', 'stem', 'inclination', 'Stem', 'morphology', '(', 'stem_azi', ')', ',', 'gon', 'stem_azi', 'Stem', 'morphology', 'is', 'measured', 'as', 'stem', 'inclination', 'and', 'stem', 'azimuth', '.'], ['Moreover', ',', 'we', 'show', 'that', 'multiple', 'components', 'of', 'tree', 'diversity', 'can', 'synergistically', 'affect', 'species', 'richness', 'and', 'phylogenetic', 'diversity', 'of', 'lepidopteran', 'larvae', '.'], ['However', ',', 'currently', 'we', 'lack', 'the', 'ability', 'to', 'predict', 'the', 'consequences', 'of', 'realistic', 'species', 'loss', 'on', 'ecosystem', 'processes', '.'], ['BEF-China', 'Main', 'Experiment', '117.8998', '118.1483', '29.2852', '29.10178', '########', '########', 'All', 'EFN-visiting', 'arthropods', 'All', 'EFN-visiting', 'arthropods', 'mstaab', 'aklein', 'jpeters', 'Main', 'Experiment', ':', 'Visitors', 'of', 'extrafloral', 'nectaries', '(', '2012', ')', 'Trees', 'with', 'extrafloral', 'nectaries', '(', 'EFN', ')', 'are', 'common', 'in', 'tropical', 'and', 'subtropical', 'forests', 'and', 'the', 'presence', 'of', 'EFN', 'trees', 'within', 'a', 'tree', 'community', 'may', 'influence', 'tree', 'growth', '.'], ['Allometries', '(', 'Allometrie', ')', ',', 'dimensionless', 'Allometrie', 'Data', 'to', 'derive', 'tree', 'or', 'sapling', 'allometries', ',', 'as', 'well', 'as', 'allometric', 'equations', '.'], ['Commands', ':', 'as.taxo', '(', ')', ',', 'divc', '(', ')', '(', 'div_abgd', ':', 'Observed', 'number', 'of', 'caterpillar', 'OTUs', 'based', 'on', 'ABGD', 'method', ')', 'dimensionless', 'real', 'Taxonomic', 'biodiversity', 'Taxon', 'diversity', 'can', 'be', 'given', 'as', 'species', 'richness', ',', 'or', 'other', 'diversity', 'indices', '.'], ['Toxicokinetic', 'studies', 'aiming', 'to', 'completely', 'elucidate', 'the', 'As', 'metabolic', 'pathway', 'would', 'therefore', 'benefit', 'from', 'incorporating', 'the', 'metabolic', 'potency', 'of', 'human', 'gut', 'microbiota', '.'], ['Our', 'results', 'highlight', 'the', 'need', 'for', 'fine-scale', 'climate', 'information', 'to', 'assist', 'agro-ecological', 'communities', 'in', 'developing', 'effective', 'adaptive', 'management', '.'], ['Living', 'status', '(', 'Dead', ')', ',', 'Dead', 'if', 'an', 'organism', 'is', 'dead', 'or', 'alive', 'or', 'damaged', '(', 'Dead', ':', 'indicator', 'for', 'species', 'dead', '(', '1', ')', 'or', 'alive', '(', '0', ')', ')', 'if', 'an', 'organism', 'is', 'dead', 'or', 'alive', 'or', 'damaged', 'Living', 'status', 'if', 'an', 'organism', 'is', 'dead', 'or', 'alive', 'or', 'damaged', 'indicator', 'for', 'species', 'dead', '(', '1', ')', 'or', 'alive', '(', '0', ')', 'Plant', 'height', '(', 'Height_P', ')', ',', 'cm', 'Height_P', 'measuring', 'tree', 'height', '(', 'Height_P', ':', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'photosynthetically', 'active', 'tissue', ')', 'dimensionless', 'real', 'Plant', 'height', 'measuring', 'tree', 'height', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'photosynthetically', 'active', 'tissue', 'Plant', 'height', '(', 'Height_G', ')', ',', 'cm', 'Height_G', 'measuring', 'tree', 'height', '(', 'Height_G', ':', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'still', 'living', 'tissue', ')', 'dimensionless', 'real', 'Plant', 'height', 'measuring', 'tree', 'height', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'still', 'living', 'tissue', 'Plant', 'leaf', 'number', '(', 'Leaves_Liv', ')', ',', 'Leaves_Liv', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', '(', 'Leaves_Liv', ':', 'Number', 'of', 'living', 'leaves', ')', 'dimensionless', 'real', 'Plant', 'leaf', 'number', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', 'Number', 'of', 'living', 'leaves', 'Plant', 'leaf', 'number', '(', 'Leaves_Dam', ')', ',', 'Leaves_Dam', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', '(', 'Leaves_Dam', ':', 'Number', 'of', 'damaged', 'leaves', ')', 'dimensionless', 'real', 'Plant', 'leaf', 'number', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', 'Number', 'of', 'damaged', 'leaves', 'Plant', 'leaf', 'number', '(', 'Leaves_Dead', ')', ',', 'Leaves_Dead', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', '(', 'Leaves_Dead', ':', 'Number', 'of', 'dead', 'leaves', 'on', 'seedling', ')', 'dimensionless', 'real', 'Plant', 'leaf', 'number', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', 'Number', 'of', 'dead', 'leaves', 'on', 'seedling', 'Herbivore', 'damage', '(', 'Damage_pro', ')', ',', 'in', 'percent', 'Damage_pro', 'Herbivore', 'damage', 'in', 'percentage', 'or', 'as', 'herbivory', 'classes', 'e.g', '.'], ['Ways', 'to', 'quantify', 'precipitation', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mmmeasured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ';', 'rainfall', 'amount', 'open', 'field', '(', 'vaisala', ')', 'mmmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'peak', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'of', 'the', 'five', 'highest', 'five', 'minute', 'intensities', 'open', 'field', '(', 'vaisala', ')', 'measured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mmmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'peak', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '(', 'am_b', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mm', '--', 'rainfall', 'amount', '(', 'collecting', 'bottle', ')', '--', 'measured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ')', 'millimeter', 'real', 'Precipitation', 'Precipitation', 'measured', 'at', 'the', 'climate', 'station', 'or', 'locally', 'within', 'sites', '.'], ['decay', 'class', 'of', 'downed', 'wood', 'Organisms', 'found', 'on', 'or', 'in', 'specimen', '(', 'ter', ')', ',', 'dimensionless', 'ter', 'Organisms', 'found', 'in', 'the', 'specimen', 'under', 'study', '.'], ['woody', 'recruits', ')', 'in', 'the', 'herb', 'layer', 'can', 'act', 'as', 'an', 'indicator', 'for', 'regeneration', '.'], ['Using', 'a', 'Multi-Trait', 'Approach', 'to', 'Manipulate', 'Plant', 'Functional', 'Diversity', 'in', 'a', 'Biodiversity-Ecosystem', 'Function', 'Experiment', 'A', 'frequent', 'pattern', 'emerging', 'from', 'biodiversity-ecosystem', 'function', 'studies', 'is', 'that', 'functional', 'group', 'richness', 'enhances', 'ecosystem', 'functions', 'such', 'as', 'primary', 'productivity', '.'], ['The', 'data', 'might', 'provide', 'valuable', 'information', 'to', 'be', 'compared', 'with', 'data', 'from', 'the', 'main', 'experiment', '.'], ['We', 'assessed', 'leaf', 'toughness', ',', 'leaf', 'total', 'phenolics', 'and', 'tannin', 'concentrations', 'for', '51', 'subtropical', 'tree', 'species', '.'], ['Samples', 'were', 'analyzed', 'over', 'the', 'depth', 'profile', 'of', 'each', 'CSP', '(', 'see', 'detailed', 'methods', 'below', ')', 'and', 'analyzed', 'for', 'phospholipid', 'fatty', 'acid', 'profiles', ',', 'which', 'represent', 'both', 'the', 'biomass', 'and', 'broad', 'community', 'structure', 'of', 'the', 'soil', 'microbial', 'community', 'including', 'broad', 'groups', 'of', 'bacteria', 'and', 'fungi', '.'], ['(', 'abundance_size55', ':', 'Features', 'of', 'sediment', 'Rockmaterial', '/', 'Description', 'of', 'artefacts', '/', 'Abundance/Size', ':', 'Soil', 'horizon', 'description', 'II', ';', 'abundance_size55', ')', 'Basic', 'information', 'on', 'soil', 'properties', ',', 'according', 'to', '``', 'Eckelmann', ',', 'W.', ',', 'Sponagel', ',', 'H.', ',', 'Grottenthaler', ',', 'W.', ',', 'Hartmann', ',', 'J.', 'K.', ',', 'Hartwich', ',', 'R.', ',', 'Janetzko', ',', 'P.', ',', '...', '&', 'Traidl', ',', 'R.', '(', '2005', ')', '.'], ['In', 'addition', ',', 'heterospecific', 'pollen', 'grains', 'were', 'deposited', 'on', 'most', 'stigmas', 'of', 'both', 'I.', 'noli-tangere', 'and', 'I.', 'textori', 'flowers', 'that', 'were', 'situated', 'within', '2', 'm', 'of', 'flowers', 'of', 'the', 'other', 'species', 'resulting', 'in', 'depressed', 'fruit', 'set', '.'], ['However', ',', 'the', 'model', 'was', 'unable', 'to', 'match', 'the', 'SAR', 'and', 'beta-diversity', 'simultaneously', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP09', ')', ',', 'CSP09', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['Helper', '(', 'hei.len.rem.kn', ')', ',', 'dimensionless', 'hei.len.rem.kn', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', '(', 'hei.len.rem.kn', ':', 'remark', 'on', 'heigtht', '..', 'length', 'by', 'Karin', ',', 'mostly', 'copying', 'those', 'entries', 'that', 'could', 'not', 'be', 'converted', 'to', 'numbersHelper', ';', 'Datagroup', 'description', ':', 'Helper', ')', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Helper', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'remark', 'on', 'heigtht', '..', 'length', 'by', 'Karin', ',', 'mostly', 'copying', 'those', 'entries', 'that', 'could', 'not', 'be', 'converted', 'to', 'numbersHelper', ';', 'Datagroup', 'description', ':', 'Helper', 'Woody', 'debris', 'dimensions', '(', 'broken', 'at', ')', ',', 'meter', 'broken', 'at', 'Woody', 'debris', 'dimensions', 'consist', 'of', 'base', 'diameter', ',', 'top', 'diameter', ',', 'and', 'length', '.'], ['Successional', 'age', 'of', 'a', 'forest', 'plot', 'Successional', 'stage', 'describes', 'the', 'amount', 'of', 'time', 'a', 'given', 'forest', 'had', 'to', 'grow', 'without', 'further', 'disturbance', '.'], ['CSPs', ':', 'Soil', 'fungal', 'metagenome', 'from', '12', 'CSPs', 'based', 'on', 'the', 'fungal', 'ITS', 'rDNA', 'pyrotags', '/datasets/397', 'ASCII', '1', 'column', ',', 'Operational', 'taxonomic', 'unit', '(', 'OTU', ')', '(', 'Taxon', ')', ',', 'Taxon', 'In', 'phylogeny', 'an', 'operational', 'taxonomic', 'unit', '(', 'OTU', ')', 'is', 'an', 'operational', 'definition', 'of', 'a', 'species', 'or', 'group', 'of', 'species', 'often', 'used', 'when', 'only', 'DNA', 'sequence', 'data', 'is', 'available', '.'], ['year', 'of', 'species', 'description', 'Global', 'unique', 'identifier', '(', 'global', 'unique', 'identifier', ')', ',', 'global', 'unique', 'identifier', 'Global', 'unique', 'identifier', 'for', 'the', 'respecive', 'species', 'provided', 'by', 'different', 'sources', 'for', 'taxonomic', 'affiliation', '.'], ['Ways', 'to', 'quantify', 'precipitation', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mmmeasured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ';', 'rainfall', 'amount', 'open', 'field', '(', 'vaisala', ')', 'mmmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'peak', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'of', 'the', 'five', 'highest', 'five', 'minute', 'intensities', 'open', 'field', '(', 'vaisala', ')', 'measured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mmmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'peak', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '(', 'am_t', ':', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mm', '--', 'rainfall', 'amount', '(', 'tipping-bucket', ')', '--', 'measured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', ')', 'millimeter', 'real', 'Precipitation', 'Precipitation', 'measured', 'at', 'the', 'climate', 'station', 'or', 'locally', 'within', 'sites', '.'], ['Compromise', 'solutions', 'tend', 'to', 'focus', 'agricultural', 'expansion', 'along', 'existing', 'transportation', 'corridors', 'and', 'in', 'already', 'disturbed', 'areas', '.'], ['total', 'sum', 'of', 'lipids', 'found', ';', ';', 'Wu', 'et', 'al.', ',', '2012', '(', 'see', 'metadata', 'sheet', ',', 'doi:10.1007/s10021-012-9533-3', ')', '(', 'derived', 'from', 'datagroup', ')', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', '(', 'Bacteria', ')', ',', 'nmol', 'g', 'dry', 'soil-1', 'Bacteria', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', '.'], ['Later', ',', 'Arion', 'vulgaris', 'slugs', '(', 'formerly', 'known', 'as', 'A.', 'lusitanicus', ';', 'Gastropoda', ':', 'Arionidae', ')', 'were', 'added', 'and', 'allowed', 'to', 'freely', 'choose', 'among', 'the', 'available', 'plant', 'species', '.'], ['Leaf', 'area', 'index', 'measured', 'above', 'the', 'planted', 'seedlings', '(', '1m', 'height', ')', 'in', 'each', 'subplot', 'Inclination', '(', 'Slope', ')', ',', 'Slope', 'Inclination', '``', 'is', 'the', 'angular', 'distance', 'of', 'the', 'orbital', 'plane', 'from', 'the', 'plane', 'of', 'reference', '(', 'usually', 'the', 'primary', 's', 'equator', 'or', 'the', 'ecliptic', ')', ',', 'normally', 'stated', 'in', 'degrees', 'degrees', '(', 'Wikipedia', ',', '2011', ')', '.'], ['These', 'areas', 'are', 'within', '300ft', 'of', ':', 'open', 'water', ',', 'inland', 'water', 'bodies', 'greater', 'than', '2', 'acres', 'in', 'size', ',', 'open', 'space', 'greater', 'than', '2', 'acres', ',', 'the', 'shoreline', '.'], ['We', 'summarize', 'the', 'process', 'and', 'results', 'for', 'a', 'large', 'set', 'of', 'the', 'species', 'of', 'two', 'speciose', 'subfamilies', 'of', 'ACG', 'skipper', 'butterflies', '(', 'Hesperiidae', ')', 'and', 'emphasize', 'the', 'effectiveness', 'of', 'barcoding', 'these', 'species', '(', 'which', 'are', 'often', 'difficult', 'and', 'time-consuming', 'to', 'identify', ')', '.'], ['(', 'Iridomyrmex', 'anceps', ')', ',', 'Iridomyrmex', 'anceps', '(', 'Iridomyrmex', 'anceps', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Crematogaster', 'cf', '.'], ['Secondly', ',', 'to', 'analyze', 'the', 'immunological', 'profile', 'in', 'both', 'earthworm', 'species', ',', 'the', 'activity', 'and', 'expression', 'of', 'lysozyme', ',', 'pattern', 'recognition', 'protein', 'CCF', ',', 'and', 'antimicrobial', 'proteins', 'with', 'hemolytic', 'function', ',', 'fetidin', 'and', 'lysenins', ',', 'have', 'been', 'assessed', '.'], ['We', 'note', 'that', 'A.', 'cerana', 'mtDNA', 'is', 'included', 'because', 'it', 'is', 'considered', 'a', 'potentially', 'invasive', 'honey', 'bee', 'species', 'and', 'monitoring', 'for', 'its', 'occurrence', 'is', 'in', 'practice', 'regionally', ',', 'including', 'in', 'Australia', ',', 'New', 'Zealand', 'and', 'the', 'USA', '.'], ['Source', ':', 'Last', 'updated', 'at', ':', '########', 'License', '-', 'Creative', 'Commons', 'Attribution', '4', 'CC-BY', 'download_json_1', 'id', 'id', 'integer', '#', 'integer', 'id', 'name', 'name', 'string', '#', 'string', 'name', 'parentlayerid', 'parentLayerId', 'integer', '#', 'integer', 'parentlayerid', 'defaultvisibility', 'defaultVisibility', 'boolean', '#', 'boolean', 'defaultvisibility', 'sublayerids', 'subLayerIds', 'string', '#', 'string', 'sublayerids', 'minscale', 'minScale', 'boolean', '#', 'boolean', 'minscale', 'maxscale', 'maxScale', 'boolean', '#', 'boolean', 'maxscale', 'data/download_json_1.csv', 'csv', 'original/download-json-1.json', 'original/download-json-1.json', 'json', 'application/json', '50778', 'original/wms-getcapabilities-2.html', 'original/wms-getcapabilities-2.html', 'html', 'text/html', '338470', 'agricultural', 'soil', 'analysis', 'arable', 'land', 'arable', 'land', 'groundwater', 'chemical', 'chemistry', 'continental', 'scale', 'earth', 'science', 'egdi', 'environment', 'europe', 'european', 'soil', 'analysis', 'forensic', 'chemistry', 'gemas', 'geochemical', 'geochemical', 'analysis', 'geochemical', 'mapping', 'geology', 'geoscientificinformation', 'grazing', 'land', 'groundwater', 'heavy', 'metals', 'ireland', 'land', 'lithosphere', 'mapping', 'metal', 'micka', 'pedosphere', 'science', 'soil', 'soil', 'nutrient', 'toxic', 'element', 'trace', 'element', 'water', 'geographic'], ['This', 'is', 'the', 'species', 'list', 'containing', 'bryophytes', '.'], ['Mean', 'density', 'of', 'litter', 'thrips', 'per', 'plots', 'in', 'the', 'tropics', 'and', 'subtropics', 'was', 'significantly', 'higher', 'than', 'that', 'in', 'the', 'temperate', 'region', '(', 'n=25', ',', 'p', '<', '0.05', ')', ',', 'but', 'the', 'average', 'density', 'was', 'not', 'significantly', 'different', 'between', 'tropical', 'and', 'subtropical', 'zones', '(', 'n=25', ',', 'p', '>', '0.05', ')', '.'], ['Soil', 'description', '(', 'according', 'to', '``', 'Bodenkundliche', 'Kartieranleitung', 'Kartieranleitung', ')', 'Basic', 'information', 'on', 'soil', 'properties', ',', 'according', 'to', '``', 'Eckelmann', ',', 'W.', ',', 'Sponagel', ',', 'H.', ',', 'Grottenthaler', ',', 'W.', ',', 'Hartmann', ',', 'J.', 'K.', ',', 'Hartwich', ',', 'R.', ',', 'Janetzko', ',', 'P.', ',', '...', '&', 'Traidl', ',', 'R.', '(', '2005', ')', '.'], ['This', 'is', 'the', 'best', 'estimate', 'of', 'the', 'total', 'number', 'of', 'species', 'in', 'Japanese', 'waters', 'and', 'indicates', 'that', 'more', 'than', '70', '%', 'of', 'Japan', 's', 'marine', 'biodiversity', 'remains', 'un-described', '.'], ['The', 'most', 'common', 'cause', 'is', 'snow', 'break', '(', '1', ')', ',', 'the', 'next', 'common', 'most', 'likely', 'is', 'being', 'crashed', 'by', 'a', 'fallen', 'tree', '(', '#ERROR!', '2', ')', '.'], ['Source', ':', 'Last', 'updated', 'at', ':', '3/6/2017', '[', 'License', '-', 'Creative', 'Commons', 'Attribution', '3', 'New', 'Zealand', '(', 'CC', 'BY', '3', 'NZ', ')', ']', '(', 'Other', 'biodiversity_vegetation_2002', 'lcdb2_name', 'LCDB2_NAME', 'string', '#', 'string', 'lcdb2_name', 'lcdb1_name', 'LCDB1_NAME', 'string', '#', 'string', 'lcdb1_name', 'gen_veg', 'GEN_VEG', 'string', '#', 'string', 'gen_veg', 'wetland', 'WETLAND', 'boolean', '#', 'boolean', 'wetland', 'minor_clsa', 'MINOR_CLSA', 'string', '#', 'string', 'minor_clsa', 'minor_clsb', 'MINOR_CLSB', 'string', '#', 'string', 'minor_clsb', 'minor_clsc', 'MINOR_CLSC', 'string', '#', 'string', 'minor_clsc', 'uncertain1', 'UNCERTAIN1', 'string', '#', 'string', 'uncertain1', 'uncertain2', 'UNCERTAIN2', 'string', '#', 'string', 'uncertain2', 'comments', 'COMMENTS', 'string', '#', 'string', 'comments', 'class_cor', 'CLASS_COR', 'string', '#', 'string', 'class_cor', 'bound_cor', 'BOUND_COR', 'string', '#', 'string', 'bound_cor', 'wetld_cor', 'WETLD_COR', 'string', '#', 'string', 'wetld_cor', 'field_com', 'FIELD_COM', 'string', '#', 'string', 'field_com', 'photo_1', 'PHOTO_1', 'string', '#', 'string', 'photo_1', 'photo1_id', 'PHOTO1_ID', 'string', '#', 'string', 'photo1_id', 'photo_east1', 'PHOTO_EAST1', 'integer', '#', 'integer', 'photo_east1', 'photo_nth1', 'PHOTO_NTH1', 'integer', '#', 'integer', 'photo_nth1', 'photo_2', 'PHOTO_2', 'string', '#', 'string', 'photo_2', 'photo2_id', 'PHOTO2_ID', 'string', '#', 'string', 'photo2_id', 'photo_east2', 'PHOTO_EAST2', 'integer', '#', 'integer', 'photo_east2', 'photo_nth2', 'PHOTO_NTH2', 'integer', '#', 'integer', 'photo_nth2', 'district', 'DISTRICT', 'string', '#', 'string', 'district', 'id', 'ID', 'integer', '#', 'integer', 'id', 'data/biodiversity_vegetation_2002.csv', 'csv', 'original/BIODIVERSITY_VEGETATION_2002.csv', 'original/BIODIVERSITY_VEGETATION_2002.csv', 'csv', 'text/csv', '3102121', 'original/BioVeg2002_read_me.txt', 'original/BioVeg2002_read_me.txt', 'txt', 'text/plain', '1609', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-1.zip', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-1.zip', 'zip', 'application/zip', '26642309', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-3.zip', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-3.zip', 'zip', 'application/zip', '22189678', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-4.zip', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-4.zip', 'zip', 'application/zip', '11987022', 'biodiversity', 'coastal', 'ecology', 'ecosystem', 'land', 'cover', 'land', 'use', 'sand', 'dune', 'terrestrial', 'vegetation', 'waikato', 'wetland', 'environment'], ['All', 'data', 'were', 'collected', 'with', 'direct', 'visual', 'observation', 'of', 'single', 'leaves', '.'], ['(', 'global', 'unique', 'identifier', ':', 'global', 'unique', 'identifier', ')', 'Global', 'unique', 'identifier', 'for', 'the', 'respecive', 'species', 'provided', 'by', 'different', 'sources', 'for', 'taxonomic', 'affiliation', '.'], ['(', 'event_start', ':', 'start', 'date', 'of', 'the', 'event', ')', 'Date', 'time', 'information', ',', 'given', 'as', 'year', 'or', 'as', 'date', 'or', 'as', 'date', 'time', '.'], ['Here', 'we', 'present', 'and', 'test', 'a', 'new', 'conceptual', 'model', 'describing', 'the', 'mechanisms', 'and', 'consequences', 'of', 'biodiversity', 'change', 'in', 'fragmented', 'landscapes', ',', 'identifying', 'the', 'fragmentation', 'threshold', 'as', 'a', 'first', 'step', 'in', 'a', 'positive', 'feedback', 'mechanism', 'that', 'has', 'the', 'capacity', 'to', 'impair', 'ecological', 'resilience', ',', 'and', 'drive', 'a', 'regime', 'shift', 'in', 'biodiversity', '.'], ['This', 'is', 'the', 'first', 'study', 'of', 'aquarium', 'trade', 'imports', 'to', 'compare', 'commercial', 'invoices', 'to', 'government', 'forms', 'and', 'provides', 'a', 'means', 'to', ',', 'routinely', 'and', 'in', 'real', 'time', ',', 'examine', 'the', 'biodiversity', 'of', 'the', 'trade', 'in', 'coral', 'reef', 'wildlife', 'species', '.'], ['I', 'analyze', 'how', 'the', 'amount', 'of', 'available', 'data', 'has', 'changed', 'through', 'time', 'and', 'the', 'consequent', 'changes', 'in', 'taxonomic', ',', 'spatial', ',', 'habitat', ',', 'and', 'climatic', 'representativeness', '.'], ['Bootless', 'Bay', 'lies', 'directly', 'south', 'of', 'Port', 'Moresby', ',', 'the', 'capital', 'of', 'Papua', 'New', 'Guinea', ',', 'and', 'experiences', 'the', 'highest', 'human', 'population', 'density', 'of', 'any', 'marine', 'area', 'in', 'the', 'country', '.']]\n"
          ]
        }
      ],
      "source": [
        "print(test_texts_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5I0Wpcwu2GK",
        "outputId": "a2295084-1159-4ea9-b0a4-bde545576cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quality: Density; Phenomena: Treatment; Quality: Dead; Environment: Garden; Organism: Seedling; Phenomena: growth; Quality: biomass; Environment: plant communities; Quality: species richness; Environment: tropical forest ecosystems \n",
            "\n",
            "Organism: honey bees \n",
            "\n",
            "Environment: soil \n",
            "\n",
            "Environment: riparian reserves; Environment: forest; Environment: riparian reserves; Matter: oil palm \n",
            "\n",
            "Organism: species \n",
            "\n",
            "Phenomena: precipitation; Quality: rainfall amount; Environment: field; Phenomena: rainfall; Quality: rainfall amount; Environment: field; Quality: average rainfall intensity; Environment: field; Quality: peak rainfall intensity; Environment: field; Quality: intensities; Environment: field; Quality: rainfall amount; Quality: average rainfall intensity; Quality: peak rainfall intensity; Quality: intensities; Environment: field; Quality: intensities; Phenomena: Precipitation; Phenomena: Precipitation \n",
            "\n",
            "Environment: forest; Environment: tropical forest landscape; Quality: area; Environment: canopy cover; Quality: species richness; Environment: canopy \n",
            "\n",
            "Environment: Soil; Quality: pH analyses; Quality: depth \n",
            "\n",
            "Organism: species \n",
            "\n",
            "Quality: volume; Quality: diameter \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for row in train_outputs[:10]:\n",
        "  print(row, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3vdOw46wUO8",
        "outputId": "296ed634-d010-4606-b826-166adeed6318"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('-- - 6 digit metal tags starting with 3 were also used for woody debris items -- the reference file linking metal tags to tree individual tags is called `` Tree stem reference list for the Comparative Study Sites ( CSPs ) ) ( neigh.label : label ID of neighbouring individual : We locate every tagged individual CWD piece .',\n",
              " 'Matter: woody debris items')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_inputs[11], train_outputs[11]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZtoHc0t7Rrh"
      },
      "source": [
        "# Training preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH6z2GHdtz09"
      },
      "source": [
        "We first load a ViT5 tokenizer and a pretrained model powered by Transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "c_s3KK_b-7gT"
      },
      "outputs": [],
      "source": [
        "#Create a tokenizer and a model supported by ViT5\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "# model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNJ20Y6Wt9yd"
      },
      "source": [
        "Define a function which converts data to tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gt4CQd1o6kyX"
      },
      "outputs": [],
      "source": [
        "#Function for tokenizing texts and labels\n",
        "def preprocess(examples):\n",
        "  model_inputs = tokenizer(\n",
        "      examples[\"inputs\"], max_length=512, truncation=True, padding=True\n",
        "  )\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(\n",
        "        examples[\"labels\"], max_length=512, truncation=True, padding=True\n",
        "    )\n",
        "  model_inputs[\"labels\"] = labels['input_ids']\n",
        "  model_inputs['input_ids'] = model_inputs['input_ids']\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZdVtLNIuDZV"
      },
      "source": [
        "Define a dictionary that holds inputs and their corresponding labels\n",
        "\n",
        "Create a dataset from that dictionary and apply the tokenization process to every data sample with map function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dRcl5K44W1m6"
      },
      "outputs": [],
      "source": [
        "#Tokenise dataset\n",
        "def dict_to_dataset(inputs, outputs):\n",
        "  dict_obj = {'inputs':inputs, 'labels':outputs}\n",
        "  dataset = Dataset.from_dict(dict_obj)\n",
        "  tokenized_datasets = dataset.map(preprocess, batched=True, num_proc=8)\n",
        "\n",
        "  return tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985,
          "referenced_widgets": [
            "6dd1f2605cfd4d40ba894e5c9f29255a",
            "a87b4753034440fab12c9aef88e4a65e",
            "53762e63ddb14378ab6347cfbbcdf2eb",
            "07f63ba8e0204cd987a30927c3c7bf54",
            "923d4b4e8e0a450388c53bfa3691592c",
            "34779fe2fcac4f3c9f925f12d83ab174",
            "dbc6ea78d1704f58ae4d8248847fbb89",
            "1807a557d3db431d90926ea61a1853a3",
            "8ba39d09760e4f8e91ea8640d8e9233c",
            "ae20d94212114a5b921a15a26c377402",
            "b7e4bae75624447aa8021cb0b89aeb49",
            "5ef1c56bb5904ed4b39c8c94e5960fb4",
            "c304e72bda2d4397b99b072027a8d960",
            "fc92bc9cd85a4c2484802990f86f437d",
            "3679027768db49dc961580d1efb904c3",
            "d7a2d62fa4b1414e9edaeeb8a4519476",
            "1cb29d4334a342d2a868c2fd8bd9a185",
            "ae23cf8b433240adae92dbcfc8a3c475",
            "f2a922c40f25457290be9ffe17ec401c",
            "7aac12116a4b496b9ce6dd24bde26378",
            "29fb2306d6404d4e8a517e69b3310da4",
            "517ecfa0f50e45f4be35081c052d6c1c",
            "55c345ce06a148dfbeb44ea35f0ce8bd",
            "7479ac28ec80431ab399cbfe7b7bb7c0",
            "7928e1b2353745138f0a78a9c0b9947e",
            "9b02de5b63f54267be94812b5f301194",
            "5a4edf2b61f742c3b12bbbe314002c44",
            "f847c9b7ed2a49a198e79f8ee0cc2235",
            "ab89ace79da646a2b0f2e624f9d2853a",
            "039fc2da5d194b17b14c448ec256d733",
            "e3d572e368014fc08bd332d72f0ddade",
            "45b35b4492d44a59a6ed50033df03029",
            "724a2e6ae2bb47958b3fc70aca0b62b7"
          ]
        },
        "id": "wFZajnqMxSvi",
        "outputId": "ee29a069-601e-46f7-9594-c18573c1968b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=8):   0%|          | 0/1776 [00:00<?, ? examples/s]/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=8): 100%|██████████| 1776/1776 [00:00<00:00, 2083.74 examples/s]\n",
            "Map (num_proc=8):   0%|          | 0/215 [00:00<?, ? examples/s]/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  13%|█▎        | 27/215 [00:00<00:00, 197.42 examples/s]/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8): 100%|██████████| 215/215 [00:00<00:00, 563.06 examples/s]\n"
          ]
        }
      ],
      "source": [
        "train_tokenized = dict_to_dataset(train_inputs, train_outputs)\n",
        "val_tokenized = dict_to_dataset(val_inputs, val_outputs)\n",
        "# test_tokenized = dict_to_dataset(test_inputs, test_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "B0fxK-AbcVOi"
      },
      "outputs": [],
      "source": [
        "logging_dir=\"./log\"\n",
        "logging_dir_name=\"training_logs\"\n",
        "logging_dir_path = os.path.join(logging_dir, logging_dir_name)\n",
        "os.makedirs(logging_dir_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LlQQmunecb14"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yMURgah0d5GT"
      },
      "outputs": [],
      "source": [
        "from seqeval import metrics as seqeval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lv-sEFRvdm4N"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "  predictions, labels = p.predictions, p.label_ids\n",
        "  flat_predictions = [label for sentence_labels in predictions for label in sentence_labels]\n",
        "  flat_labels = [label for sentence_labels in labels for label in sentence_labels]\n",
        "  accuracy = seqeval_metrics.accuracy_score([flat_labels], [flat_predictions])\n",
        "  return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks2ubpzuuVm9"
      },
      "source": [
        "Set training arguments for training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "96TTbpQKW1pY"
      },
      "outputs": [],
      "source": [
        "#Arguments for training model\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
        "training_args = Seq2SeqTrainingArguments('../Model Data/t5-small/t5-small_001',\n",
        "                                      report_to = 'wandb',\n",
        "                                      do_train=True,\n",
        "                                      do_eval=True,\n",
        "                                      num_train_epochs=10,\n",
        "                                      learning_rate=2e-5,\n",
        "                                      warmup_ratio=0.00,\n",
        "                                      weight_decay=0.01,\n",
        "                                      per_device_train_batch_size=4,\n",
        "                                      per_device_eval_batch_size=4,\n",
        "\n",
        "                                      logging_steps=50,\n",
        "                                      group_by_length=True,\n",
        "                                      # save_strategy=\"epoch\",\n",
        "                                      save_total_limit=0,\n",
        "                                      #eval_steps=1,\n",
        "                                      evaluation_strategy=\"epoch\",\n",
        "                                      # evaluation_strategy=\"no\",\n",
        "                                      # fp16=True,\n",
        "                                      # eval_accumulation_steps=50\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_VXedIdualN"
      },
      "source": [
        "Make sure to push the model to GPU for optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoaX4kSBJPoR",
        "outputId": "67f04d16-aaf7-45d0-c740-1fc56bba2f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt7i-ijz7lcF"
      },
      "source": [
        "# Train Named Entity Recognition model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "WcPJJxYddB2r",
        "outputId": "de4fd213-5762-4f49-fa5f-038cf4b32c11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshannen\u001b[0m (\u001b[33mshannen-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/nlpbiodiv2023/CS198Repository/Notebooks/wandb/run-20231211_202442-jfr6udnh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shannen-team/huggingface/runs/jfr6udnh' target=\"_blank\">efficient-armadillo-5</a></strong> to <a href='https://wandb.ai/shannen-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shannen-team/huggingface' target=\"_blank\">https://wandb.ai/shannen-team/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shannen-team/huggingface/runs/jfr6udnh' target=\"_blank\">https://wandb.ai/shannen-team/huggingface/runs/jfr6udnh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2220' max='2220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2220/2220 15:27, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>0.670642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.165600</td>\n",
              "      <td>0.428507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>0.330167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.108700</td>\n",
              "      <td>0.274708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.089900</td>\n",
              "      <td>0.228207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.089800</td>\n",
              "      <td>0.198058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.073100</td>\n",
              "      <td>0.176359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.084800</td>\n",
              "      <td>0.167968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.067700</td>\n",
              "      <td>0.164274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>0.162634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2220, training_loss=0.41993976681082096, metrics={'train_runtime': 938.4612, 'train_samples_per_second': 18.925, 'train_steps_per_second': 2.366, 'total_flos': 2403670394142720.0, 'train_loss': 0.41993976681082096, 'epoch': 10.0})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# #Procession of training model\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "JH1E6_y4Msky",
        "outputId": "56580830-adb7-423c-d160-6926a6d764cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3359127938747406,\n",
              " 'eval_runtime': 3.2573,\n",
              " 'eval_samples_per_second': 66.006,\n",
              " 'eval_steps_per_second': 8.289,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(eval_dataset=val_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5voTJS1tuWGC"
      },
      "outputs": [],
      "source": [
        "# Assuming that 'model' is your Seq2Seq model\n",
        "model.save_pretrained(os.path.join(model_path, \"final\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlAOTOIYwetK"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8i2dS_OulI1"
      },
      "source": [
        "Load fine-tuned model stored in Google Drive with a Tokenizer by ViT5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JB0w5o8kUgdv"
      },
      "outputs": [],
      "source": [
        "#Load model saved as a checkpoint\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\"../Model Data/t5-small/t5-small_001/checkpoint-1000\")\n",
        "model = trainer.model\n",
        "# model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWniPKChpR1a",
        "outputId": "d306f8bb-8668-4ee2-b733-52891cf1d2e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60506624"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Total number of trainable parameters\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqOO3wPdbW_4",
        "outputId": "e5347674-7a8e-48dd-c03e-06057480e341"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxLi-lwz91HZ"
      },
      "source": [
        "To use the model at its best, make sure the data fed to the model is word-level,\n",
        " if it's not, simply use an RDR-Segmenter!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-uR8DpBusQV"
      },
      "source": [
        "The cell below helps produce target text with 'generate' method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvC-izf5Uhmp",
        "outputId": "044d0d13-3b16-45b4-b703-7381806c3427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1636,    37, 21965,  7322,    19,   787,    57,   309,  1713,  3316,\n",
              "           448,  2990,    55,  4505,     3,   102,   834,    23,     2,   357,\n",
              "             3,     6,    28,     3,   102,   834,    23,  9085,     8,  5237,\n",
              "         15025,    13,     8,    34,   107,  3244,     3,     5,     1]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = train_inputs[100]\n",
        "# sentence = eval_input_sequences[23]\n",
        "encoding = tokenizer(sentence, return_tensors=\"pt\", max_length=512)\n",
        "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "VwmwTJuaTNI-"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1673\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1657\u001b[0m         input_ids,\n\u001b[1;32m   1658\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1670\u001b[0m     )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1672\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2521\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2521\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1746\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1746\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1761\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1113\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1099\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1100\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         output_attentions,\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:694\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    704\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:601\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    592\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m ):\n\u001b[1;32m    600\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 601\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    611\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:572\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    570\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m*\u001b[39m layer_head_mask\n\u001b[0;32m--> 572\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m unshape(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    573\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo(attn_output)\n\u001b[1;32m    575\u001b[0m present_key_value_state \u001b[38;5;241m=\u001b[39m (key_states, value_states) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m use_cache) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_sLITdWTtPN",
        "outputId": "f7130fb0-7818-4198-b715-f13223b7da47"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'outputs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutputs\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ],
      "source": [
        "print(outputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zITKrz-VTftL",
        "outputId": "3836e2c6-3ea3-4787-e86c-3461c4b1cd6d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'outputs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43moutputs\u001b[49m[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults: \u001b[39m\u001b[38;5;124m\"\u001b[39m, labels)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_outputs[\u001b[38;5;241m50\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ],
      "source": [
        "labels = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "print(\"Results: \", labels)\n",
        "print(\"Actual labels:\", train_outputs[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ZjrVUiUyWUfz"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWu-IC7cvBQ2"
      },
      "source": [
        "'word_labels' takes into account two parameters 'sentence' and 'labels' to calculate the correct BIO label and map them to a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "AeSzeA5XWW-P"
      },
      "outputs": [],
      "source": [
        "def word_labels(sentence, labels):\n",
        "  predictions = [\"O\" for i in range(len(sentence.split()))]\n",
        "  if labels != '':\n",
        "    list_labels = labels.split(\";\")\n",
        "    sent = sentence.split()\n",
        "\n",
        "    start = 0\n",
        "    for i in range(len(list_labels)):\n",
        "      sub_list = list_labels[i].split(\":\")\n",
        "      # print(list_labels[i])\n",
        "      # print(sub_list)\n",
        "      class_entity = sub_list[0].strip() # location, organization, age,...\n",
        "      named_entity = sub_list[1].strip().lower() # Ha Noi, London, 433,...\n",
        "      named_entity_element = named_entity.split() # Ha, Noi, London, 433, Soc Trang,...\n",
        "\n",
        "      flist = []\n",
        "      for i in range(len(named_entity_element)):\n",
        "        if named_entity_element[i][-1] == ',':\n",
        "          entity1 = named_entity_element[i][0:len(named_entity_element[i])-1]\n",
        "          entity2 = \",\"\n",
        "          flist.append(entity1)\n",
        "          flist.append(entity2)\n",
        "        else:\n",
        "          flist.append(named_entity_element[i])\n",
        "\n",
        "      named_entity_element = flist\n",
        "      for i in range(len(named_entity_element)):\n",
        "        try:\n",
        "          findex = sent.index(named_entity_element[i], start)\n",
        "          start = findex + 1\n",
        "          f_class = \"\"\n",
        "          if i == 0:\n",
        "            f_class = \"B-\" + class_entity\n",
        "          else:\n",
        "            f_class = \"I-\" + class_entity\n",
        "          predictions[findex] = f_class\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do934z0gQ_C1"
      },
      "source": [
        "# reverse the subword tokens to their real words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG1eia3Me5aR"
      },
      "source": [
        "Load dataset for devaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "pUYALXFR8UKO"
      },
      "outputs": [],
      "source": [
        "# #Read test set\n",
        "# evalWord = [json.loads(line) for line in open('gdrive/MyDrive/Ct550/word/test_word.json', 'r', encoding='utf-8')]\n",
        "# evalWordData = pd.DataFrame(evalWord)\n",
        "# evalWordData = evalWordData.rename(columns={'tags':'target_text', 'words':'source_text'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf545NJ0vXGe"
      },
      "source": [
        "Create lists of input and output sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "3n06Gjyy8tgn"
      },
      "outputs": [],
      "source": [
        "# #Create a list of texts\n",
        "eval_input_data = test_texts_c\n",
        "test_inputs = []\n",
        "\n",
        "for sentence in eval_input_data:\n",
        "  test_inputs.append(\" \".join(sentence))\n",
        "\n",
        "# #Create a list of targets\n",
        "eval_output_data = test_tags_c\n",
        "test_outputs = []\n",
        "\n",
        "for sentence in eval_output_data:\n",
        "  test_outputs.append(\" \".join(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YfJtTui_6p8l",
        "outputId": "cbf46236-7077-4df8-96f3-eed0af0ade2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Or the allometries are not used to extrapolate the biomass of the first item ( for example a tree dbh ) . )'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# eval_input_sequences\n",
        "test_inputs[8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMlAeuKta0ZH",
        "outputId": "d6837864-76b5-4591-c392-06570a44b3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3tHRvDPvcQl"
      },
      "source": [
        "The process below predicts targets for 2k data samples in the dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "YC8AH5ItnuWw"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "references = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppvx9TdCpFA8",
        "outputId": "b8b07e94-a7fd-4e17-f3fe-d4cfed81fd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chlamydia caviae infection alters abundance but not composition of the guinea pig vaginal microbiota In humans , the vaginal microbiota is thought to be the first line of defense again pathogens including Chlamydia trachomatis .\n"
          ]
        }
      ],
      "source": [
        "print(test_inputs[47])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZFWc1l-CIEJ",
        "outputId": "770923ac-589e-4ed0-900f-a10cef0bebcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "Error in iteration 7: list index out of range\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "Error in iteration 27: list index out of range\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "Error in iteration 33: list index out of range\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "Error in iteration 65: list index out of range\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "Error in iteration 97: list index out of range\n",
            "98\n",
            "99\n",
            "Error in iteration 99: list index out of range\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "Error in iteration 104: list index out of range\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "Error in iteration 113: list index out of range\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "Error in iteration 121: list index out of range\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "Error in iteration 140: list index out of range\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "Error in iteration 144: list index out of range\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "Error in iteration 157: list index out of range\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "Error in iteration 177: list index out of range\n",
            "178\n",
            "Error in iteration 178: list index out of range\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n"
          ]
        }
      ],
      "source": [
        "# for i in test_inputs:\n",
        "for i in range(len(test_inputs)):\n",
        "  print (i)\n",
        "  sentence = test_inputs[i]\n",
        "  tokenized_input = tokenizer(sentence, return_tensors='pt', max_length=512)\n",
        "  input_ids = tokenized_input['input_ids'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  attention_mask = tokenized_input['attention_mask'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  try:\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids, attention_mask=attention_mask, max_length=512\n",
        "        )\n",
        "        # print(outputs[0])\n",
        "        labels = tokenizer.decode(outputs[0], clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
        "        # print(\"prev sentence:\", sentence)\n",
        "        # print(\"prev_label:\", labels)\n",
        "        sentence = unidecode(sentence).lower()\n",
        "        labels = unidecode(labels)\n",
        "        # print(\"decoded_sentence:\", sentence)\n",
        "        # print(\"decoded_label:\", labels)\n",
        "        flabels = word_labels(sentence, labels)\n",
        "        if len(flabels) != len(test_outputs[i].split()):\n",
        "          print(f\"Unequal prediction and reference!\")\n",
        "          continue\n",
        "        predictions.append(flabels)\n",
        "        references.append(test_outputs[i].split())\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Error in iteration {i}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Or the allometries are not used to extrapolate the biomass of the first item ( for example a tree dbh ) . )\n",
            "117.8998 118.1483 29.2852 29.10178 1/7/2008 ######## no organisms , only vegetated and bare plots no organisms , only vegetated and bare plots tscholten pkuehn cgeissler CSPs : Kinetic energy of raindrops in the CSPs : characteristics of rain events Rain was captured in open field and in vegetated conditions parallel to measurements in the Comparative study plots ( CSPs ) .\n",
            "We hypothesize that , after extraction of variation that is explained by location and land-use type , soil properties still explain significant proportions of variation in the abundance and diversity of soil biota .\n"
          ]
        }
      ],
      "source": [
        "# List index out of range error\n",
        "print(test_inputs[8])\n",
        "print(test_inputs[36])\n",
        "print(test_inputs[43])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O O O O O O O O O B-Quality O O O O O O O O B-Organism O O O O\n",
            "O O O O O O O B-Organism O O O O O O O O O O O O O O O O O O O B-Quality I-Quality O B-Matter O O O O O O B-Phenomena I-Phenomena B-Matter O O O O B-Environment O O O O O O O O O O O O O O O O\n",
            "O O O O O O O O O O O O O O O O O B-Environment O O O O O O O O O B-Quality O O O B-Environment O O\n"
          ]
        }
      ],
      "source": [
        "print(test_outputs[8])\n",
        "print(test_outputs[36])\n",
        "print(test_outputs[43])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PwKvxL-mOZj",
        "outputId": "8b568b54-b7b6-4fe9-b2c1-683702a4aecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Phenomena', 'I-Phenomena', 'O', 'O', 'B-Environment', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'O', 'O', 'B-Organism', 'B-Quality', 'I-Quality', 'O']\n",
            "['B-Quality', 'I-Quality', 'I-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'I-Organism', 'O', 'O', 'B-Organism', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'B-Location', 'I-Location', 'I-Location', 'B-Location', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Location', 'I-Location', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Environment', 'I-Environment', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Environment', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Environment', 'I-Environment', 'I-Environment', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Matter', 'O']\n"
          ]
        }
      ],
      "source": [
        "for row in references[:10]:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjbp1ETk5OF",
        "outputId": "87c85879-f062-4d1c-b33c-e4eeac839328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'I-Organism', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'I-Organism', 'I-Organism', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "for row in predictions[:10]:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvBpg0vNapMe"
      },
      "source": [
        "# resultssss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr0HZVnvmX-"
      },
      "source": [
        "Use seqeval framework introduced to calculate scores F1/precision/recall for every class entity and overall score for model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJFXFngWatOH",
        "outputId": "2191362b-d6f1-4485-db09-bbca65149062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.3581\n",
            "Recall: 0.1470\n",
            "F1-Score: 0.2085\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   Environment       0.12      0.01      0.01       140\n",
            "      Location       0.00      0.00      0.00        20\n",
            "        Matter       0.00      0.00      0.00        50\n",
            "      Organism       0.40      0.27      0.32       229\n",
            "Organism count       0.00      0.00      0.00         0\n",
            "     Organisms       0.00      0.00      0.00         0\n",
            "     Phenomena       0.00      0.00      0.00        54\n",
            "       Quality       0.33      0.19      0.24       262\n",
            "\n",
            "     micro avg       0.36      0.15      0.21       755\n",
            "     macro avg       0.11      0.06      0.07       755\n",
            "  weighted avg       0.26      0.15      0.18       755\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/nlpbiodiv2023/.local/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "precision = precision_score(references, predictions)\n",
        "recall = recall_score(references, predictions)\n",
        "f1 = f1_score(references, predictions)\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "\n",
        "# You can also print a detailed classification report\n",
        "print(classification_report(references, predictions))\n",
        "\n",
        "# result = seqeval.compute(predictions=predictions, references=references)\n",
        "# resultb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8fmt4UDrG60",
        "outputId": "5065bf98-72ad-49a4-fd1a-e4582ecb31d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203\n"
          ]
        }
      ],
      "source": [
        "print(len(references))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "039fc2da5d194b17b14c448ec256d733": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f63ba8e0204cd987a30927c3c7bf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae20d94212114a5b921a15a26c377402",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e4bae75624447aa8021cb0b89aeb49",
            "value": " 1918/1918 [00:03&lt;00:00, 665.54 examples/s]"
          }
        },
        "1807a557d3db431d90926ea61a1853a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb29d4334a342d2a868c2fd8bd9a185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29fb2306d6404d4e8a517e69b3310da4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34779fe2fcac4f3c9f925f12d83ab174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3679027768db49dc961580d1efb904c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29fb2306d6404d4e8a517e69b3310da4",
            "placeholder": "​",
            "style": "IPY_MODEL_517ecfa0f50e45f4be35081c052d6c1c",
            "value": " 240/240 [00:00&lt;00:00, 429.03 examples/s]"
          }
        },
        "45b35b4492d44a59a6ed50033df03029": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517ecfa0f50e45f4be35081c052d6c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53762e63ddb14378ab6347cfbbcdf2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1807a557d3db431d90926ea61a1853a3",
            "max": 1918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ba39d09760e4f8e91ea8640d8e9233c",
            "value": 1918
          }
        },
        "55c345ce06a148dfbeb44ea35f0ce8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7479ac28ec80431ab399cbfe7b7bb7c0",
              "IPY_MODEL_7928e1b2353745138f0a78a9c0b9947e",
              "IPY_MODEL_9b02de5b63f54267be94812b5f301194"
            ],
            "layout": "IPY_MODEL_5a4edf2b61f742c3b12bbbe314002c44"
          }
        },
        "5a4edf2b61f742c3b12bbbe314002c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef1c56bb5904ed4b39c8c94e5960fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c304e72bda2d4397b99b072027a8d960",
              "IPY_MODEL_fc92bc9cd85a4c2484802990f86f437d",
              "IPY_MODEL_3679027768db49dc961580d1efb904c3"
            ],
            "layout": "IPY_MODEL_d7a2d62fa4b1414e9edaeeb8a4519476"
          }
        },
        "6dd1f2605cfd4d40ba894e5c9f29255a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a87b4753034440fab12c9aef88e4a65e",
              "IPY_MODEL_53762e63ddb14378ab6347cfbbcdf2eb",
              "IPY_MODEL_07f63ba8e0204cd987a30927c3c7bf54"
            ],
            "layout": "IPY_MODEL_923d4b4e8e0a450388c53bfa3691592c"
          }
        },
        "724a2e6ae2bb47958b3fc70aca0b62b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7479ac28ec80431ab399cbfe7b7bb7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f847c9b7ed2a49a198e79f8ee0cc2235",
            "placeholder": "​",
            "style": "IPY_MODEL_ab89ace79da646a2b0f2e624f9d2853a",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "7928e1b2353745138f0a78a9c0b9947e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039fc2da5d194b17b14c448ec256d733",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d572e368014fc08bd332d72f0ddade",
            "value": 240
          }
        },
        "7aac12116a4b496b9ce6dd24bde26378": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ba39d09760e4f8e91ea8640d8e9233c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "923d4b4e8e0a450388c53bfa3691592c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b02de5b63f54267be94812b5f301194": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b35b4492d44a59a6ed50033df03029",
            "placeholder": "​",
            "style": "IPY_MODEL_724a2e6ae2bb47958b3fc70aca0b62b7",
            "value": " 240/240 [00:00&lt;00:00, 289.67 examples/s]"
          }
        },
        "a87b4753034440fab12c9aef88e4a65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34779fe2fcac4f3c9f925f12d83ab174",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc6ea78d1704f58ae4d8248847fbb89",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "ab89ace79da646a2b0f2e624f9d2853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae20d94212114a5b921a15a26c377402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae23cf8b433240adae92dbcfc8a3c475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7e4bae75624447aa8021cb0b89aeb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c304e72bda2d4397b99b072027a8d960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb29d4334a342d2a868c2fd8bd9a185",
            "placeholder": "​",
            "style": "IPY_MODEL_ae23cf8b433240adae92dbcfc8a3c475",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "d7a2d62fa4b1414e9edaeeb8a4519476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc6ea78d1704f58ae4d8248847fbb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3d572e368014fc08bd332d72f0ddade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2a922c40f25457290be9ffe17ec401c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f847c9b7ed2a49a198e79f8ee0cc2235": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc92bc9cd85a4c2484802990f86f437d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a922c40f25457290be9ffe17ec401c",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aac12116a4b496b9ce6dd24bde26378",
            "value": 240
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
