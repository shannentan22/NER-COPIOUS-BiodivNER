{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"t5-small\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Vslp-YSsLj"
      },
      "source": [
        "# Libraries installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4X12ofdmpgv"
      },
      "source": [
        "Install Transformers libaries, framework seqeval, some extensions: unidecode for formatting accent language, datasets for creating a Dataset,..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TEFje_FCy_hh"
      },
      "outputs": [],
      "source": [
        "# #Install required libraries\n",
        "# !pip install datasets transformers evaluate seqeval unidecode google.colab\n",
        "# !pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJnMSNd7Zsjg"
      },
      "source": [
        "## WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sKgmGqjWsDD",
        "outputId": "6bcfc052-ae70-4092-d72d-d80c0a14333f"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb\n",
        "# !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUvcGfo9ZGZU",
        "outputId": "3efa92b4-6232-4225-933f-899830fb56ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VK3L9ZKZJuK",
        "outputId": "62a2c2e4-9b67-4429-e0c6-5fd8289bc7dd"
      },
      "outputs": [],
      "source": [
        "# !pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xr1TdcUHZOQT"
      },
      "outputs": [],
      "source": [
        "# import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxYN1xRnZXwY",
        "outputId": "dd67e053-8a22-492e-c282-db913bdacd90"
      },
      "outputs": [],
      "source": [
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8ickZFYZgPJ",
        "outputId": "9ffa9e35-04e3-4d1e-927c-dc2f7e4d45b8"
      },
      "outputs": [],
      "source": [
        "# %env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyIQ855Mm6hO"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nYQ2MGLYW6-X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl.metadata\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.35.2)\n",
            "Collecting evaluate\n",
            "  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: seqeval in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)\n",
            "Collecting unidecode\n",
            "  Obtaining dependency information for unidecode from https://files.pythonhosted.org/packages/e4/63/7685ef40c65aba621ccd2524a24181bf11f0535ab1fdba47e40738eacff6/Unidecode-1.3.7-py3-none-any.whl.metadata\n",
            "  Downloading Unidecode-1.3.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.23.5)\n",
            "Collecting pyarrow>=8.0.0 (from datasets)\n",
            "  Obtaining dependency information for pyarrow>=8.0.0 from https://files.pythonhosted.org/packages/d4/f0/607f50ec87ac4775d6124855ae6be2c48bab58aa0a660ccd46e9af52bcd9/pyarrow-14.0.1-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading pyarrow-14.0.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Obtaining dependency information for dill<0.3.8,>=0.3.0 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/b7/3a/74a609706ef4430fe6d041a3b8d209882c15440b695e373fe26d48c6f35c/xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/e7/41/96ac938770ba6e7d5ae1d8c9cafebac54b413549042c6260f0d0a6ec6622/multiprocess-0.70.15-py311-none-any.whl.metadata\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2023.9.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\shann\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.9.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\shann\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\shann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "   ---------------------------------------- 0.0/521.2 kB ? eta -:--:--\n",
            "   ---------------------- ----------------- 297.0/521.2 kB 6.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 521.2/521.2 kB 4.6 MB/s eta 0:00:00\n",
            "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "   ---------------------------------------- 0.0/84.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 84.1/84.1 kB 4.6 MB/s eta 0:00:00\n",
            "Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
            "   ---------------------------------------- 0.0/235.5 kB ? eta -:--:--\n",
            "   ------------------------------------- - 225.3/235.5 kB 14.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 235.5/235.5 kB 4.8 MB/s eta 0:00:00\n",
            "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "Downloading pyarrow-14.0.1-cp311-cp311-win_amd64.whl (24.6 MB)\n",
            "   ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.4/24.6 MB 13.9 MB/s eta 0:00:02\n",
            "   - -------------------------------------- 1.0/24.6 MB 10.1 MB/s eta 0:00:03\n",
            "   - -------------------------------------- 1.0/24.6 MB 11.0 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 1.3/24.6 MB 7.4 MB/s eta 0:00:04\n",
            "   -- ------------------------------------- 1.6/24.6 MB 7.9 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 2.0/24.6 MB 8.0 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 2.4/24.6 MB 8.5 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 2.8/24.6 MB 8.6 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 3.4/24.6 MB 8.7 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 3.8/24.6 MB 8.9 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 4.2/24.6 MB 9.0 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 4.8/24.6 MB 9.0 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 5.3/24.6 MB 9.3 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 5.7/24.6 MB 9.1 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 6.3/24.6 MB 9.4 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 6.8/24.6 MB 9.5 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 7.4/24.6 MB 9.5 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 7.8/24.6 MB 9.5 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 8.3/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 8.7/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 9.2/24.6 MB 9.7 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 9.8/24.6 MB 9.8 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 10.3/24.6 MB 9.8 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 10.6/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 11.0/24.6 MB 9.4 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 11.5/24.6 MB 9.8 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 11.8/24.6 MB 9.9 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 12.2/24.6 MB 9.8 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 12.6/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 13.0/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 13.4/24.6 MB 9.5 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 13.9/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 14.5/24.6 MB 9.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 14.7/24.6 MB 9.5 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 15.1/24.6 MB 9.2 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 15.4/24.6 MB 9.1 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 15.9/24.6 MB 8.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 16.1/24.6 MB 8.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 16.4/24.6 MB 8.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 16.8/24.6 MB 8.5 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 17.0/24.6 MB 8.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 17.2/24.6 MB 8.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 17.2/24.6 MB 8.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 17.2/24.6 MB 8.4 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 18.2/24.6 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 18.5/24.6 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 18.9/24.6 MB 7.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 19.2/24.6 MB 7.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 19.4/24.6 MB 7.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 19.8/24.6 MB 7.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 20.0/24.6 MB 7.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 20.4/24.6 MB 7.1 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 20.6/24.6 MB 7.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 20.8/24.6 MB 7.0 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 21.1/24.6 MB 7.0 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 21.4/24.6 MB 6.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 21.7/24.6 MB 6.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 21.9/24.6 MB 6.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.2/24.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.4/24.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.6/24.6 MB 6.5 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 22.8/24.6 MB 6.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 23.0/24.6 MB 6.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 23.1/24.6 MB 6.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 23.3/24.6 MB 6.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.5/24.6 MB 5.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.7/24.6 MB 5.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.8/24.6 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.0/24.6 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.1/24.6 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.1/24.6 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.1/24.6 MB 5.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.1/24.6 MB 5.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.1/24.6 MB 5.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.1/24.6 MB 5.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.6/24.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 24.6/24.6 MB 3.2 MB/s eta 0:00:00\n",
            "Using cached multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
            "Installing collected packages: xxhash, unidecode, pyarrow-hotfix, pyarrow, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-14.0.1 pyarrow-hotfix-0.6 responses-0.18.0 unidecode-1.3.7 xxhash-3.4.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#Import libraries to project\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "import os\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7TIOIRBnCJj"
      },
      "source": [
        "Mount Google Drive to Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we3vliI84wF9",
        "outputId": "17840ab4-b983-4b53-ff39-4f9c0a184e3c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Mount Drive to Colab\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# #Mount Drive to Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jWsOi2IS56c"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A34esVOtGjO"
      },
      "source": [
        "Read training set from dataset stored in Google Drive.\n",
        "Create a list of input and output sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aPW44SkrzZTe"
      },
      "outputs": [],
      "source": [
        "#Read datasets\n",
        "\n",
        "root_data_dir = \"../Datasets/NER/BiodivNER\"\n",
        "\n",
        "dataset = \"train\"\n",
        "train_csv_file_path = \"train.csv\"\n",
        "val_csv_file_path = \"dev.csv\"\n",
        "test_csv_file_path = \"test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UEKJDG3_qlIY"
      },
      "outputs": [],
      "source": [
        "def loadData(csv_file_path):\n",
        "  dataset_path = os.path.join(root_data_dir, csv_file_path)\n",
        "  data = pd.read_csv(dataset_path, encoding=\"utf-8\")\n",
        "  data = data.fillna(method=\"ffill\")\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "aKclhjBhqprC"
      },
      "outputs": [],
      "source": [
        "data = loadData(train_csv_file_path)\n",
        "val_data = loadData(val_csv_file_path)\n",
        "test_data = loadData(test_csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "U8FCpm3Kqoxm"
      },
      "outputs": [],
      "source": [
        "class SentenceGetter(object):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                        s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbdAPQtzsLJp",
        "outputId": "6ceed375-be32-44e0-bd19-03cf38e46087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('bottom', 'O'), ('board', 'O'), ('debris', 'O'), (',', 'O'), ('frames', 'O'), (',', 'O'), ('landing', 'O'), ('platforms', 'O'), (')', 'O'), (',', 'O'), ('and', 'O'), ('isolates', 'O'), ('of', 'O'), ('microbes', 'O'), (',', 'O'), ('parasites', 'O'), ('and', 'O'), ('pathogens', 'O'), ('from', 'O'), ('honey', 'B-Organism'), ('bees', 'I-Organism'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxEW9UXosLxX",
        "outputId": "9540bba9-343d-4489-9aaa-6395f74e1803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('However', 'O'), (',', 'O'), ('the', 'O'), ('lack', 'O'), ('of', 'O'), ('correlation', 'O'), ('between', 'O'), ('dung', 'O'), ('beetle', 'O'), ('community', 'B-Environment'), ('characteristics', 'O'), ('and', 'O'), ('dung', 'O'), ('removal', 'O'), ('highlights', 'O'), ('the', 'O'), ('need', 'O'), ('for', 'O'), ('further', 'O'), ('research', 'O'), ('into', 'O'), ('spatial', 'O'), ('variation', 'O'), ('in', 'O'), ('biodiversityÃ¢â\\x82¬â\\x80\\x9cecosystem', 'O'), ('function', 'O'), ('relationships', 'O'), ('and', 'O'), ('how', 'O'), ('the', 'O'), ('results', 'O'), ('of', 'O'), ('such', 'O'), ('studies', 'O'), ('are', 'O'), ('affected', 'O'), ('by', 'O'), ('methodological', 'O'), ('choices', 'O'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter_val = SentenceGetter(val_data)\n",
        "sentences_val = getter_val.sentences\n",
        "sent_val = getter_val.get_next()\n",
        "print(sent_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMgWbWdusNmT",
        "outputId": "67729016-9793-4e40-db80-f71be1113bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('The', 'O'), ('primacy', 'O'), ('of', 'O'), ('either', 'O'), ('species', 'B-Quality'), ('or', 'O'), ('functional', 'O'), ('group', 'O'), ('richness', 'B-Quality'), ('effects', 'O'), ('depended', 'O'), ('on', 'O'), ('the', 'O'), ('sequence', 'O'), ('of', 'O'), ('testing', 'O'), ('these', 'O'), ('terms', 'O'), (',', 'O'), ('indicating', 'O'), ('that', 'O'), ('both', 'O'), ('aspects', 'O'), ('of', 'O'), ('richness', 'B-Quality'), ('were', 'O'), ('congruent', 'O'), ('and', 'O'), ('complementary', 'O'), ('to', 'O'), ('expected', 'O'), ('strong', 'O'), ('effects', 'O'), ('of', 'O'), ('legume', 'O'), ('presence', 'O'), ('and', 'O'), ('grass', 'B-Organism'), ('presence', 'O'), ('on', 'O'), ('plant', 'B-Organism'), ('chemical', 'B-Quality'), ('composition', 'I-Quality'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter_test = SentenceGetter(test_data)\n",
        "sentences_test = getter_test.sentences\n",
        "sent_test = getter_test.get_next()\n",
        "print(sent_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Z437Qz_ksYiu"
      },
      "outputs": [],
      "source": [
        "def get_text_tags_lists(sentences):\n",
        "  texts = []\n",
        "  tags = []\n",
        "  for sent in sentences: #list of tuples\n",
        "    sent_texts = []\n",
        "    sent_tags = []\n",
        "    for tuple1 in sent:\n",
        "      sent_texts.append(tuple1[0])\n",
        "      sent_tags.append(tuple1[1])\n",
        "\n",
        "    texts.append(sent_texts)\n",
        "    tags.append(sent_tags)\n",
        "  return texts, tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "fNuvDHsZsZND"
      },
      "outputs": [],
      "source": [
        "train_texts, train_tags = get_text_tags_lists(sentences)\n",
        "val_texts, val_tags = get_text_tags_lists(sentences_val)\n",
        "test_texts, test_tags = get_text_tags_lists(sentences_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dRsnSPfKIADP"
      },
      "outputs": [],
      "source": [
        "#Create a list of texts\n",
        "def create_input_seq(texts):\n",
        "  inputs = texts\n",
        "  input_sequences = []\n",
        "\n",
        "  for sentence in inputs:\n",
        "    input_sequences.append(' '.join(sentence))\n",
        "\n",
        "  return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "Q2-7zvDOv_90"
      },
      "outputs": [],
      "source": [
        "train_inputs_raw = create_input_seq(train_texts)\n",
        "val_inputs_raw = create_input_seq(val_texts)\n",
        "test_inputs_raw = create_input_seq(test_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmZmuZcCtUNf"
      },
      "source": [
        "Convert problem into text-to-text format by formatting an output which is a sequence of class:entity pairs separated by a semicolon ';'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TYTj6WzxcCIK"
      },
      "outputs": [],
      "source": [
        "def format_targets(text, label):\n",
        "  s = \"\"\n",
        "  texts = []\n",
        "  for i in range(len(text)-1):\n",
        "    if label[i] != 'O':\n",
        "      s += text[i] + \" \"\n",
        "      if label[i+1] == 'O' or label[i+1][0:1] == 'B':\n",
        "        s = label[i][2:] + \": \" + s\n",
        "        texts.append(s.strip())\n",
        "        s = \"\"\n",
        "  texts = \"; \".join(texts)\n",
        "  return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "UGzd5z73Igxn",
        "outputId": "143db8b7-9e61-4d27-b0e8-c33694b9642c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Quality: Density; Phenomena: Treatment; Quality: Dead; Environment: Garden; Organism: Seedling; Phenomena: growth; Quality: biomass; Environment: plant communities; Quality: species richness; Environment: tropical forest ecosystems'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str1 = format_targets(train_texts[0], train_tags[0])\n",
        "str1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llZv3PEKtm_N"
      },
      "source": [
        " Convert them back to sentence format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GNwHXjj2udeJ"
      },
      "outputs": [],
      "source": [
        "def create_output_seq(texts, tags):\n",
        "  output_sequences = []\n",
        "\n",
        "  for i in range(len(texts)):\n",
        "    text = texts[i]\n",
        "    label = tags[i]\n",
        "\n",
        "    target = format_targets(text, label)\n",
        "    output_sequences.append(target)\n",
        "\n",
        "  return output_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "u9rBXsn0urFM"
      },
      "outputs": [],
      "source": [
        "train_outputs_raw = create_output_seq(train_texts, train_tags)\n",
        "val_outputs_raw = create_output_seq(val_texts, val_tags)\n",
        "test_outputs_raw = create_output_seq(test_texts, test_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "def has_non_ascii(sentence):\n",
        "    return any(ord(char) > 127 for char in sentence)\n",
        "\n",
        "def clean_non_ascii(inputs, labels):\n",
        "    clean_inputs = []\n",
        "    clean_labels = []\n",
        "\n",
        "    for sentence, label in zip(inputs, labels):\n",
        "        if has_non_ascii(sentence):\n",
        "            continue\n",
        "        \n",
        "        clean_inputs.append(sentence)\n",
        "        clean_labels.append(label)\n",
        "\n",
        "    return clean_inputs, clean_labels\n",
        "\n",
        "def clean_non_ascii_test(texts, tags):\n",
        "    clean_inputs = []\n",
        "    clean_labels = []\n",
        "\n",
        "    for sentence, label in zip(texts, tags):\n",
        "        sentence2 = ' '.join(sentence)\n",
        "        if has_non_ascii(sentence2):\n",
        "            continue\n",
        "        \n",
        "        clean_inputs.append(sentence)\n",
        "        clean_labels.append(label)\n",
        "\n",
        "    return clean_inputs, clean_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_inputs, train_outputs = clean_non_ascii(train_inputs_raw, train_outputs_raw)\n",
        "val_inputs, val_outputs = clean_non_ascii(val_inputs_raw, val_outputs_raw)\n",
        "test_texts_c, test_tags_c = clean_non_ascii_test(test_texts, test_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Combining', 'metabolic', 'and', 'food-', 'web', 'theory', ',', 'we', 'calculate', 'annual', 'energy', 'fluxes', 'to', 'model', 'impacts', 'of', 'land-use', 'intensification', 'on', 'multitrophic', 'ecosystem', 'functioning', '.'], ['The', 'primacy', 'of', 'either', 'species', 'or', 'functional', 'group', 'richness', 'effects', 'depended', 'on', 'the', 'sequence', 'of', 'testing', 'these', 'terms', ',', 'indicating', 'that', 'both', 'aspects', 'of', 'richness', 'were', 'congruent', 'and', 'complementary', 'to', 'expected', 'strong', 'effects', 'of', 'legume', 'presence', 'and', 'grass', 'presence', 'on', 'plant', 'chemical', 'composition', '.'], ['Full', 'ant', 'species', 'name', '.'], ['If', 'it', 'would', 'not', 'be', 'considered', 'greater', 'than', '10', ',', 'it', 'would', 'not', 'be', 'considered', 'in', 'the', 'outer', 'subplots.Helper', ';', 'Datagroup', 'description', ':', 'Helper', ')', 'dimensionless', 'real', 'Helper', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Probability', 'that', 'a', 'stem', 'would', 'be', 'considerd', 'greater', 'or', 'equal', 'than', '10', 'given', 'it', 's', 'basal', 'diameter', '.'], ['117.8998', '118.1483', '29.2852', '29.10178', '########', '########', 'Fungal', 'communities', 'based', 'on', 'fungal', 'IST', 'rDNA', 'pyrosequencing', '.'], ['4', '79106', 'Freiburg', 'im', 'Breisgau', 'Germany', '49', '(', '0', ')', '761', '203', '-', '67787', 'Alexandra-Maria', 'Klein', 'Institute', 'of', 'Ecology', 'and', 'Environmental', 'Chemistry', ',', 'Section', 'Ecosystem', 'Functions', ',', 'Leuphana', 'University', 'of', 'Lueneburg', 'Scharnhorststr', '.'], ['There', 'are', 'three', 'main', 'sites', 'for', 'research', 'plots', 'in', 'the', 'BEF', 'Experiment', ':', 'Comparative', 'Study', 'Plots', '(', 'CSP', ')', 'in', 'the', 'Gutianshan', 'Nature', 'Reserve', ',', 'having', 'a', 'size', 'of', '30x30m^2', ',', 'measured', 'on', 'the', 'ground', '.'], ['Number', 'of', 'individuals', 'Organism', 'count', '(', 'Hemiptera_sum', ')', ',', 'Hemiptera_sum', 'Counting', 'the', 'individuals', 'of', 'a', 'given', 'taxon', ',', 'also', 'called', 'abundance', '.'], ['Or', 'the', 'allometries', 'are', 'not', 'used', 'to', 'extrapolate', 'the', 'biomass', 'of', 'the', 'first', 'item', '(', 'for', 'example', 'a', 'tree', 'dbh', ')', '.', ')'], ['The', 'vector', 'data', 'file', 'is', 'included', 'in', '``', 'Habitat_OffshorePigeonPoint.zip', ',', ',', 'which', 'is', 'accessible', 'from', 'Using', 'multibeam', 'echosounder', '(', 'MBES', ')', 'bathymetry', 'and', 'backscatter', 'data', ',', 'potential', 'marine', 'benthic', 'habitat', 'maps', 'were', 'constructed', '.'], ['MMMTAV', ',', 'the', 'toxicokinetic', 'properties', 'of', 'which', 'are', 'not', 'well', 'known', ',', 'was', 'in', 'many', 'cases', 'a', 'major', 'metabolite', '.'], ['The', 'vaginal', 'microbiota', 'of', 'the', 'guinea', 'pig', 'differs', 'from', 'that', 'of', 'humans', 'and', 'can', 'not', 'prevent', 'chlamydial', 'infections', 'efficiently', '.'], ['These', 'covariations', 'were', 'inconsistent', 'at', 'the', 'within-species', 'level', '.'], ['Higher', 'arthropod', 'taxa', '(', 'Genus', ')', ',', 'Genus', 'Higher', 'arthropod', 'taxa', '(', 'Genus', ':', 'Genus', 'of', 'the', 'species', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP19', ')', ',', 'CSP19', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['We', 'used', 'R', 'to', 'carry', 'out', 'different', 'multivariate', 'tests', '.'], ['on', 'the', 'ground', 'area', 'of', 'circular', 'plot', 'of', 'neighbour', 'evaluation', ',', 'used', 'as', 'area', 'basis', 'for', 'determination', 'of', 'neighbour', 'indices', 'Density', 'measure', '(', 'neigh_a', ')', ',', 'neigh_a', 'Measure', 'of', 'density', ',', 'i.e', '.'], ['Leaf', 'traits', 'and', 'chemicals', 'from', 'tree', 'species', 'in', 'the', 'Main', 'Experimental', 'sites', ',', 'including', 'secondary', 'compound', '(', 'total', 'phenolic', 'and', 'tannin', 'concentrations', ')', 'and', 'information', 'on', 'stomata', '.'], ['Most', 'species', 'had', 'a', 'significant', 'range', 'contraction', '(', 'up', 'to', '72', '%', ')', 'and', '12', '%', 'of', 'species', 'were', 'projected', 'to', 'be', 'regionally', 'extinct', '.'], ['Unexpectedly', ',', 'resource', 'acquisition', '(', 'growth', ',', 'recruitment', ')', 'and', 'conservation', '(', 'mortality', ',', 'turnover', ')', 'played', 'an', 'equally', 'important', 'role', 'throughout', 'the', 'succession', '.'], ['A', 'global', 'model', 'of', 'the', 'response', 'of', 'tropical', 'and', 'sub-tropical', 'forest', 'biodiversity', 'to', 'anthropogenic', 'pressures', 'Habitat', 'loss', 'and', 'degradation', ',', 'driven', 'largely', 'by', 'agricultural', 'expansion', 'and', 'intensification', ',', 'present', 'the', 'greatest', 'immediate', 'threat', 'to', 'biodiversity', '.'], ['We', 'show', 'that', 'in', 'contrast', 'to', 'what', 'was', 'expected', 'from', 'the', 'sharp', 'decrease', 'in', 'organic', 'carbon', 'fluxes', 'and', 'reduced', 'faunal', 'abundance', ',', 'the', 'deep-sea', 'biodiversity', 'of', 'both', 'the', 'eastern', 'and', 'the', 'western', 'basins', 'of', 'the', 'Mediterranean', 'Sea', 'is', 'similarly', 'high', '.'], ['Ways', 'to', 'quantify', 'precipitation', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mmmeasured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ';', 'rainfall', 'amount', 'open', 'field', '(', 'vaisala', ')', 'mmmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'peak', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'of', 'the', 'five', 'highest', 'five', 'minute', 'intensities', 'open', 'field', '(', 'vaisala', ')', 'measured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mmmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'peak', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '(', 'int_t', ':', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/h', '--', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', '--', 'measured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', ')', 'dimensionless', 'real', 'Precipitation', 'Precipitation', 'measured', 'at', 'the', 'climate', 'station', 'or', 'locally', 'within', 'sites', '.'], ['HoloBee-Mop', 'is', 'a', 'database', 'comprised', 'mostly', 'of', 'chro', 'mosomal', ',', 'mitochondrial', 'and', 'plasmid', 'genome', 'assemblies', 'in', 'order', 'to', 'aggregate', 'as', 'much', 'honey', 'bee', 'holobiont', 'genomic', 'sequence', 'information', 'as', 'possible', '.'], ['woody', 'debris', ')', 'is', 'measured', 'as', 'an', 'indication', 'of', 'its', 'position', '(', 'direction', 'CWD', ':', 'Direction', 'to', 'woody', 'debris', 'item', ':', 'The', 'direction', 'a', 'woody', 'debris', 'is', 'aligned', 'from', 'the', 'thick', 'to', 'the', 'thin', 'part', 'of', 'the', 'debris', 'object', ')', 'dimensionless', 'real', 'Angle', 'the', 'angle', 'from', 'the', 'base', 'along', 'an', 'object', 'to', 'its', 'top', '(', 'e.g', '.'], ['An', 'Assessment', 'of', 'the', 'Amount', 'and', 'Extent', 'of', 'Plant', 'Collection', 'Records', 'and', 'Census', 'Data', 'Available', 'for', 'Tropical', 'South', 'America', 'Large-scale', 'studies', 'are', 'needed', 'to', 'increase', 'our', 'understanding', 'of', 'how', 'large-scale', 'conservation', 'threats', ',', 'such', 'as', 'climate', 'change', 'and', 'deforestation', ',', 'are', 'impacting', 'diverse', 'tropical', 'ecosystems', '.'], ['This', 'shift', 'offers', 'opportunities', 'for', 'a', 'deeper', 'mechanistic', 'understanding', 'of', 'the', 'role', 'of', 'biodiversity', 'in', 'maintaining', 'multiple', 'ecosystem', 'processes', 'and', 'services', '.'], ['The', 'spatial', 'identification', 'of', 'hot', 'spots', 'highlighted', 'the', 'ecological', 'importance', 'of', 'most', 'of', 'the', 'western', 'Mediterranean', 'shelves', '(', 'and', 'in', 'particular', ',', 'the', 'Strait', 'of', 'Gibraltar', 'and', 'the', 'adjacent', 'Alboran', 'Sea', ')', ',', 'western', 'African', 'coast', ',', 'the', 'Adriatic', ',', 'and', 'the', 'Aegean', 'Sea', ',', 'which', 'show', 'high', 'concentrations', 'of', 'endangered', ',', 'threatened', ',', 'or', 'vulnerable', 'species', '.'], ['In', 'order', 'to', 'test', 'for', 'effects', 'of', 'density-dependence', ',', 'each', 'subplot', ',', 'was', 'then', 'subdivided', 'in', 'split-plots', 'where', 'tree', 'seedlings', 'were', 'planted', 'in', 'conspecific', 'communities', 'at', 'different', 'density', 'levels', 'of', '4', ',', '9', 'and', '25', 'individuals', 'each', '.'], ['Here', ',', 'we', 'report', 'unprecedented', 'rates', 'of', 'local', 'extinctions', 'of', 'medium', 'to', 'large-bodied', 'mammals', 'in', 'one', 'of', 'the', 'world', 's', 'most', 'important', 'tropical', 'biodiversity', 'hotspots', '.'], ['CSPs', ':', 'Ants', '(', 'Formicidae', ')', 'of', 'pitfall', 'traps', 'in', 'the', 'CSPs', '2009', 'Alexandra-Maria', 'Klein', 'Institute', 'of', 'Ecology', 'and', 'Environmental', 'Chemistry', ',', 'Section', 'Ecosystem', 'Functions', ',', 'Leuphana', 'University', 'of', 'Lueneburg', 'Scharnhorststr', '.'], ['The', 'scientific', 'species', 'fullnames', 'are', 'based', 'on', 'the', '``', 'Flora', 'of', 'China', 'China', '.'], ['(', 'rot', ':', 'presence', 'of', 'red', 'mould', ')', 'Organisms', 'found', 'in', 'the', 'specimen', 'under', 'study', '.'], ['Number', 'of', 'individuals', 'Organism', 'count', '(', 'Tetramorium.wroughtonii', ')', ',', 'Tetramorium.wroughtonii', 'Counting', 'the', 'individuals', 'of', 'a', 'given', 'taxon', ',', 'also', 'called', 'abundance', '.'], ['Primary', 'production', 'and', 'export', 'flux', 'over', 'the', 'MAR', 'were', 'not', 'enhanced', 'compared', 'with', 'a', 'nearby', 'reference', 'station', 'over', 'the', 'Porcupine', 'Abyssal', 'Plain', '.'], ['nz-waikato_0808cb5e-1fc2-4be7-b92e-2e8a7e548fdb', 'Environmental', 'indicators', '-', 'Land', 'and', 'soil', '(', 'Waikato', ')', 'Environmental', 'indicators', '-', 'Land', 'and', 'soil', '(', 'Waikato', ')', 'The', 'indicators', 'for', 'the', 'quality', 'of', 'the', 'Waikato', 'region', 's', 'land', ',', 'soil', 'and', 'native', 'vegetation', 'and', 'how', 'it', 'changes', '.'], ['117.8998', '118.1483', '29.2852', '29.10178', '1/7/2008', '########', 'no', 'organisms', ',', 'only', 'vegetated', 'and', 'bare', 'plots', 'no', 'organisms', ',', 'only', 'vegetated', 'and', 'bare', 'plots', 'tscholten', 'pkuehn', 'cgeissler', 'CSPs', ':', 'Kinetic', 'energy', 'of', 'raindrops', 'in', 'the', 'CSPs', ':', 'characteristics', 'of', 'rain', 'events', 'Rain', 'was', 'captured', 'in', 'open', 'field', 'and', 'in', 'vegetated', 'conditions', 'parallel', 'to', 'measurements', 'in', 'the', 'Comparative', 'study', 'plots', '(', 'CSPs', ')', '.'], ['Our', 'meta-analysis', 'shows', 'a', 'significant', 'decline', 'of', 'the', 'diversity', 'and', 'density', 'of', 'soil', 'invertebrates', 'in', 'response', 'to', 'earthworm', 'invasion', 'with', 'anecic', 'and', 'endogeic', 'earthworms', 'causing', 'the', 'strongest', 'effects', '.'], ['Most', 'participants', 'wanted', '1', ')', 'a', 'monitoring', 'design', 'covering', 'the', 'entire', 'territory', 'and', 'focusing', 'on', 'natural', 'habitats', ';', '2', ')', 'a', 'focus', 'on', 'species', 'related', 'to', 'ecosystem', 'services', ',', 'on', 'threatened', 'and', 'on', 'invasive', 'species', '.'], ['--', 'd', ')', 'Compare', 'species-specific', 'sensitivities', 'to', 'snow', 'break', 'as', 'a', 'trait', 'i', ')', 'Calculate', 'the', 'likelihood', 'of', 'being', 'subject', 'to', 'snowbreak', 'given', 'the', 'species', ',', 'size', 'and', 'potentially', 'the', 'relative', 'position', 'using', 'logistic', 'regression', 'ii', ')', 'Calculate', 'the', 'likelihood', 'of', 'snag', 'survival', ';', 'this', 'requires', 're-sampling', 'iii', ')', 'Estimate', 'the', 'down-slope', 'transport', 'of', 'deadwood', 'pieces', 'iv', ')', 'Estimate', 'the', 'time', 'it', 'takes', 'for', 'deadwood', 'to', 'collapse', 'and', 'touch', 'the', 'forest', 'floor', '--', '--', '-', 'File', 'asset', 'Plot_skizze.pdf', ':', 'plot', 'sketch', 'how', 'the', 'debris', 'objects', 'are', 'selected', '-', 'File', 'asset', 'sp10', 'CWD_protocol_Gutianshan_AF_20081215_kn.doc', ':', 'Inventory', 'protocol', ',', 'should', 'be', 'included', 'into', 'methods', '--', '--', '-', '2', ')', 'Objective', 'allometries', ':', 'use', 'some', 'of', 'the', 'downed', 'or', 'alive', 'trees', 'to', 'establish', 'coarse', 'allometries', 'to', 'estimate', 'volume', 'of', 'the', 'remaining', 'intems', 'allometries', 'basal', 'diameter', 'coarse', 'woody', 'debris', 'co-variable', 'CSP', 'date', 'dbh', 'dead', 'wood', 'decomposition', 'fungi', 'ice', 'storm', 'location', 'mortality', 'object', 'red', 'mould', 'response', 'variable', 'size', 'snag', 'height', 'soil', 'species', 'stem', 'termites', 'weather', 'woody', 'debris', 'Find', 'the', 'list', 'of', 'keywords', 'here', ':', 'rownr', 'date', 'Date', 'start', 'end', 'plotignore', 'CSP', 'working', 'condition', 'protoc.first', 'protoc.sur', 'meas.first', 'meas.sur', 'entered.first', 'entered.sur', 'entered.date', 'page', 'Central_subplot', 'CWD-Id', 'CWD_CSP_original', 'Idaddon', 'CWD_CSP', 'Species', 'specunpolished', 'TagAFCW', 'TagMBa', 'TagAFCW', 'original', 'TagMBa', 'original', 'DBH', 'dbh.comment', 'dbhpostmean', 'dbhpostsd', 'stemsGrEq10', 'stemsCnSm10', 'height', 'BD', 'lookup', 'tag', 'dbase.remark.kn', 'dtop', 'dtop.remark.kn', 'length', 'len.rem.kn', 'height_length', 'hei.len.rem.kn', 'broken', 'at', 'broken', 'diam', 'neigh.label', 'reference', 'is', 'self', 'neigh.dist', 'neigh.azimut', 'direction', 'CWD', 'pos.cw', 'pos.af_original', 'plot', 'estimate', 'pos.af', 'alive', 'sc', 'mc', 'dc', 'ter', 'rot', 'fungi', 'valid', 'crown_origin', 'remark', 'vol_factor', 'Allometrie', 'comment', 'Karin', 'meandbh', 'meanGr10', 'meanSm10Cn', 'ice_storm_representative', 'List', 'of', 'headers', 'of', 'the', 'data', 'columns', 'in', 'this', 'dataset', 'Permission', 'is', 'granted', 'to', 'anybody', 'to', 'access', ',', 'use', 'and', 'publish', 'all', 'open', 'for', 'public', 'data', 'freely', '.'], ['DESCRIPTION', 'Life', 'expectancy', 'estimates', 'for', 'North', 'American', 'zoo', 'and', 'aquarium', 'vertebrate', 'animals', 'SUMMARY', 'Data', 'behind', 'the', 'article', 'Sex-specific', 'median', 'life', 'expectancies', 'from', 'ex', 'situ', 'populations', 'for', '330', 'animal', 'species', '.'], ['dimensionless', 'real', 'Woody', 'debris', 'dimensions', 'Woody', 'debris', 'dimensions', 'consist', 'of', 'base', 'diameter', ',', 'top', 'diameter', ',', 'and', 'length', '.'], ['In', '16S', 'rRNA', 'clone', 'libraries', ',', 'the', 'agricultural', 'soil', 'was', 'dominated', 'by', 'chemolithoautotrophs', '(', 'Betaproteobacteria', ')', 'whereas', 'photoautotrophic', 'Chloroflexi', 'and', 'sulphide', 'oxidizers', 'dominated', 'saline', 'ecosystems', '.'], ['We', 'hypothesize', 'that', ',', 'after', 'extraction', 'of', 'variation', 'that', 'is', 'explained', 'by', 'location', 'and', 'land-use', 'type', ',', 'soil', 'properties', 'still', 'explain', 'significant', 'proportions', 'of', 'variation', 'in', 'the', 'abundance', 'and', 'diversity', 'of', 'soil', 'biota', '.'], ['Our', 'checklist', 'will', 'set', 'a', 'baseline', 'against', 'which', 'future', 'environmental', 'changes', 'can', 'be', 'tracked', '.'], ['5-Jan', ',', 'Chaoyang', 'District', 'Beijing', 'China', '008610-64807085', '########', 'en_US', 'We', 'integrated', 'multiple', 'components', 'of', 'plant', 'and', 'herbivore', 'diversity', 'to', 'unravel', 'the', 'linkages', 'that', 'drive', 'biodiversity', 'relationships', 'and', 'determine', 'the', 'consequences', 'of', 'biodiversity', 'loss', 'across', 'trophic', 'levels', '.'], ['Commands', ':', 'as.taxo', '(', ')', ',', 'divc', '(', ')', '(', 'shannon', ':', 'shannon', 'index', 'of', 'target', 'groups', ')', 'dimensionless', 'real', 'Taxonomic', 'biodiversity', 'Taxon', 'diversity', 'can', 'be', 'given', 'as', 'species', 'richness', ',', 'or', 'other', 'diversity', 'indices', '.'], ['Chlamydia', 'caviae', 'infection', 'alters', 'abundance', 'but', 'not', 'composition', 'of', 'the', 'guinea', 'pig', 'vaginal', 'microbiota', 'In', 'humans', ',', 'the', 'vaginal', 'microbiota', 'is', 'thought', 'to', 'be', 'the', 'first', 'line', 'of', 'defense', 'again', 'pathogens', 'including', 'Chlamydia', 'trachomatis', '.'], ['For', 'the', 'ease', 'of', 'analysis', ',', 'words', 'have', 'been', 'spearated', 'by', '``', '_', '_', '.'], ['In', 'a', 'grassland', 'biodiversity', 'experiment', ',', 'we', 'addressed', 'this', 'gap', 'by', 'assessing', 'aboveground', 'decomposer', 'and', 'herbivore', 'communities', 'and', 'linking', 'their', 'abundance', 'and', 'diversity', 'to', 'rates', 'of', 'decomposition', 'and', 'herbivory', '.'], ['Inclusion', 'of', 'intraspecific', 'trait', 'variability', 'significantly', 'decreased', 'the', 'strength', 'of', 'these', 'covariations', '.'], ['Mass-', '%', 'of', '8', 'grain', 'size', 'classes', 'of', 'fine', 'earth', '<', '2', 'mm', 'from', 'soil', 'horizons', 'of', 'each', 'soil', 'profile', 'per', 'CSP', '.'], ['Earthworms', 'decreased', 'total', 'shoot', 'biomass', 'in', 'mesocosms', 'with', 'more', 'plant', 'species', 'but', 'did', 'not', 'affect', 'biomass', 'production', 'of', 'individual', 'functional', 'groups', '.'], ['Decision-makers', 'need', 'to', 'know', 'which', 'of', 'the', 'remaining', 'forests', 'to', 'prioritize', 'for', 'conservation', ',', 'but', 'the', 'only', 'spatial', 'information', 'on', 'forest', 'biodiversity', 'has', ',', 'until', 'recently', ',', 'come', 'from', 'a', 'sparse', 'network', 'of', 'ground-based', 'plots', '.'], ['Height', 'is', 'for', 'a', 'standing', 'tree', ',', 'length', 'for', 'a', 'tree', 'lying', 'on', 'the', 'ground', '.'], ['CSPs', ':', 'Coarse', 'woody', 'debris', '(', 'CWD', ')', '.'], ['While', 'the', 'wildlife', 'trade', 'may', 'put', 'additional', 'stress', 'on', 'coral', 'reefs', ',', 'it', 'brings', 'income', 'into', 'impoverished', 'parts', 'of', 'the', 'world', 'and', 'may', 'stimulate', 'interest', 'in', 'marine', 'conservation', '.'], ['(', 'rock_artefacts49', ':', 'Features', 'of', 'sediment', '/', 'Primary', 'constituents', '/', 'Rock', 'fragments', 'and', 'artefacts', ':', 'Soil', 'horizon', 'description', 'II', ';', 'rock_artefacts49', ')', 'Basic', 'information', 'on', 'soil', 'properties', ',', 'according', 'to', '``', 'Eckelmann', ',', 'W.', ',', 'Sponagel', ',', 'H.', ',', 'Grottenthaler', ',', 'W.', ',', 'Hartmann', ',', 'J.', 'K.', ',', 'Hartwich', ',', 'R.', ',', 'Janetzko', ',', 'P.', ',', '...', '&', 'Traidl', ',', 'R.', '(', '2005', ')', '.'], ['The', 'aim', 'of', 'our', 'study', 'was', 'to', 'conduct', 'a', 'rRNA-targeted', 'metagenomic', 'analysis', 'on', 'amoebae', 'and', 'intra-amoebal', 'bacteria', 'found', 'in', 'drinking', 'water', 'network', ',', 'to', 'provide', 'the', 'first', 'FLA', 'microbiome', 'in', 'environmental', 'strains', '.'], ['nawai', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Camponotus', 'vitiosus', ')', ',', 'Camponotus', 'vitiosus', '(', 'Camponotus', 'vitiosus', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Pristomyrmex', 'punctatus', ')', ',', 'Pristomyrmex', 'punctatus', '(', 'Pristomyrmex', 'punctatus', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Alticinae', 'sp.1', ')', ',', 'Alticinae', 'sp.1', '(', 'Alticinae', 'sp.1', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Crematogaster', 'cf', '.'], [';', 'Comparative', 'Study', 'Plots', '(', 'CSP', ')', 'in', 'the', 'Gutianshan', 'Nature', 'Reserve', ',', 'having', 'a', 'size', 'of', '30x30m^2', ',', 'measured', 'on', 'the', 'ground', '.', ')'], ['The', 'finding', 'that', 'intraspecific', 'trait', 'variation', 'contributed', 'less', 'to', 'this', 'relationship', 'suggests', 'that', 'the', 'trade-off', 'is', 'dominated', 'by', 'evolutionary', 'constraints', 'rather', 'than', 'by', 'carbon', 'allocation', 'constraints', '.'], ['For', 'each', 'compound', ',', 'the', 'target', 'pathogen', 'and', 'biochemical', 'mode', 'of', 'action', 'are', 'described', ',', 'in', 'order', 'to', 'draw', 'attention', 'to', 'the', 'complexity', 'of', 'these', 'phenomena', '.'], ['The', 'aim', 'of', 'this', 'study', 'was', 'to', 'test', 'whether', 'species', 'contributions', 'to', 'community', 'biomass', 'can', 'be', 'used', 'as', 'surrogate', 'measures', 'of', 'their', 'contribution', 'to', 'ecosystem', 'processes', '.'], ['From', '27', 'comparative', 'study', 'plots', '(', 'CSPs', ')', 'soil', 'samples', 'were', 'taken', 'horizonwise', 'from', '1', 'soil', 'profile', 'per', 'CSP', 'Soil', 'profiles', 'are', 'located', 'directly', 'adjacent', 'to', 'the', 'CSPs', '.'], ['string', '#', 'string', 'qscore', 'data/nfa_2018_edition.csv', 'csv', 'original/GFN', 'Country', 'code', 'concordance', 'table.csv', 'original/GFN', 'Country', 'code', 'concordance', 'table.csv', 'csv', 'text/csv', '5699', 'original/NFA', '2018', 'Edition.csv', 'original/NFA', '2018', 'Edition.csv', 'csv', 'text/csv', '7132699', 'science', 'earth', 'one', 'planet', 'sustainability', 'earth', 'science', 'international', 'government', 'carbon', 'forest', 'infrastructure', 'anthropogenic'], ['These', 'surficial', 'lithology', 'classes', 'were', 'derived', 'from', 'the', 'USGS', 'map', '``', 'Surficial', 'Materials', 'in', 'the', 'Conterminous', 'United', 'States', 'States', ',', 'which', 'was', 'based', 'on', 'texture', ',', 'internal', 'structure', ',', 'thickness', 'and', 'environment', 'of', 'deposition', 'or', 'formation', 'of', 'materials', '(', 'Soller', 'and', 'Reheis', ',', '2004', ')', '.'], ['Rainevent', 'for', 'determinig', 'kinetic', 'energy', 'of', 'rainfalls', 'Splashcups', 'were', 'collected', 'after', 'certain', 'rain', 'events', '.'], ['(', 'CSP20', ':', 'BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', ')', 'dimensionless', 'real', 'Abundance', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['The', 'Directive', 'was', 'transposed', 'into', 'Irish', 'Law', 'by', 'the', 'European', 'Communities', '(', 'Health', 'of', 'Aquaculture', 'Animals', 'and', 'Products', ')', 'Regulations', '2008', '(', 'SI', 'No', '.'], ['The', 'abundance', 'of', 'tree', 'species', 'were', 'collected', 'from', '64', 'plots', '(', 'each', '1250', 'm2', 'in', 'size', ')', 'within', 'a', 'Sierra', 'Leonean', 'national', 'park', ',', 'and', 'Shannon-Wiener', 'biodiversity', 'indices', 'were', 'calculated', '.'], ['(', 'Fungi', ':', 'sum', '18:01', 'w9c', ',', '18:02', 'w6,9c', ';', ';', 'Wu', 'et', 'al.', ',', '2012', '(', 'see', 'metadata', 'sheet', ',', 'doi:10.1007/s10021-012-9533-3', ')', '(', 'derived', 'from', 'datagroup', ')', ')', 'dimensionless', 'real', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', '.'], ['To', 'estimate', 'habitat', 'favorability', 'to', 'fungi', ',', 'we', 'examined', 'the', 'relationship', 'of', 'fungal', 'abundance', 'and', 'species', 'richness', 'to', 'various', 'weather', 'and', 'environmental', 'parameters', 'in', 'the', 'Intermountain', 'West', '.'], ['The', 'greatest', 'changes', 'were', 'seen', 'for', 'early', 'stage', 'transitions', ',', 'such', 'as', 'introduction', 'of', 'reduced', 'tillage', 'regimes', 'and', 'conversion', 'to', 'grassland', 'from', 'arable', 'land', '.'], ['On', 'each', 'tree', ',', 'a', 'total', 'of', '20', 'young', 'leaves', 'and', 'the', 'attached', 'branch', 'sections', 'of', 'three', 'randomly', 'selected', 'branches', 'were', 'visually', 'inspected', 'for', 'the', 'occurrence', 'and', 'the', 'number', 'of', 'sap-sucking', 'Hemiptera', 'and', 'honeydew-collecting', 'ants', '.'], ['The', 'Levantine', 'Basin', ',', 'severely', 'impacted', 'by', 'the', 'invasion', 'of', 'species', ',', 'is', 'endangered', 'as', 'well', '.'], ['Ant', 'species', 'name', '(', 'Species_Tax', ')', ',', 'Species_Tax', 'Ants', 'were', 'identified', 'to', 'species', 'level', 'with', 'primary', 'taxonomic', 'literature', 'whenever', 'possible', '.'], ['Based', 'on', 'community-weighted', 'mean', 'calculations', 'for', 'each', 'functional', 'trait', ',', 'we', 'figured', 'out', 'that', 'the', 'traits', 'N-fixation', 'and', 'species', 'origin', ',', 'i.e', '.'], ['Here', 'we', 'provide', 'an', 'overview', 'of', 'important', 'considerations', 'related', 'to', 'forest', 'restoration', 'that', 'can', 'be', 'inferred', 'from', 'this', 'BEF-perspective', '.'], ['Recent', 'community', 'evolution', 'models', 'are', 'a', 'promising', 'step', 'in', 'that', 'direction', '.'], ['HoloBee-Barcode', 'is', 'intended', 'to', 'improve', 'and', 'standardize', 'quantitative', 'and', 'qualitative', 'metagenomic', 'descriptions', 'of', 'holobiont', 'communities', 'associated', 'with', 'honey', 'bees', 'by', 'providing', 'a', 'curated', 'set', 'of', 'barcode', 'sequences', '.'], ['Growing', 'human', 'population', 'densities', ',', 'intensified', 'land-use', ',', 'invasive', 'species', 'and', 'increasing', 'habitat', 'fragmentation', 'threaten', 'ecosystems', 'worldwide', 'and', 'protected', 'areas', 'are', 'often', 'the', 'only', 'refuge', 'for', 'endangered', 'species', '.'], ['In', 'a', 'series', 'of', 'experiments', 'replicated', 'at', 'a', 'global', 'scale', 'we', 'translocated', 'several', 'hundred', 'marine', 'hard', 'bottom', 'communities', 'to', 'new', 'environments', 'simulating', 'a', 'rapid', 'but', 'moderate', 'environmental', 'change', '.'], ['With', 'this', 'data', ',', 'herb', 'community', 'analysis', 'from', 'the', 'CSPs', 'can', 'be', 'performed', '.'], ['(', 'Ants_sum', ':', 'Total', 'number', 'of', 'individuals', 'of', 'ants', ')', 'dimensionless', 'real', 'Organism', 'count', 'Counting', 'the', 'individuals', 'of', 'a', 'given', 'taxon', ',', 'also', 'called', 'abundance', '.'], ['Our', 'findings', 'compromise', 'the', 'validity', 'of', 'the', 'guinea', 'pig-C.', 'caviae', 'model', 'to', 'study', 'the', 'role', 'of', 'the', 'vaginal', 'microbiota', 'during', 'the', 'early', 'steps', 'of', 'sexually', 'transmitted', 'infection', '.'], ['The', 'community', 'composition', 'of', 'the', 'riparian', 'reserves', 'was', 'more', 'similar', 'to', 'logged', 'forest', 'than', 'oil', 'palm', '.'], ['Using', 'monocultures', 'of', 'ten', 'and', 'seven', 'tree', 'species', ',', 'respectively', 'planted', 'at', 'two', 'different', 'sites', ',', 'juveniles', 'of', 'all', 'species', 'were', 'grown', 'in', 'their', 'own', '(', 'home', ')', 'and', 'in', 'all', 'other', 'monocultures', '(', 'away', ')', ',', 'thereby', 'testing', 'for', 'distance', 'effect', ',', 'just', 'as', 'in', 'three', 'different', 'levels', 'of', 'planting', 'density', ',', 'testing', 'for', 'density', 'effects', '(', 'see', '``', 'Main', 'Experiment', ':', 'Seedling', 'addition', 'experiment', '-', 'growth', 'and', 'biomass', 'data', 'data', 'for', 'further', 'details', ')', 'In', 'addition', ',', 'we', 'repeated', 'a', 'similar', 'set-up', 'in', 'a', 'nearby', 'common', 'garden', 'experiment', ',', 'where', 'we', 'added', 'a', 'shadow', 'shadow', 'treatment', 'to', 'simulate', 'different', 'light', 'conditions', 'induced', 'by', 'the', 'canopy', 'layer', '.'], ['Sand-filled', 'splash', 'cups', 'were', 'used', 'to', 'study', 'the', 'erosivity', 'of', 'rainfall', 'and', 'throughfall', 'in', 'the', 'humid', 'subtropics', 'of', 'southeast', 'China', 'in', 'spring', 'and', 'summer', '2010', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP26', ')', ',', 'CSP26', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['Even', 'if', 'species', 'can', 'migrate', 'in', 'response', 'to', 'climate', 'change', ',', 'if', 'ecotones', 'do', 'not', 'they', 'can', 'function', 'as', 'hard', 'barriers', 'to', 'species', 'migrations', ',', 'making', 'ecotone', 'migrations', 'central', 'to', 'understanding', 'species', 'persistence', 'under', 'scenarios', 'of', 'climate', 'change', '.'], ['(', 'BA17', ':', 'basal', 'area', 'in', '2017', ')', 'dimensionless', 'real', 'Basal', 'area', 'Basal', 'area', 'is', 'calculated', 'as', 'the', 'area', 'at', 'breastheight', 'of', 'a', 'given', 'tree', 'and', 'can', 'be', 'summed', 'up', 'to', 'estimate', 'the', 'tree', 'mass', 'in', 'a', 'given', 'plot', '.'], ['Insect', 'pollination', 'and', 'self-incompatibility', 'in', 'edible', 'and/or', 'medicinal', 'crops', 'in', 'southwestern', 'China', ',', 'a', 'global', 'hotspot', 'of', 'biodiversity', '.'], ['Forest', 'Ecology', 'and', 'Management', '261', '(', '3', ')', ':', '499-507', '(', 'derived', 'from', 'datagroup', ')', '(', 'CI_ME', ':', 'competition', 'index', '(', 'Martin', 'and', 'Ek', '1984', ')', ')', 'dimensionless', 'real', 'Competition', 'index', 'Individual', 'tree', 'competition', 'index', '.'], ['Besides', 'the', 'formation', 'of', 'monomethylarsonic', 'acid', '(', 'MMAV', ')', ',', 'we', 'detected', 'the', 'highly', 'toxic', 'monomethylarsonous', 'acid', '(', 'MMAIII', ')', '.'], ['Corrections', 'are', 'in', 'pos.af', ';', 'Datagroup', 'description', ':', 'Helper', 'Allometries', '(', 'plot', 'estimate', ')', ',', 'dimensionless', 'plot', 'estimate', 'Data', 'to', 'derive', 'tree', 'or', 'sapling', 'allometries', ',', 'as', 'well', 'as', 'allometric', 'equations', '.'], ['Another', 'definition', ':', '``', 'Operational', 'taxonomic', 'unit', ',', 'species', 'distinction', 'in', 'microbiology', '.'], ['The', 'NNR', 'comprises', 'a', 'large', 'portion', 'of', 'broad-leaved', 'forests', 'of', 'advanced', 'successional', 'stages', '(', 'Hu', '&', 'Yu', '2008', ')', ',', 'which', 'have', 'not', 'been', 'managed', 'since', 'the', 'beginning', 'of', 'the', '1990ies', ',', 'as', 'well', 'as', 'young', 'successional', 'stages', 'and', 'conifer', 'plantations', ',', 'mainly', 'of', 'Cunninghamia', 'lanceolata', 'and', 'Pinus', 'massoniana', '.'], ['Here', ',', 'we', 'asked', 'to', 'which', 'degree', 'physical', 'and', 'chemical', 'carbon-based', 'leaf', 'defence', 'traits', 'covary', 'within', 'and', 'across', 'species', '.'], ['information', 'on', 'data', 'analysis', 'Main', 'Experiment', ':', 'Leaf', 'traits', 'and', 'chemicals', 'from', 'individual', 'trees', 'in', 'the', 'Main', 'Experiment', '(', 'Site', 'A', '&', 'B', ')', '/datasets/323', 'ASCII', '1', 'column', ',', 'Identifier', '(', 'Samplecode', ')', ',', 'Samplecode', 'An', 'unabiguous', 'identifier', 'that', 'refers', 'to', 'a', 'specific', 'sample', '(', 'Samplecode', ':', 'Identifier', ';', 'Combination', 'of', 'characters', 'and', 'number', 'allowing', 'a', 'specific', 'identification', 'of', 'the', 'respective', 'specimen', ')', 'An', 'unabiguous', 'identifier', 'that', 'refers', 'to', 'a', 'specific', 'sample', 'Identifier', 'An', 'unabiguous', 'identifier', 'that', 'refers', 'to', 'a', 'specific', 'sample', 'Identifier', ';', 'Combination', 'of', 'characters', 'and', 'number', 'allowing', 'a', 'specific', 'identification', 'of', 'the', 'respective', 'specimen', 'Helper', '(', 'Sample.Collector', ')', ',', 'Sample.Collector', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', '(', 'Sample.Collector', ':', 'Sample.Collector', ')', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Helper', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Sample.Collector', 'Scientific', 'plant', 'species', 'name', '(', 'Species', ')', ',', 'Species', 'The', 'scientific', 'species', 'fullnames', 'are', 'based', 'on', 'the', '``', 'Flora', 'of', 'China', 'China', 'identified', 'by', 'Teng', 'Fang', 'and', 'verified', 'by', 'Helge', 'Bruelheide', '(', 'trees', ')', 'and', 'Alexandra', 'Erfmeier', '(', 'herbs', ')', '.'], ['The', 'contrast', 'in', 'diversity-multi-functionality', 'relationships', 'among', 'fallow', 'types', 'appears', 'related', 'to', 'differences', 'in', 'management', 'and', 'associated', 'factors', 'including', 'disturbance', 'and', 'species', 'composition', '.'], ['Here', 'we', 'combined', 'an', 'extensive', 'literature', 'analysis', 'with', 'expert', 'opinions', 'to', 'update', 'publicly', 'available', 'estimates', 'of', 'major', 'taxa', 'in', 'this', 'marine', 'ecosystem', 'and', 'to', 'revise', 'and', 'update', 'several', 'species', 'lists', '.'], ['This', 'system', 'is', 'an', 'important', 'model', 'for', 'understanding', 'how', 'microbial', 'communities', 'degrade', 'plant', 'biomass', 'in', 'natural', 'systems', 'and', 'has', 'direct', 'relevancy', 'for', 'bioenergy', ',', 'given', 'recent', 'interest', 'in', 'cellulosic', 'biofuels', '.'], ['Assessing', 'biodiversity', 'of', 'a', 'freshwater', 'benthic', 'macroinvertebrate', 'community', 'through', 'non-destructive', 'environmental', 'barcoding', 'of', 'DNA', 'from', 'preservative', 'ethanol', 'Background', 'Characterizing', 'biodiversity', 'in', 'a', 'habitat', 'or', 'in', 'targeted', 'taxonomically', 'or', 'socioeconomically', 'important', 'groups', 'remains', 'a', 'challenge', '.'], [';', 'Datagroup', 'description', ':', 'Organism', 'count', 'yes', '1224'], ['DESCRIPTION', 'Fish', 'Health', 'Unit', 'Authorised', 'Sites', 'SUMMARY', 'Fish', 'Health', 'Unit', 'registered', 'finfish', 'sites', 'in', 'Ireland', 'where', 'Fish', 'Health', 'regulations', 'and', 'Fish', 'Health', 'monitoring', 'on', 'finfish', 'are', 'applied', '.'], ['Of', 'other', 'trophobioses', ',', 'voucher', 'specimens', 'were', 'collected', '(', 'stored', 'in', '99', '%', 'ethanol', ')', '.'], ['Patterns', 'and', 'Perceptions', 'of', 'Climate', 'Change', 'in', 'a', 'Biodiversity', 'Conservation', 'Hotspot', 'Quantifying', 'local', 'people', 's', 'perceptions', 'to', 'climate', 'change', ',', 'and', 'their', 'assessments', 'of', 'which', 'changes', 'matter', ',', 'is', 'fundamental', 'to', 'addressing', 'the', 'dual', 'challenge', 'of', 'land', 'conservation', 'and', 'poverty', 'alleviation', 'in', 'densely', 'populated', 'tropical', 'regions', 'To', 'develop', 'appropriate', 'policies', 'and', 'responses', ',', 'it', 'will', 'be', 'important', 'not', 'only', 'to', 'anticipate', 'the', 'nature', 'of', 'expected', 'changes', ',', 'but', 'also', 'how', 'they', 'are', 'perceived', ',', 'interpreted', 'and', 'adapted', 'to', 'by', 'local', 'residents', '.'], ['Biotic', 'variables', 'included', 'species', 'richness', ',', 'functional', 'diversity', ',', 'competition', 'index', ',', 'the', 'dbh', 'of', 'the', 'target', 'tree', 'and', 'mean', 'upper', 'canopy', 'height', ',', 'while', 'the', 'abiotic', 'variables', 'were', 'slope', 'inclination', ',', 'slope', 'aspect', 'and', 'soil', 'depth', '.'], ['Strong', 'negative', 'covariations', 'were', 'detected', 'between', 'physical', 'and', 'chemical', 'defence', 'trait', 'when', 'phylogenetic', 'non-independence', 'was', 'accounted', 'for', '.'], ['Location', 'of', 'the', 'pitfall', 'trap', 'Helper', '(', 'Species', ')', ',', 'Species', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', '(', 'Species', ':', 'Species', 'name', '.'], ['basal', 'area', 'in', '2013', 'Basal', 'area', '(', 'BA14', ')', ',', 'BA14', 'Basal', 'area', 'is', 'calculated', 'as', 'the', 'area', 'at', 'breastheight', 'of', 'a', 'given', 'tree', 'and', 'can', 'be', 'summed', 'up', 'to', 'estimate', 'the', 'tree', 'mass', 'in', 'a', 'given', 'plot', '.'], ['us-vcgi-org_dd789af6-cdcc-4380-a40b-d407d1243adc', 'VT', 'Biodiversity', 'Project', '-', 'Plant', 'and', 'Animal', 'Species', 'Atlas', 'VT', 'Biodiversity', 'Project', '-', 'Plant', 'and', 'Animal', 'Species', 'Atlas', '(', '[', 'Link', 'to', 'Metadata', ']', '(', 'This', 'database', 'contains', 'town-level', 'totals', 'of', 'documented', 'species', 'records', 'for', 'several', 'plant', 'and', 'animal', 'taxa', 'including', 'vascular', 'plants', ',', 'trees', ',', 'bryophytes', ',', 'ferns', ',', 'fish', ',', 'mammals', ',', 'and', 'reptiles', '&', 'amphibians', '.'], ['An', 'Insect', 'Herbivore', 'Microbiome', 'with', 'High', 'Plant', 'Biomass-Degrading', 'Capacity', 'Herbivores', 'can', 'gain', 'indirect', 'access', 'to', 'recalcitrant', 'carbon', 'present', 'in', 'plant', 'cell', 'walls', 'through', 'symbiotic', 'associations', 'with', 'lignocellulolytic', 'microbes', '.'], ['Common', 'measures', 'are', 'functional', 'diversity', ',', 'eveness', ',', 'dissimilarity', '.'], ['Woody', 'debris', 'type', 'Woody', 'debris', 'type', 'is', 'a', 'positioning', 'information', 'in', 'categories', '11-Jan', ',', 'plus', 'diverse', 'other', 'information', '.'], ['The', 'results', 'revealed', 'that', 'the', 'frequency', 'of', 'drought', 'has', 'increased', 'in', 'the', '21st', 'century', 'with', 'the', 'drying', 'trend', 'occurring', 'in', 'most', 'of', 'China', '.'], ['From', 'a', 'spatial', 'point', 'of', 'view', ',', 'all', 'indices', 'clearly', 'singled', 'out', 'Corsica', 'Island', 'as', 'having', 'higher', 'average', 'originality', 'and', 'specialization', '.'], ['Effective', 'global', 'stewardship', 'of', 'plant', 'biodiversity', 'in', 'the', 'Anthropocene', 'will', 'require', 'integrated', 'frameworks', 'for', 'observing', ',', 'modeling', 'and', 'forecasting', 'the', 'different', 'forms', 'of', 'anthropogenic', 'biodiversity', 'change', 'processes', 'at', 'regional', 'landscape', 'scales', ',', 'towards', 'conserving', 'biodiversity', 'within', 'the', 'novel', 'plant', 'communities', 'created', 'and', 'sustained', 'by', 'human', 'systems', '.'], ['A', 'subset', 'of', '12', 'CSPs', 'were', 'selected', 'according', 'to', 'an', 'successional', 'age', 'and', 'a', 'diversity', 'gradient', ';', 'based', 'on', 'the', 'original', 'age', 'classifications', ':', 'young', '(', 'CSPs', '16,17,25,26', ')', ',', 'medium', '(', 'CSPs', '1,5,8,9', ')', 'and', 'old', '(', 'CSPs', '2,4,12,13', ')', '.'], ['city-of-ny_fuhs-xmg2', 'Urban', 'Park', 'Ranger', 'Animal', 'Condition', 'Response', 'This', 'dataset', 'contains', 'information', 'about', 'requests', 'for', 'animal', 'assistance', ',', 'relocation', ',', 'and/or', 'rescue', 'completed', 'by', 'the', '...'], ['The', 'expression', 'of', 'fetidin/lysenins', 'in', 'E.', 'fetida', 'was', 'not', 'affected', 'upon', 'the', 'challenge', 'with', 'compost', 'microbiota', ',', 'suggesting', 'more', 'substantial', 'changes', 'in', 'the', 'regulation', 'of', 'the', 'gene', 'expression', '.'], ['R', 'uses', 'rarefy', '(', ')', 'from', 'the', 'package', 'vegan', 'to', 'estimated', 'species', 'number', 'for', 'a', 'given', 'number', 'of', 'individuals', '.'], ['Commands', ':', 'as.taxo', '(', ')', ',', 'divc', '(', ')', 'Estimated', 'number', 'of', 'caterpillar', 'OTUs', '(', 'Hill', 'number', '2', ')', 'Phylogenetic', 'biodiversity', '(', 'PD_boot', ')', ',', 'PD_boot', 'Phylogenetic', 'biodiversity', '(', 'PD_boot', ':', 'bootstrapped', 'PD', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'bootstrapped', 'PD', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MPD_boot', ')', ',', 'MPD_boot', 'Phylogenetic', 'biodiversity', '(', 'MPD_boot', ':', 'bootstrapped', 'MPD', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'bootstrapped', 'MPD', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MNTD_boot', ')', ',', 'MNTD_boot', 'Phylogenetic', 'biodiversity', '(', 'MNTD_boot', ':', 'bootstrapped', 'MNTD', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'bootstrapped', 'MNTD', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'PD', ')', ',', 'PD', 'Phylogenetic', 'biodiversity', '(', 'PD', ':', 'phylogenetic', 'diversity', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'phylogenetic', 'diversity', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MPD', ')', ',', 'MPD', 'Phylogenetic', 'biodiversity', '(', 'MPD', ':', 'mean', 'phylogenetic', 'diversity', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'mean', 'phylogenetic', 'diversity', 'of', 'caterpillars', 'Phylogenetic', 'biodiversity', '(', 'MNTD', ')', ',', 'MNTD', 'Phylogenetic', 'biodiversity', '(', 'MNTD', ':', 'mean', 'nearest', 'taxon', 'distance', 'of', 'caterpillars', ')', 'dimensionless', 'real', 'Phylogenetic', 'biodiversity', 'Phylogenetic', 'biodiversity', 'mean', 'nearest', 'taxon', 'distance', 'of', 'caterpillars', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', '(', 'tree', 'richness', ')', ',', 'tree', 'richness', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', '(', 'tree', 'richness', ':', 'Tree', 'species', 'richness', ')', 'dimensionless', 'real', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', 'Tree', 'species', 'identifier', 'in', 'the', 'Main', 'Experiment', 'design', 'Tree', 'species', 'richness', 'Functional', 'biodiversity', '(', 'func_div_rao', ')', ',', 'func_div_rao', 'Functional', 'biodiversity', 'uses', 'functional', 'traits', 'of', 'organisms', 'as', 'a', 'basis', 'to', 'quantifying', 'biodiversity', '.'], ['Our', 'conversion', 'of', 'carbon', 'to', 'CO2', 'increased', 'in', 'precision', ',', 'which', 'increased', 'the', 'world', 's', 'carbon', 'footprint', 'by', 'approximately', '1', '%', '.'], ['In', 'the', 'Pilot', 'experiment', ',', 'vegetation', 'layer', 'is', 'referred', 'to', 'as', '``', 'stratum', 'stratum', 'and', 'is', 'measured', 'in', '50cm', 'thick', 'layers', 'above', 'ground', '.'], ['Yet', 'these', 'biodiversity', 'changes', 'and', 'others', 'caused', 'directly', 'by', 'human', 'populations', 'and', 'their', 'use', 'of', 'land', 'tend', 'to', 'co-occur', 'as', 'long-term', 'biodiversity', 'change', 'processes', 'in', 'the', 'Anthropocene', '.'], ['The', 'present', 'study', 'may', 'facilitate', 'a', 'better', 'understanding', 'of', 'the', 'toxicity', 'of', 'BDE-209', 'toward', 'the', 'soil', 'environment', '.'], ['Our', 'meta-analysis', 'provides', 'support', 'for', 'wider', 'use', 'of', 'retention', 'forestry', 'since', 'it', 'moderates', 'negative', 'harvesting', 'impacts', 'on', 'biodiversity', '.'], ['In', 'particular', ',', 'drought-sensitive', 'species', '(', 'i.e', '.'], ['rare', 'faction', 'of', 'functional', 'groups', 'of', 'target', 'group', '.'], ['For', 'this', 'purpose', 'we', 'classified', 'the', 'species', 'into', 'seven', 'functional', 'groups', '.'], ['(', 'Sub', ':', 'Species', 'binomial', ')', 'The', 'scientific', 'species', 'fullnames', 'are', 'based', 'on', 'the', '``', 'Flora', 'of', 'China', 'China', 'identified', 'by', 'Teng', 'Fang', 'and', 'verified', 'by', 'Helge', 'Bruelheide', '(', 'trees', ')', 'and', 'Alexandra', 'Erfmeier', '(', 'herbs', ')', '.'], ['Conclusion', 'This', 'study', 'may', 'provide', 'fundamentally', 'new', 'insights', 'into', 'the', 'role', 'of', 'chemolithoautotrophic', 'and', 'photoautotrophic', 'bacterial', 'diversity', 'in', 'biochemical', 'carbon', 'cycling', 'in', 'barren', 'saline', 'soils', '.'], ['Not', 'all', 'changes', ',', 'however', ',', 'result', 'in', 'positive', 'effects', 'on', 'the', 'assessed', 'community', 'metrics', '.'], ['rogenhoferi', ')', ',', 'Crematogaster', 'cf', '.'], ['Acta', 'Oecologica', '61', ':', '32-40', '.'], ['It', 'would', 'be', 'no', 'more', 'appropriate', 'to', 'ignore', 'barcode', 'data', 'in', 'a', 'species', 'inventory', 'than', 'it', 'would', 'be', 'to', 'ignore', 'adult', 'genitalia', 'variation', 'or', 'caterpillar', 'ecology', '.'], ['(', 'ppm', ')', 'number', '#', 'decimal', 'st_dev_p_bicar_ppm', 'data/p_bicar.csv', 'csv', 'ph', 'vegetation_class', 'Vegetation', 'Class', 'string', '#', 'string', 'vegetation_class', 'dir_quad', 'DIR', '.'], ['For', 'the', 'national', 'terrestrial', 'ecosystem', 'mapping', 'effort', ',', 'the', 'original', '28', 'lithology', 'classes', 'were', 'reclassified', 'into', 'a', 'set', 'of', '18', 'lithologies', 'that', 'typically', 'control', 'or', 'influence', 'the', 'distribution', 'of', 'vegetation', 'types', '(', 'Kruckeberg', ',', '2002', ')', '.'], ['mutualism', ',', 'predation', ')', 'might', 'be', 'an', 'important', 'moderator', 'of', 'biodiversity-ecosystem', 'function', 'relationships', '.'], ['Microbial', 'biomass', 'and', 'diversity', 'increased', 'in', 'mineral', 'soil', 'layers', ',', 'with', 'a', 'weak', 'negative', 'effect', 'in', 'organic', 'soil', 'layers', ',', 'indicating', 'that', 'the', 'mixing', 'of', 'soil', 'layers', 'by', 'earthworms', '(', 'bioturbation', ')', 'may', 'homogenize', 'microbial', 'communities', 'across', 'soil', 'layers', '.'], ['Trap', 'location', 'within', 'the', 'Comparative', 'Study', 'Sites', '.'], ['In', 'each', 'CSP', 'there', 'is', 'only', 'one', 'neighbourhood', 'per', 'species', '.'], ['--', '-', '6', 'digit', 'metal', 'tags', 'starting', 'with', '3', 'were', 'also', 'used', 'for', 'woody', 'debris', 'items', '--', 'the', 'reference', 'file', 'linking', 'metal', 'tags', 'to', 'tree', 'individual', 'tags', 'is', 'called', '``', 'Tree', 'stem', 'reference', 'list', 'for', 'the', 'Comparative', 'Study', 'Sites', '(', 'CSPs', ')', ')', 'Silver', 'ID', 'given', 'by', 'Anja', ',', 'can', 'be', 'given', 'to', 'a', 'woody', 'debris', 'item', 'or', 'to', 'a', 'standing', 'dead', 'tree', 'or', 'snagCSP', 'metal', 'tag', 'number', '(', 'trees', ',', 'woody', 'debris', ')', ';', 'Datagroup', 'description', ':', 'CSP', 'metal', 'tag', 'number', '(', 'trees', ',', 'woody', 'debris', ')', ';', 'Datagroup', 'description', ':', 'CSP', 'tree', 'individuals', 'were', 'marked', 'mostly', 'with', 'metal', 'tags', 'but', 'also', 'additional', 'tags', 'were', 'used', '.'], ['string', '#', 'string', 'dir_quad', 'int_ext', 'INT/EXT', 'string', '#', 'string', 'int_ext', 'a_b', 'A', '&', 'B', 'string', '#', 'string', 'a_b', 'data_labels', 'Data', 'Labels', 'string', '#', 'string', 'data_labels', 'series_name', 'Series', 'Name', 'string', '#', 'string', 'series_name', 'sample_1', 'Sample', '#', '1', 'number', '#', 'decimal', 'sample_1', 'sample_2', 'Sample', '#', '2', 'number', '#', 'decimal', 'sample_2', 'sample_3', 'Sample', '#', '3', 'number', '#', 'decimal', 'sample_3', 'sample_4', 'Sample', '#', '4', 'number', '#', 'decimal', 'sample_4', 'average_ca_total_bases', 'Average', 'Ca', 'Total', 'Bases', '(', '%', ')', 'number', '#', 'decimal', 'average_ca_total_bases', 'st_dev_ca_total_bases', 'St.', 'Dev', 'Ca', 'Total', 'Bases', '(', '%', ')', 'number', '#', 'decimal', 'st_dev_ca_total_bases', 'data/catotal_bases.csv', 'csv', 'cu', 'vegetation_class', 'Vegetation', 'Class', 'string', '#', 'string', 'vegetation_class', 'dir_quad', 'DIR', '.'], ['Our', 'results', 'indicate', 'substantial', 'differences', 'in', 'the', 'conservation', 'status', 'of', 'PNVs', '.'], ['This', 'highlights', 'the', 'imbalance', 'of', 'exploration', 'within', 'these', 'areas', 'rather', 'than', 'any', 'reduction', 'in', 'biodiversity', '.'], ['With', 'a', 'TCE', 'dose', 'increase', 'by', 'more', 'than', '10', 'mg/kg', ',', 'the', 'TCE', 'degradation', 'decreases', 'due', 'to', 'the', 'toxic', 'effect', 'of', 'this', 'pollutant', 'on', 'microbial', 'consortium', 'activity', '.'], ['Central', 'components', 'of', 'the', 'J-C', 'hypothesis', 'are', 'non-competitive', 'effects', 'of', 'density', '-', 'and', 'distance', '#NAME?', ',', 'thereby', 'two', 'drivers', 'that', 'contribute', 'independently', 'to', 'species', 'coexistence', ',', 'but', 'that', 'are', 'ultimately', 'linked', 'in', 'the', 'field', '.'], ['Our', 'species', 'set', 'represents', 'a', 'range', 'of', 'vertebrate', 'taxa', '(', 'primarily', 'mammals', ',', 'birds', ',', 'amphibians', ',', 'and', 'reptiles', ')', 'and', 'diverse', 'life', 'histories', '.'], ['2015', ':', 'Trade-offs', 'between', 'physical', 'and', 'chemical', 'carbon-based', 'leaf', 'defence', ':', 'Of', 'intraspecific', 'variation', 'and', 'trait', 'evolution', '(', 'Journal', 'of', 'Ecology', ')', 'David', 'Eichenberg', 'Botanik', 'Halle', 'Leipzig', 'Germany', 'Helge', 'Bruelheide', 'Christian', 'Ristok', 'Oliver', 'Purschke', 'German', 'Centre', 'for', 'Integrative', 'Biodiversity', 'Research', '(', 'iDiv', ')', 'Halle-Jena-Leipzig', 'Deutscher', 'Platz', '5e', 'Leipzig', 'Germany', '49', '(', '0', ')', '341-97-33121', '########', 'en_US', '1', '.'], ['Finally', ',', 'we', 'observed', 'that', 'the', 'originality', 'index', 'based', 'on', 'niche', 'traits', 'might', 'be', 'used', 'as', 'an', 'informative', 'biodiversity', 'indicator', 'because', 'we', 'showed', 'it', 'is', 'sensitive', 'to', 'different', 'land', 'use', 'classes', 'along', 'a', 'landscape', 'artificialization', 'gradient', '.'], ['Where', 'is', 'the', 'UK', 's', 'pollinator', 'biodiversity', '?'], ['The', 'respective', 'category', 'can', 'be', 'taxonomic', 'or', 'functional', ',', 'depending', 'on', 'the', 'subject', 'of', 'the', 'respective', 'study', '.'], ['I', 'show', 'that', 'there', 'are', 'large', 'and', 'growing', 'amounts', 'of', 'data', 'available', 'for', 'tropical', 'South', 'America', '.'], ['Here', 'we', 'summarize', 'the', 'various', 'topographical', ',', 'entomological', ',', 'parasitological', ',', 'human', 'ecological', 'and', 'socio-', 'economic', 'factors', ',', 'which', 'are', 'crucial', 'and', 'shape', 'malaria', 'transmission', 'in', 'forested', 'areas', '.'], ['number', '#', 'decimal', 'carbon', 'total', 'total', 'The', 'total', 'area', 'when', 'adding', 'cropland', ',', 'grazing', 'land', ',', 'forest', 'land', ',', 'fishing', 'ground', ',', 'built', 'up', 'land', 'and', 'carbon', 'footprints', 'together', 'number', '#', 'decimal', 'total', 'qscore', 'QScore', 'A', 'data', 'quality', 'scoring', 'system', 'to', 'show', 'a', 'country', 's', 'data', 'quality', 'which', 'is', 'comprised', 'of', 'two', 'components', ',', 'a', 'timeline', 'score', '(', 'excluding', 'latest', 'year', 'and', 'denoted', 'by', 'a', 'number', 'from', '1', 'to', '3', ')', 'and', 'a', 'latest', 'year', 'score', '(', 'denoted', 'by', 'a', 'letter', 'from', 'A', 'to', 'D', ')', '.'], ['The', 'vegetation', 'attributes', 'best', 'predicted', 'by', 'texture', 'are', 'relevant', 'in', 'the', 'face', 'of', 'two', 'of', 'the', 'gravest', 'threats', 'to', 'biosphere', 'integrity', ':', 'climate', 'change', 'and', 'biodiversity', 'loss', '.'], ['abundance', 'CSP', 'ectomycorrhiza', 'fungi', 'saprophytes', 'successional', 'age', 'Find', 'the', 'list', 'of', 'keywords', 'here', ':', 'Taxon', 'CSP', 'age', 'class', 'abundance', 'Taxonomic.assignment', 'List', 'of', 'headers', 'of', 'the', 'data', 'columns', 'in', 'this', 'dataset', 'Permission', 'is', 'granted', 'to', 'anybody', 'to', 'access', ',', 'use', 'and', 'publish', 'all', 'open', 'for', 'public', 'data', 'freely', '.'], ['Biodiversity', 'and', 'Ecosystem', 'Multi-Functionality', ':', 'Observed', 'Relationships', 'in', 'Smallholder', 'Fallows', 'in', 'Western', 'Kenya', 'Recent', 'studies', 'indicate', 'that', 'species', 'richness', 'can', 'enhance', 'the', 'ability', 'of', 'plant', 'assemblages', 'to', 'support', 'multiple', 'ecosystem', 'functions', '.'], ['Agricultural', 'expansion', 'and', 'intensification', 'are', 'major', 'threats', 'to', 'global', 'biodiversity', ',', 'ecological', 'functions', ',', 'and', 'ecosystem', 'services', '.'], ['Only', 'completely', 'developed', 'leaves', 'were', 'sampled', ',', 'without', 'visible', 'herbivore', 'damage', 'and', 'preferably', 'free', 'of', 'leaf', 'fungi', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP21', ')', ',', 'CSP21', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['DESCRIPTION', 'From', '2000-2011', ',', 'the', 'FAA', 'released', 'the', 'number', 'of', 'incidents', 'where', 'birds', 'have', 'struck', 'a', 'plane', '.'], ['Plant', 'Diversity', 'Impacts', 'Decomposition', 'and', 'Herbivory', 'via', 'Changes', 'in', 'Aboveground', 'Arthropods', 'Loss', 'of', 'plant', 'diversity', 'influences', 'essential', 'ecosystem', 'processes', 'as', 'aboveground', 'productivity', ',', 'and', 'can', 'have', 'cascading', 'effects', 'on', 'the', 'arthropod', 'communities', 'in', 'adjacent', 'trophic', 'levels', '.'], ['--', '--', 'For', 'general', 'comparisons', 'between', 'sites', 'subfamily', 'data', 'are', 'usefull', '.'], [')', ',', 'so', 'that', '6', 'samples', 'exist', 'per', 'CSP', '.'], ['life', 'form', 'Abundance', '(', 'CSP01', ')', ',', 'CSP01', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['The', 'direction', 'of', 'the', 'pendular', 'was', 'measured', 'by', 'means', 'of', 'a', 'compass.', '--', '-', 'Stem', 'slenderness', 'is', 'calculated', 'as', 'total', 'height', 'divided', 'by', 'stem', 'diameter', 'stem', 'inclination', 'Stem', 'morphology', '(', 'stem_azi', ')', ',', 'gon', 'stem_azi', 'Stem', 'morphology', 'is', 'measured', 'as', 'stem', 'inclination', 'and', 'stem', 'azimuth', '.'], ['Moreover', ',', 'we', 'show', 'that', 'multiple', 'components', 'of', 'tree', 'diversity', 'can', 'synergistically', 'affect', 'species', 'richness', 'and', 'phylogenetic', 'diversity', 'of', 'lepidopteran', 'larvae', '.'], ['However', ',', 'currently', 'we', 'lack', 'the', 'ability', 'to', 'predict', 'the', 'consequences', 'of', 'realistic', 'species', 'loss', 'on', 'ecosystem', 'processes', '.'], ['BEF-China', 'Main', 'Experiment', '117.8998', '118.1483', '29.2852', '29.10178', '########', '########', 'All', 'EFN-visiting', 'arthropods', 'All', 'EFN-visiting', 'arthropods', 'mstaab', 'aklein', 'jpeters', 'Main', 'Experiment', ':', 'Visitors', 'of', 'extrafloral', 'nectaries', '(', '2012', ')', 'Trees', 'with', 'extrafloral', 'nectaries', '(', 'EFN', ')', 'are', 'common', 'in', 'tropical', 'and', 'subtropical', 'forests', 'and', 'the', 'presence', 'of', 'EFN', 'trees', 'within', 'a', 'tree', 'community', 'may', 'influence', 'tree', 'growth', '.'], ['Allometries', '(', 'Allometrie', ')', ',', 'dimensionless', 'Allometrie', 'Data', 'to', 'derive', 'tree', 'or', 'sapling', 'allometries', ',', 'as', 'well', 'as', 'allometric', 'equations', '.'], ['Commands', ':', 'as.taxo', '(', ')', ',', 'divc', '(', ')', '(', 'div_abgd', ':', 'Observed', 'number', 'of', 'caterpillar', 'OTUs', 'based', 'on', 'ABGD', 'method', ')', 'dimensionless', 'real', 'Taxonomic', 'biodiversity', 'Taxon', 'diversity', 'can', 'be', 'given', 'as', 'species', 'richness', ',', 'or', 'other', 'diversity', 'indices', '.'], ['Toxicokinetic', 'studies', 'aiming', 'to', 'completely', 'elucidate', 'the', 'As', 'metabolic', 'pathway', 'would', 'therefore', 'benefit', 'from', 'incorporating', 'the', 'metabolic', 'potency', 'of', 'human', 'gut', 'microbiota', '.'], ['Our', 'results', 'highlight', 'the', 'need', 'for', 'fine-scale', 'climate', 'information', 'to', 'assist', 'agro-ecological', 'communities', 'in', 'developing', 'effective', 'adaptive', 'management', '.'], ['Living', 'status', '(', 'Dead', ')', ',', 'Dead', 'if', 'an', 'organism', 'is', 'dead', 'or', 'alive', 'or', 'damaged', '(', 'Dead', ':', 'indicator', 'for', 'species', 'dead', '(', '1', ')', 'or', 'alive', '(', '0', ')', ')', 'if', 'an', 'organism', 'is', 'dead', 'or', 'alive', 'or', 'damaged', 'Living', 'status', 'if', 'an', 'organism', 'is', 'dead', 'or', 'alive', 'or', 'damaged', 'indicator', 'for', 'species', 'dead', '(', '1', ')', 'or', 'alive', '(', '0', ')', 'Plant', 'height', '(', 'Height_P', ')', ',', 'cm', 'Height_P', 'measuring', 'tree', 'height', '(', 'Height_P', ':', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'photosynthetically', 'active', 'tissue', ')', 'dimensionless', 'real', 'Plant', 'height', 'measuring', 'tree', 'height', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'photosynthetically', 'active', 'tissue', 'Plant', 'height', '(', 'Height_G', ')', ',', 'cm', 'Height_G', 'measuring', 'tree', 'height', '(', 'Height_G', ':', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'still', 'living', 'tissue', ')', 'dimensionless', 'real', 'Plant', 'height', 'measuring', 'tree', 'height', 'Height', 'of', 'the', 'seedling', 'up', 'to', 'the', 'last', 'still', 'living', 'tissue', 'Plant', 'leaf', 'number', '(', 'Leaves_Liv', ')', ',', 'Leaves_Liv', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', '(', 'Leaves_Liv', ':', 'Number', 'of', 'living', 'leaves', ')', 'dimensionless', 'real', 'Plant', 'leaf', 'number', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', 'Number', 'of', 'living', 'leaves', 'Plant', 'leaf', 'number', '(', 'Leaves_Dam', ')', ',', 'Leaves_Dam', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', '(', 'Leaves_Dam', ':', 'Number', 'of', 'damaged', 'leaves', ')', 'dimensionless', 'real', 'Plant', 'leaf', 'number', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', 'Number', 'of', 'damaged', 'leaves', 'Plant', 'leaf', 'number', '(', 'Leaves_Dead', ')', ',', 'Leaves_Dead', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', '(', 'Leaves_Dead', ':', 'Number', 'of', 'dead', 'leaves', 'on', 'seedling', ')', 'dimensionless', 'real', 'Plant', 'leaf', 'number', 'Leaf', 'number', 'count', 'or', 'classification', 'of', 'leaf', 'numbers', 'of', 'plant', 'under', 'study', 'Number', 'of', 'dead', 'leaves', 'on', 'seedling', 'Herbivore', 'damage', '(', 'Damage_pro', ')', ',', 'in', 'percent', 'Damage_pro', 'Herbivore', 'damage', 'in', 'percentage', 'or', 'as', 'herbivory', 'classes', 'e.g', '.'], ['Ways', 'to', 'quantify', 'precipitation', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mmmeasured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ';', 'rainfall', 'amount', 'open', 'field', '(', 'vaisala', ')', 'mmmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'peak', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'of', 'the', 'five', 'highest', 'five', 'minute', 'intensities', 'open', 'field', '(', 'vaisala', ')', 'measured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mmmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'peak', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '(', 'am_b', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mm', '--', 'rainfall', 'amount', '(', 'collecting', 'bottle', ')', '--', 'measured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ')', 'millimeter', 'real', 'Precipitation', 'Precipitation', 'measured', 'at', 'the', 'climate', 'station', 'or', 'locally', 'within', 'sites', '.'], ['decay', 'class', 'of', 'downed', 'wood', 'Organisms', 'found', 'on', 'or', 'in', 'specimen', '(', 'ter', ')', ',', 'dimensionless', 'ter', 'Organisms', 'found', 'in', 'the', 'specimen', 'under', 'study', '.'], ['woody', 'recruits', ')', 'in', 'the', 'herb', 'layer', 'can', 'act', 'as', 'an', 'indicator', 'for', 'regeneration', '.'], ['Using', 'a', 'Multi-Trait', 'Approach', 'to', 'Manipulate', 'Plant', 'Functional', 'Diversity', 'in', 'a', 'Biodiversity-Ecosystem', 'Function', 'Experiment', 'A', 'frequent', 'pattern', 'emerging', 'from', 'biodiversity-ecosystem', 'function', 'studies', 'is', 'that', 'functional', 'group', 'richness', 'enhances', 'ecosystem', 'functions', 'such', 'as', 'primary', 'productivity', '.'], ['The', 'data', 'might', 'provide', 'valuable', 'information', 'to', 'be', 'compared', 'with', 'data', 'from', 'the', 'main', 'experiment', '.'], ['We', 'assessed', 'leaf', 'toughness', ',', 'leaf', 'total', 'phenolics', 'and', 'tannin', 'concentrations', 'for', '51', 'subtropical', 'tree', 'species', '.'], ['Samples', 'were', 'analyzed', 'over', 'the', 'depth', 'profile', 'of', 'each', 'CSP', '(', 'see', 'detailed', 'methods', 'below', ')', 'and', 'analyzed', 'for', 'phospholipid', 'fatty', 'acid', 'profiles', ',', 'which', 'represent', 'both', 'the', 'biomass', 'and', 'broad', 'community', 'structure', 'of', 'the', 'soil', 'microbial', 'community', 'including', 'broad', 'groups', 'of', 'bacteria', 'and', 'fungi', '.'], ['(', 'abundance_size55', ':', 'Features', 'of', 'sediment', 'Rockmaterial', '/', 'Description', 'of', 'artefacts', '/', 'Abundance/Size', ':', 'Soil', 'horizon', 'description', 'II', ';', 'abundance_size55', ')', 'Basic', 'information', 'on', 'soil', 'properties', ',', 'according', 'to', '``', 'Eckelmann', ',', 'W.', ',', 'Sponagel', ',', 'H.', ',', 'Grottenthaler', ',', 'W.', ',', 'Hartmann', ',', 'J.', 'K.', ',', 'Hartwich', ',', 'R.', ',', 'Janetzko', ',', 'P.', ',', '...', '&', 'Traidl', ',', 'R.', '(', '2005', ')', '.'], ['In', 'addition', ',', 'heterospecific', 'pollen', 'grains', 'were', 'deposited', 'on', 'most', 'stigmas', 'of', 'both', 'I.', 'noli-tangere', 'and', 'I.', 'textori', 'flowers', 'that', 'were', 'situated', 'within', '2', 'm', 'of', 'flowers', 'of', 'the', 'other', 'species', 'resulting', 'in', 'depressed', 'fruit', 'set', '.'], ['However', ',', 'the', 'model', 'was', 'unable', 'to', 'match', 'the', 'SAR', 'and', 'beta-diversity', 'simultaneously', '.'], ['BEF', 'research', 'plot', 'where', 'the', 'abundance', 'of', 'species', 'x', 'is', 'estimated', 'Abundance', '(', 'CSP09', ')', ',', 'CSP09', 'Number', 'of', 'individuals', 'determined', 'for', 'the', 'respective', 'category', '.'], ['Helper', '(', 'hei.len.rem.kn', ')', ',', 'dimensionless', 'hei.len.rem.kn', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', '(', 'hei.len.rem.kn', ':', 'remark', 'on', 'heigtht', '..', 'length', 'by', 'Karin', ',', 'mostly', 'copying', 'those', 'entries', 'that', 'could', 'not', 'be', 'converted', 'to', 'numbersHelper', ';', 'Datagroup', 'description', ':', 'Helper', ')', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'Helper', 'Helper', 'column', 'to', 'understand', 'other', 'columns', 'in', 'this', 'data', 'set', 'remark', 'on', 'heigtht', '..', 'length', 'by', 'Karin', ',', 'mostly', 'copying', 'those', 'entries', 'that', 'could', 'not', 'be', 'converted', 'to', 'numbersHelper', ';', 'Datagroup', 'description', ':', 'Helper', 'Woody', 'debris', 'dimensions', '(', 'broken', 'at', ')', ',', 'meter', 'broken', 'at', 'Woody', 'debris', 'dimensions', 'consist', 'of', 'base', 'diameter', ',', 'top', 'diameter', ',', 'and', 'length', '.'], ['Successional', 'age', 'of', 'a', 'forest', 'plot', 'Successional', 'stage', 'describes', 'the', 'amount', 'of', 'time', 'a', 'given', 'forest', 'had', 'to', 'grow', 'without', 'further', 'disturbance', '.'], ['CSPs', ':', 'Soil', 'fungal', 'metagenome', 'from', '12', 'CSPs', 'based', 'on', 'the', 'fungal', 'ITS', 'rDNA', 'pyrotags', '/datasets/397', 'ASCII', '1', 'column', ',', 'Operational', 'taxonomic', 'unit', '(', 'OTU', ')', '(', 'Taxon', ')', ',', 'Taxon', 'In', 'phylogeny', 'an', 'operational', 'taxonomic', 'unit', '(', 'OTU', ')', 'is', 'an', 'operational', 'definition', 'of', 'a', 'species', 'or', 'group', 'of', 'species', 'often', 'used', 'when', 'only', 'DNA', 'sequence', 'data', 'is', 'available', '.'], ['year', 'of', 'species', 'description', 'Global', 'unique', 'identifier', '(', 'global', 'unique', 'identifier', ')', ',', 'global', 'unique', 'identifier', 'Global', 'unique', 'identifier', 'for', 'the', 'respecive', 'species', 'provided', 'by', 'different', 'sources', 'for', 'taxonomic', 'affiliation', '.'], ['Ways', 'to', 'quantify', 'precipitation', ':', 'rainfall', 'amount', 'open', 'field', '(', 'collecting', 'bottle', ')', 'mmmeasured', 'by', 'a', 'rainfall', 'collecting', 'bottle', ';', 'rainfall', 'amount', 'open', 'field', '(', 'vaisala', ')', 'mmmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'peak', 'rainfall', 'intensity', 'open', 'field', '(', 'vaisala', ')', 'mm/hmeasured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'average', 'of', 'the', 'five', 'highest', 'five', 'minute', 'intensities', 'open', 'field', '(', 'vaisala', ')', 'measured', 'by', 'the', 'vaisala', 'sensor', '--', '-', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mmmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'average', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '--', '-', 'peak', 'rainfall', 'intensity', '(', 'tipping-bucket', ')', 'mm/hmeasured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', '(', 'am_t', ':', 'rainfall', 'amount', '(', 'tipping-bucket', ')', 'mm', '--', 'rainfall', 'amount', '(', 'tipping-bucket', ')', '--', 'measured', 'by', 'the', 'tipping-bucket', 'rain', 'gauge', ')', 'millimeter', 'real', 'Precipitation', 'Precipitation', 'measured', 'at', 'the', 'climate', 'station', 'or', 'locally', 'within', 'sites', '.'], ['Compromise', 'solutions', 'tend', 'to', 'focus', 'agricultural', 'expansion', 'along', 'existing', 'transportation', 'corridors', 'and', 'in', 'already', 'disturbed', 'areas', '.'], ['total', 'sum', 'of', 'lipids', 'found', ';', ';', 'Wu', 'et', 'al.', ',', '2012', '(', 'see', 'metadata', 'sheet', ',', 'doi:10.1007/s10021-012-9533-3', ')', '(', 'derived', 'from', 'datagroup', ')', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', '(', 'Bacteria', ')', ',', 'nmol', 'g', 'dry', 'soil-1', 'Bacteria', 'Phospholipid', 'fatty', 'acid', 'profiles', '(', 'PLFA', ')', '.'], ['Later', ',', 'Arion', 'vulgaris', 'slugs', '(', 'formerly', 'known', 'as', 'A.', 'lusitanicus', ';', 'Gastropoda', ':', 'Arionidae', ')', 'were', 'added', 'and', 'allowed', 'to', 'freely', 'choose', 'among', 'the', 'available', 'plant', 'species', '.'], ['Leaf', 'area', 'index', 'measured', 'above', 'the', 'planted', 'seedlings', '(', '1m', 'height', ')', 'in', 'each', 'subplot', 'Inclination', '(', 'Slope', ')', ',', 'Slope', 'Inclination', '``', 'is', 'the', 'angular', 'distance', 'of', 'the', 'orbital', 'plane', 'from', 'the', 'plane', 'of', 'reference', '(', 'usually', 'the', 'primary', 's', 'equator', 'or', 'the', 'ecliptic', ')', ',', 'normally', 'stated', 'in', 'degrees', 'degrees', '(', 'Wikipedia', ',', '2011', ')', '.'], ['These', 'areas', 'are', 'within', '300ft', 'of', ':', 'open', 'water', ',', 'inland', 'water', 'bodies', 'greater', 'than', '2', 'acres', 'in', 'size', ',', 'open', 'space', 'greater', 'than', '2', 'acres', ',', 'the', 'shoreline', '.'], ['We', 'summarize', 'the', 'process', 'and', 'results', 'for', 'a', 'large', 'set', 'of', 'the', 'species', 'of', 'two', 'speciose', 'subfamilies', 'of', 'ACG', 'skipper', 'butterflies', '(', 'Hesperiidae', ')', 'and', 'emphasize', 'the', 'effectiveness', 'of', 'barcoding', 'these', 'species', '(', 'which', 'are', 'often', 'difficult', 'and', 'time-consuming', 'to', 'identify', ')', '.'], ['(', 'Iridomyrmex', 'anceps', ')', ',', 'Iridomyrmex', 'anceps', '(', 'Iridomyrmex', 'anceps', ':', 'Arthropod', 'species', 'or', 'morphospecies', ')', 'Arthropod', 'species', 'or', 'morphospecies', '(', 'Crematogaster', 'cf', '.'], ['Secondly', ',', 'to', 'analyze', 'the', 'immunological', 'profile', 'in', 'both', 'earthworm', 'species', ',', 'the', 'activity', 'and', 'expression', 'of', 'lysozyme', ',', 'pattern', 'recognition', 'protein', 'CCF', ',', 'and', 'antimicrobial', 'proteins', 'with', 'hemolytic', 'function', ',', 'fetidin', 'and', 'lysenins', ',', 'have', 'been', 'assessed', '.'], ['We', 'note', 'that', 'A.', 'cerana', 'mtDNA', 'is', 'included', 'because', 'it', 'is', 'considered', 'a', 'potentially', 'invasive', 'honey', 'bee', 'species', 'and', 'monitoring', 'for', 'its', 'occurrence', 'is', 'in', 'practice', 'regionally', ',', 'including', 'in', 'Australia', ',', 'New', 'Zealand', 'and', 'the', 'USA', '.'], ['Source', ':', 'Last', 'updated', 'at', ':', '########', 'License', '-', 'Creative', 'Commons', 'Attribution', '4', 'CC-BY', 'download_json_1', 'id', 'id', 'integer', '#', 'integer', 'id', 'name', 'name', 'string', '#', 'string', 'name', 'parentlayerid', 'parentLayerId', 'integer', '#', 'integer', 'parentlayerid', 'defaultvisibility', 'defaultVisibility', 'boolean', '#', 'boolean', 'defaultvisibility', 'sublayerids', 'subLayerIds', 'string', '#', 'string', 'sublayerids', 'minscale', 'minScale', 'boolean', '#', 'boolean', 'minscale', 'maxscale', 'maxScale', 'boolean', '#', 'boolean', 'maxscale', 'data/download_json_1.csv', 'csv', 'original/download-json-1.json', 'original/download-json-1.json', 'json', 'application/json', '50778', 'original/wms-getcapabilities-2.html', 'original/wms-getcapabilities-2.html', 'html', 'text/html', '338470', 'agricultural', 'soil', 'analysis', 'arable', 'land', 'arable', 'land', 'groundwater', 'chemical', 'chemistry', 'continental', 'scale', 'earth', 'science', 'egdi', 'environment', 'europe', 'european', 'soil', 'analysis', 'forensic', 'chemistry', 'gemas', 'geochemical', 'geochemical', 'analysis', 'geochemical', 'mapping', 'geology', 'geoscientificinformation', 'grazing', 'land', 'groundwater', 'heavy', 'metals', 'ireland', 'land', 'lithosphere', 'mapping', 'metal', 'micka', 'pedosphere', 'science', 'soil', 'soil', 'nutrient', 'toxic', 'element', 'trace', 'element', 'water', 'geographic'], ['This', 'is', 'the', 'species', 'list', 'containing', 'bryophytes', '.'], ['Mean', 'density', 'of', 'litter', 'thrips', 'per', 'plots', 'in', 'the', 'tropics', 'and', 'subtropics', 'was', 'significantly', 'higher', 'than', 'that', 'in', 'the', 'temperate', 'region', '(', 'n=25', ',', 'p', '<', '0.05', ')', ',', 'but', 'the', 'average', 'density', 'was', 'not', 'significantly', 'different', 'between', 'tropical', 'and', 'subtropical', 'zones', '(', 'n=25', ',', 'p', '>', '0.05', ')', '.'], ['Soil', 'description', '(', 'according', 'to', '``', 'Bodenkundliche', 'Kartieranleitung', 'Kartieranleitung', ')', 'Basic', 'information', 'on', 'soil', 'properties', ',', 'according', 'to', '``', 'Eckelmann', ',', 'W.', ',', 'Sponagel', ',', 'H.', ',', 'Grottenthaler', ',', 'W.', ',', 'Hartmann', ',', 'J.', 'K.', ',', 'Hartwich', ',', 'R.', ',', 'Janetzko', ',', 'P.', ',', '...', '&', 'Traidl', ',', 'R.', '(', '2005', ')', '.'], ['This', 'is', 'the', 'best', 'estimate', 'of', 'the', 'total', 'number', 'of', 'species', 'in', 'Japanese', 'waters', 'and', 'indicates', 'that', 'more', 'than', '70', '%', 'of', 'Japan', 's', 'marine', 'biodiversity', 'remains', 'un-described', '.'], ['The', 'most', 'common', 'cause', 'is', 'snow', 'break', '(', '1', ')', ',', 'the', 'next', 'common', 'most', 'likely', 'is', 'being', 'crashed', 'by', 'a', 'fallen', 'tree', '(', '#ERROR!', '2', ')', '.'], ['Source', ':', 'Last', 'updated', 'at', ':', '3/6/2017', '[', 'License', '-', 'Creative', 'Commons', 'Attribution', '3', 'New', 'Zealand', '(', 'CC', 'BY', '3', 'NZ', ')', ']', '(', 'Other', 'biodiversity_vegetation_2002', 'lcdb2_name', 'LCDB2_NAME', 'string', '#', 'string', 'lcdb2_name', 'lcdb1_name', 'LCDB1_NAME', 'string', '#', 'string', 'lcdb1_name', 'gen_veg', 'GEN_VEG', 'string', '#', 'string', 'gen_veg', 'wetland', 'WETLAND', 'boolean', '#', 'boolean', 'wetland', 'minor_clsa', 'MINOR_CLSA', 'string', '#', 'string', 'minor_clsa', 'minor_clsb', 'MINOR_CLSB', 'string', '#', 'string', 'minor_clsb', 'minor_clsc', 'MINOR_CLSC', 'string', '#', 'string', 'minor_clsc', 'uncertain1', 'UNCERTAIN1', 'string', '#', 'string', 'uncertain1', 'uncertain2', 'UNCERTAIN2', 'string', '#', 'string', 'uncertain2', 'comments', 'COMMENTS', 'string', '#', 'string', 'comments', 'class_cor', 'CLASS_COR', 'string', '#', 'string', 'class_cor', 'bound_cor', 'BOUND_COR', 'string', '#', 'string', 'bound_cor', 'wetld_cor', 'WETLD_COR', 'string', '#', 'string', 'wetld_cor', 'field_com', 'FIELD_COM', 'string', '#', 'string', 'field_com', 'photo_1', 'PHOTO_1', 'string', '#', 'string', 'photo_1', 'photo1_id', 'PHOTO1_ID', 'string', '#', 'string', 'photo1_id', 'photo_east1', 'PHOTO_EAST1', 'integer', '#', 'integer', 'photo_east1', 'photo_nth1', 'PHOTO_NTH1', 'integer', '#', 'integer', 'photo_nth1', 'photo_2', 'PHOTO_2', 'string', '#', 'string', 'photo_2', 'photo2_id', 'PHOTO2_ID', 'string', '#', 'string', 'photo2_id', 'photo_east2', 'PHOTO_EAST2', 'integer', '#', 'integer', 'photo_east2', 'photo_nth2', 'PHOTO_NTH2', 'integer', '#', 'integer', 'photo_nth2', 'district', 'DISTRICT', 'string', '#', 'string', 'district', 'id', 'ID', 'integer', '#', 'integer', 'id', 'data/biodiversity_vegetation_2002.csv', 'csv', 'original/BIODIVERSITY_VEGETATION_2002.csv', 'original/BIODIVERSITY_VEGETATION_2002.csv', 'csv', 'text/csv', '3102121', 'original/BioVeg2002_read_me.txt', 'original/BioVeg2002_read_me.txt', 'txt', 'text/plain', '1609', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-1.zip', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-1.zip', 'zip', 'application/zip', '26642309', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-3.zip', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-3.zip', 'zip', 'application/zip', '22189678', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-4.zip', 'original/biodiversity-vegetation-bioveg-2002-gis-layer-4.zip', 'zip', 'application/zip', '11987022', 'biodiversity', 'coastal', 'ecology', 'ecosystem', 'land', 'cover', 'land', 'use', 'sand', 'dune', 'terrestrial', 'vegetation', 'waikato', 'wetland', 'environment'], ['All', 'data', 'were', 'collected', 'with', 'direct', 'visual', 'observation', 'of', 'single', 'leaves', '.'], ['(', 'global', 'unique', 'identifier', ':', 'global', 'unique', 'identifier', ')', 'Global', 'unique', 'identifier', 'for', 'the', 'respecive', 'species', 'provided', 'by', 'different', 'sources', 'for', 'taxonomic', 'affiliation', '.'], ['(', 'event_start', ':', 'start', 'date', 'of', 'the', 'event', ')', 'Date', 'time', 'information', ',', 'given', 'as', 'year', 'or', 'as', 'date', 'or', 'as', 'date', 'time', '.'], ['Here', 'we', 'present', 'and', 'test', 'a', 'new', 'conceptual', 'model', 'describing', 'the', 'mechanisms', 'and', 'consequences', 'of', 'biodiversity', 'change', 'in', 'fragmented', 'landscapes', ',', 'identifying', 'the', 'fragmentation', 'threshold', 'as', 'a', 'first', 'step', 'in', 'a', 'positive', 'feedback', 'mechanism', 'that', 'has', 'the', 'capacity', 'to', 'impair', 'ecological', 'resilience', ',', 'and', 'drive', 'a', 'regime', 'shift', 'in', 'biodiversity', '.'], ['This', 'is', 'the', 'first', 'study', 'of', 'aquarium', 'trade', 'imports', 'to', 'compare', 'commercial', 'invoices', 'to', 'government', 'forms', 'and', 'provides', 'a', 'means', 'to', ',', 'routinely', 'and', 'in', 'real', 'time', ',', 'examine', 'the', 'biodiversity', 'of', 'the', 'trade', 'in', 'coral', 'reef', 'wildlife', 'species', '.'], ['I', 'analyze', 'how', 'the', 'amount', 'of', 'available', 'data', 'has', 'changed', 'through', 'time', 'and', 'the', 'consequent', 'changes', 'in', 'taxonomic', ',', 'spatial', ',', 'habitat', ',', 'and', 'climatic', 'representativeness', '.'], ['Bootless', 'Bay', 'lies', 'directly', 'south', 'of', 'Port', 'Moresby', ',', 'the', 'capital', 'of', 'Papua', 'New', 'Guinea', ',', 'and', 'experiences', 'the', 'highest', 'human', 'population', 'density', 'of', 'any', 'marine', 'area', 'in', 'the', 'country', '.']]\n"
          ]
        }
      ],
      "source": [
        "print(test_texts_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5I0Wpcwu2GK",
        "outputId": "a2295084-1159-4ea9-b0a4-bde545576cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quality: Density; Phenomena: Treatment; Quality: Dead; Environment: Garden; Organism: Seedling; Phenomena: growth; Quality: biomass; Environment: plant communities; Quality: species richness; Environment: tropical forest ecosystems \n",
            "\n",
            "Organism: honey bees \n",
            "\n",
            "Environment: soil \n",
            "\n",
            "Environment: riparian reserves; Environment: forest; Environment: riparian reserves; Matter: oil palm \n",
            "\n",
            "Organism: species \n",
            "\n",
            "Phenomena: precipitation; Quality: rainfall amount; Environment: field; Phenomena: rainfall; Quality: rainfall amount; Environment: field; Quality: average rainfall intensity; Environment: field; Quality: peak rainfall intensity; Environment: field; Quality: intensities; Environment: field; Quality: rainfall amount; Quality: average rainfall intensity; Quality: peak rainfall intensity; Quality: intensities; Environment: field; Quality: intensities; Phenomena: Precipitation; Phenomena: Precipitation \n",
            "\n",
            "Environment: forest; Environment: tropical forest landscape; Quality: area; Environment: canopy cover; Quality: species richness; Environment: canopy \n",
            "\n",
            "Environment: Soil; Quality: pH analyses; Quality: depth \n",
            "\n",
            "Organism: species \n",
            "\n",
            "Quality: volume; Quality: diameter \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for row in train_outputs[:10]:\n",
        "  print(row, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3vdOw46wUO8",
        "outputId": "296ed634-d010-4606-b826-166adeed6318"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('-- - 6 digit metal tags starting with 3 were also used for woody debris items -- the reference file linking metal tags to tree individual tags is called `` Tree stem reference list for the Comparative Study Sites ( CSPs ) ) ( neigh.label : label ID of neighbouring individual : We locate every tagged individual CWD piece .',\n",
              " 'Matter: woody debris items')"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_inputs[11], train_outputs[11]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZtoHc0t7Rrh"
      },
      "source": [
        "# Training preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH6z2GHdtz09"
      },
      "source": [
        "We first load a ViT5 tokenizer and a pretrained model powered by Transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "c_s3KK_b-7gT"
      },
      "outputs": [],
      "source": [
        "#Create a tokenizer and a model supported by ViT5\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "# model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNJ20Y6Wt9yd"
      },
      "source": [
        "Define a function which converts data to tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "gt4CQd1o6kyX"
      },
      "outputs": [],
      "source": [
        "#Function for tokenizing texts and labels\n",
        "def preprocess(examples):\n",
        "  model_inputs = tokenizer(\n",
        "      examples[\"inputs\"], max_length=512, truncation=True, padding=True\n",
        "  )\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(\n",
        "        examples[\"labels\"], max_length=512, truncation=True, padding=True\n",
        "    )\n",
        "  model_inputs[\"labels\"] = labels['input_ids']\n",
        "  model_inputs['input_ids'] = model_inputs['input_ids']\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZdVtLNIuDZV"
      },
      "source": [
        "Define a dictionary that holds inputs and their corresponding labels\n",
        "\n",
        "Create a dataset from that dictionary and apply the tokenization process to every data sample with map function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "dRcl5K44W1m6"
      },
      "outputs": [],
      "source": [
        "#Tokenise dataset\n",
        "def dict_to_dataset(inputs, outputs):\n",
        "  dict_obj = {'inputs':inputs, 'labels':outputs}\n",
        "  dataset = Dataset.from_dict(dict_obj)\n",
        "  tokenized_datasets = dataset.map(preprocess, batched=True, num_proc=8)\n",
        "\n",
        "  return tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985,
          "referenced_widgets": [
            "6dd1f2605cfd4d40ba894e5c9f29255a",
            "a87b4753034440fab12c9aef88e4a65e",
            "53762e63ddb14378ab6347cfbbcdf2eb",
            "07f63ba8e0204cd987a30927c3c7bf54",
            "923d4b4e8e0a450388c53bfa3691592c",
            "34779fe2fcac4f3c9f925f12d83ab174",
            "dbc6ea78d1704f58ae4d8248847fbb89",
            "1807a557d3db431d90926ea61a1853a3",
            "8ba39d09760e4f8e91ea8640d8e9233c",
            "ae20d94212114a5b921a15a26c377402",
            "b7e4bae75624447aa8021cb0b89aeb49",
            "5ef1c56bb5904ed4b39c8c94e5960fb4",
            "c304e72bda2d4397b99b072027a8d960",
            "fc92bc9cd85a4c2484802990f86f437d",
            "3679027768db49dc961580d1efb904c3",
            "d7a2d62fa4b1414e9edaeeb8a4519476",
            "1cb29d4334a342d2a868c2fd8bd9a185",
            "ae23cf8b433240adae92dbcfc8a3c475",
            "f2a922c40f25457290be9ffe17ec401c",
            "7aac12116a4b496b9ce6dd24bde26378",
            "29fb2306d6404d4e8a517e69b3310da4",
            "517ecfa0f50e45f4be35081c052d6c1c",
            "55c345ce06a148dfbeb44ea35f0ce8bd",
            "7479ac28ec80431ab399cbfe7b7bb7c0",
            "7928e1b2353745138f0a78a9c0b9947e",
            "9b02de5b63f54267be94812b5f301194",
            "5a4edf2b61f742c3b12bbbe314002c44",
            "f847c9b7ed2a49a198e79f8ee0cc2235",
            "ab89ace79da646a2b0f2e624f9d2853a",
            "039fc2da5d194b17b14c448ec256d733",
            "e3d572e368014fc08bd332d72f0ddade",
            "45b35b4492d44a59a6ed50033df03029",
            "724a2e6ae2bb47958b3fc70aca0b62b7"
          ]
        },
        "id": "wFZajnqMxSvi",
        "outputId": "ee29a069-601e-46f7-9594-c18573c1968b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "149f39c6168d48a99989d55ba3182bfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/1776 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\utils\\py_utils.py\", line 1377, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"c:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py\", line 3466, in _map_single\n    batch = apply_function_on_filtered_inputs(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py\", line 3345, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shann\\AppData\\Local\\Temp\\ipykernel_3704\\3623910228.py\", line 3, in preprocess\nNameError: name 'tokenizer' is not defined\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[187], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m val_tokenized \u001b[38;5;241m=\u001b[39m dict_to_dataset(val_inputs, val_outputs)\n\u001b[0;32m      3\u001b[0m test_tokenized \u001b[38;5;241m=\u001b[39m dict_to_dataset(test_inputs, test_outputs)\n",
            "Cell \u001b[1;32mIn[186], line 5\u001b[0m, in \u001b[0;36mdict_to_dataset\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m      3\u001b[0m dict_obj \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m:inputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m:outputs}\n\u001b[0;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(dict_obj)\n\u001b[1;32m----> 5\u001b[0m tokenized_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_datasets\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3181\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3174\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   3176\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3177\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3178\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3179\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3180\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[0;32m   3182\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[0;32m   3183\u001b[0m     ):\n\u001b[0;32m   3184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3185\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\utils\\py_utils.py:1417\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[1;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[0;32m   1416\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m-> 1417\u001b[0m         \u001b[43m[\u001b[49m\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masync_result\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masync_results\u001b[49m\u001b[43m]\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\utils\\py_utils.py:1417\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[0;32m   1416\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m-> 1417\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\multiprocess\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "train_tokenized = dict_to_dataset(train_inputs, train_outputs)\n",
        "val_tokenized = dict_to_dataset(val_inputs, val_outputs)\n",
        "test_tokenized = dict_to_dataset(test_inputs, test_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B0fxK-AbcVOi"
      },
      "outputs": [],
      "source": [
        "logging_dir=\"./log\"\n",
        "logging_dir_name=\"training_logs\"\n",
        "logging_dir_path = os.path.join(logging_dir, logging_dir_name)\n",
        "os.makedirs(logging_dir_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LlQQmunecb14"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yMURgah0d5GT"
      },
      "outputs": [],
      "source": [
        "from seqeval import metrics as seqeval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lv-sEFRvdm4N"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "  predictions, labels = p.predictions, p.label_ids\n",
        "  flat_predictions = [label for sentence_labels in predictions for label in sentence_labels]\n",
        "  flat_labels = [label for sentence_labels in labels for label in sentence_labels]\n",
        "  accuracy = seqeval_metrics.accuracy_score([flat_labels], [flat_predictions])\n",
        "  return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks2ubpzuuVm9"
      },
      "source": [
        "Set training arguments for training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "96TTbpQKW1pY"
      },
      "outputs": [],
      "source": [
        "#Arguments for training model\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
        "training_args = Seq2SeqTrainingArguments('/content/gdrive/Shareddrives/CS 198 NLP for Biodiversity (Plants)/Model Data',\n",
        "                                      report_to = 'wandb',\n",
        "                                      do_train=True,\n",
        "                                      do_eval=True,\n",
        "                                      num_train_epochs=5,\n",
        "                                      learning_rate=2e-5,\n",
        "                                      warmup_ratio=0.00,\n",
        "                                      weight_decay=0.01,\n",
        "                                      per_device_train_batch_size=4,\n",
        "                                      per_device_eval_batch_size=4,\n",
        "\n",
        "                                      logging_steps=50,\n",
        "                                      group_by_length=True,\n",
        "                                      # save_strategy=\"epoch\",\n",
        "                                      save_total_limit=0,\n",
        "                                      #eval_steps=1,\n",
        "                                      evaluation_strategy=\"epoch\",\n",
        "                                      # evaluation_strategy=\"no\",\n",
        "                                      # fp16=True,\n",
        "                                      # eval_accumulation_steps=50\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_VXedIdualN"
      },
      "source": [
        "Make sure to push the model to GPU for optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoaX4kSBJPoR",
        "outputId": "67f04d16-aaf7-45d0-c740-1fc56bba2f0f"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:2271\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   2267\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2268\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2269\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2270\u001b[0m         )\n\u001b[1;32m-> 2271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
            "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt7i-ijz7lcF"
      },
      "source": [
        "# Train Named Entity Recognition model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "WcPJJxYddB2r",
        "outputId": "de4fd213-5762-4f49-fa5f-038cf4b32c11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 14:41, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.065700</td>\n",
              "      <td>0.156220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>0.144565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.043100</td>\n",
              "      <td>0.135807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.049900</td>\n",
              "      <td>0.132062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.071300</td>\n",
              "      <td>0.130788</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory /content/gdrive/Shareddrives/CS 198 NLP for Biodiversity (Plants)/Model Data/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/gdrive/Shareddrives/CS 198 NLP for Biodiversity (Plants)/Model Data/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2400, training_loss=0.05676367496450742, metrics={'train_runtime': 873.5687, 'train_samples_per_second': 10.978, 'train_steps_per_second': 2.747, 'total_flos': 1297927876116480.0, 'train_loss': 0.05676367496450742, 'epoch': 5.0})"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # #Procession of training model\n",
        "# trainer = Seq2SeqTrainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_tokenized,\n",
        "#     eval_dataset=val_tokenized,\n",
        "#     data_collator=data_collator,\n",
        "# )\n",
        "\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "JH1E6_y4Msky",
        "outputId": "56580830-adb7-423c-d160-6926a6d764cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='43' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 43/480 00:04 < 00:51, 8.44 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-61230b133573>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     def predict(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3008\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3184\u001b[0m         \u001b[0mobserved_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3186\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3187\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;31m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mskip_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         return type(tensor)(\n\u001b[0;32m--> 161\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m         return type(tensor)(\n\u001b[1;32m    161\u001b[0m             {\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             }\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.evaluate(eval_dataset=train_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5voTJS1tuWGC"
      },
      "outputs": [],
      "source": [
        "# Assuming that 'model' is your Seq2Seq model\n",
        "# model.save_pretrained()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlAOTOIYwetK"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8i2dS_OulI1"
      },
      "source": [
        "Load fine-tuned model stored in Google Drive with a Tokenizer by ViT5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "JB0w5o8kUgdv"
      },
      "outputs": [],
      "source": [
        "#Load model saved as a checkpoint\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"../Models/t5-small_001/\")\n",
        "# model = trainer.model\n",
        "# model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWniPKChpR1a",
        "outputId": "d306f8bb-8668-4ee2-b733-52891cf1d2e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60506624"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Total number of trainable parameters\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqOO3wPdbW_4",
        "outputId": "e5347674-7a8e-48dd-c03e-06057480e341"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxLi-lwz91HZ"
      },
      "source": [
        "To use the model at its best, make sure the data fed to the model is word-level,\n",
        " if it's not, simply use an RDR-Segmenter!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-uR8DpBusQV"
      },
      "source": [
        "The cell below helps produce target text with 'generate' method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvC-izf5Uhmp",
        "outputId": "044d0d13-3b16-45b4-b703-7381806c3427"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1636,    37, 21965,  7322,    19,   787,    57,   309,  1713,  3316,\n",
              "           448,  2990,    55,  4505,     3,   102,   834,    23,     2,   357,\n",
              "             3,     6,    28,     3,   102,   834,    23,  9085,     8,  5237,\n",
              "         15025,    13,     8,    34,   107,  3244,     3,     5,     1]])"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = train_inputs[100]\n",
        "# sentence = eval_input_sequences[23]\n",
        "encoding = tokenizer(sentence, return_tensors=\"pt\", max_length=512)\n",
        "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "VwmwTJuaTNI-"
      },
      "outputs": [],
      "source": [
        "outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_sLITdWTtPN",
        "outputId": "f7130fb0-7818-4198-b715-f13223b7da47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,  6495,    10, 21965,  7322,   117,  6495,    10, 15025,     1]])\n"
          ]
        }
      ],
      "source": [
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zITKrz-VTftL",
        "outputId": "3836e2c6-3ea3-4787-e86c-3461c4b1cd6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results:  Quality: Simpson diversity; Quality: abundance\n",
            "Actual labels: Organism: plant; Quality: herbivore diversity; Phenomena: biodiversity loss; Quality: trophic levels\n"
          ]
        }
      ],
      "source": [
        "labels = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "print(\"Results: \", labels)\n",
        "print(\"Actual labels:\", train_outputs[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "ZjrVUiUyWUfz"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWu-IC7cvBQ2"
      },
      "source": [
        "'word_labels' takes into account two parameters 'sentence' and 'labels' to calculate the correct BIO label and map them to a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "AeSzeA5XWW-P"
      },
      "outputs": [],
      "source": [
        "def word_labels(sentence, labels):\n",
        "  predictions = [\"O\" for i in range(len(sentence.split()))]\n",
        "  if labels != '':\n",
        "    list_labels = labels.split(\";\")\n",
        "    sent = sentence.split()\n",
        "\n",
        "    start = 0\n",
        "    for i in range(len(list_labels)):\n",
        "      sub_list = list_labels[i].split(\":\")\n",
        "      # print(list_labels[i])\n",
        "      # print(sub_list)\n",
        "      class_entity = sub_list[0].strip() # location, organization, age,...\n",
        "      named_entity = sub_list[1].strip().lower() # Ha Noi, London, 433,...\n",
        "      named_entity_element = named_entity.split() # Ha, Noi, London, 433, Soc Trang,...\n",
        "\n",
        "      flist = []\n",
        "      for i in range(len(named_entity_element)):\n",
        "        if named_entity_element[i][-1] == ',':\n",
        "          entity1 = named_entity_element[i][0:len(named_entity_element[i])-1]\n",
        "          entity2 = \",\"\n",
        "          flist.append(entity1)\n",
        "          flist.append(entity2)\n",
        "        else:\n",
        "          flist.append(named_entity_element[i])\n",
        "\n",
        "      named_entity_element = flist\n",
        "      for i in range(len(named_entity_element)):\n",
        "        try:\n",
        "          findex = sent.index(named_entity_element[i], start)\n",
        "          start = findex + 1\n",
        "          f_class = \"\"\n",
        "          if i == 0:\n",
        "            f_class = \"B-\" + class_entity\n",
        "          else:\n",
        "            f_class = \"I-\" + class_entity\n",
        "          predictions[findex] = f_class\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do934z0gQ_C1"
      },
      "source": [
        "# reverse the subword tokens to their real words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG1eia3Me5aR"
      },
      "source": [
        "Load dataset for devaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "pUYALXFR8UKO"
      },
      "outputs": [],
      "source": [
        "# #Read test set\n",
        "# evalWord = [json.loads(line) for line in open('gdrive/MyDrive/Ct550/word/test_word.json', 'r', encoding='utf-8')]\n",
        "# evalWordData = pd.DataFrame(evalWord)\n",
        "# evalWordData = evalWordData.rename(columns={'tags':'target_text', 'words':'source_text'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf545NJ0vXGe"
      },
      "source": [
        "Create lists of input and output sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "3n06Gjyy8tgn"
      },
      "outputs": [],
      "source": [
        "# #Create a list of texts\n",
        "eval_input_data = test_texts_c\n",
        "test_inputs = []\n",
        "\n",
        "for sentence in eval_input_data:\n",
        "  test_inputs.append(\" \".join(sentence))\n",
        "\n",
        "# #Create a list of targets\n",
        "eval_output_data = test_tags_c\n",
        "test_outputs = []\n",
        "\n",
        "for sentence in eval_output_data:\n",
        "  test_outputs.append(\" \".join(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YfJtTui_6p8l",
        "outputId": "cbf46236-7077-4df8-96f3-eed0af0ade2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Or the allometries are not used to extrapolate the biomass of the first item ( for example a tree dbh ) . )'"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# eval_input_sequences\n",
        "test_inputs[8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMlAeuKta0ZH",
        "outputId": "d6837864-76b5-4591-c392-06570a44b3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3tHRvDPvcQl"
      },
      "source": [
        "The process below predicts targets for 2k data samples in the dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "YC8AH5ItnuWw"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "references = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppvx9TdCpFA8",
        "outputId": "b8b07e94-a7fd-4e17-f3fe-d4cfed81fd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chlamydia caviae infection alters abundance but not composition of the guinea pig vaginal microbiota In humans , the vaginal microbiota is thought to be the first line of defense again pathogens including Chlamydia trachomatis .\n"
          ]
        }
      ],
      "source": [
        "print(test_inputs[47])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgN_jAB8pLtK",
        "outputId": "607cc4b4-e13e-49df-fd6a-6a3da178bcf4"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[216], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m)\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "print(predictions[8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZFWc1l-CIEJ",
        "outputId": "770923ac-589e-4ed0-900f-a10cef0bebcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "Error in iteration 7: list index out of range\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "Error in iteration 33: list index out of range\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "Error in iteration 39: list index out of range\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "Error in iteration 104: list index out of range\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "Error in iteration 117: list index out of range\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "Error in iteration 123: list index out of range\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "Error in iteration 141: list index out of range\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "Error in iteration 150: list index out of range\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "Error in iteration 177: list index out of range\n",
            "178\n",
            "179\n",
            "Error in iteration 179: list index out of range\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "Error in iteration 203: list index out of range\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n"
          ]
        }
      ],
      "source": [
        "# for i in test_inputs:\n",
        "for i in range(len(test_inputs)):\n",
        "  print (i)\n",
        "  sentence = test_inputs[i]\n",
        "  tokenized_input = tokenizer(sentence, return_tensors='pt', max_length=512)\n",
        "  input_ids = tokenized_input['input_ids'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  attention_mask = tokenized_input['attention_mask'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  try:\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids, attention_mask=attention_mask, max_length=512\n",
        "        )\n",
        "        # print(outputs[0])\n",
        "        labels = tokenizer.decode(outputs[0], clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
        "        # print(\"prev sentence:\", sentence)\n",
        "        # print(\"prev_label:\", labels)\n",
        "        sentence = unidecode(sentence).lower()\n",
        "        labels = unidecode(labels)\n",
        "        # print(\"decoded_sentence:\", sentence)\n",
        "        # print(\"decoded_label:\", labels)\n",
        "        flabels = word_labels(sentence, labels)\n",
        "        if len(flabels) != len(test_outputs[i].split()):\n",
        "          print(f\"Unequal prediction and reference!\")\n",
        "          continue\n",
        "        predictions.append(flabels)\n",
        "        references.append(test_outputs[i].split())\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Error in iteration {i}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of individuals Organism count ( Hemiptera_sum ) , Hemiptera_sum Counting the individuals of a given taxon , also called abundance .\n",
            "Number of individuals Organism count ( Tetramorium.wroughtonii ) , Tetramorium.wroughtonii Counting the individuals of a given taxon , also called abundance .\n",
            "-- d ) Compare species-specific sensitivities to snow break as a trait i ) Calculate the likelihood of being subject to snowbreak given the species , size and potentially the relative position using logistic regression ii ) Calculate the likelihood of snag survival ; this requires re-sampling iii ) Estimate the down-slope transport of deadwood pieces iv ) Estimate the time it takes for deadwood to collapse and touch the forest floor -- -- - File asset Plot_skizze.pdf : plot sketch how the debris objects are selected - File asset sp10 CWD_protocol_Gutianshan_AF_20081215_kn.doc : Inventory protocol , should be included into methods -- -- - 2 ) Objective allometries : use some of the downed or alive trees to establish coarse allometries to estimate volume of the remaining intems allometries basal diameter coarse woody debris co-variable CSP date dbh dead wood decomposition fungi ice storm location mortality object red mould response variable size snag height soil species stem termites weather woody debris Find the list of keywords here : rownr date Date start end plotignore CSP working condition protoc.first protoc.sur meas.first meas.sur entered.first entered.sur entered.date page Central_subplot CWD-Id CWD_CSP_original Idaddon CWD_CSP Species specunpolished TagAFCW TagMBa TagAFCW original TagMBa original DBH dbh.comment dbhpostmean dbhpostsd stemsGrEq10 stemsCnSm10 height BD lookup tag dbase.remark.kn dtop dtop.remark.kn length len.rem.kn height_length hei.len.rem.kn broken at broken diam neigh.label reference is self neigh.dist neigh.azimut direction CWD pos.cw pos.af_original plot estimate pos.af alive sc mc dc ter rot fungi valid crown_origin remark vol_factor Allometrie comment Karin meandbh meanGr10 meanSm10Cn ice_storm_representative List of headers of the data columns in this dataset Permission is granted to anybody to access , use and publish all open for public data freely .\n"
          ]
        }
      ],
      "source": [
        "# List index out of range error\n",
        "print(test_inputs[8])\n",
        "print(test_inputs[36])\n",
        "print(test_inputs[43])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O O O B-Quality I-Quality O O O O O O O O O O O B-Organism O O O B-Quality O\n",
            "O O O B-Quality I-Quality O O O O O O O O O O O B-Organism O O O B-Quality O\n",
            "O O O O O O O B-Phenomena I-Phenomena O O B-Quality O O O O O O O O O O O O B-Organism O B-Quality O O O B-Quality I-Quality O O O O O O O O O B-Phenomena I-Phenomena O O O O O O O O O O O B-Matter O O O O O O O O O B-Matter O O O O O B-Environment I-Environment O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-Organism I-Organism O O O O O O B-Quality O O O O O B-Quality I-Quality B-Matter I-Matter I-Matter O O O O B-Phenomena I-Phenomena I-Phenomena B-Organism B-Phenomena I-Phenomena B-Quality B-Quality O O O O O B-Quality O B-Quality B-Environment B-Organism O O B-Phenomena B-Matter I-Matter O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-Organism O O O O O O O O O O O O O B-Quality O O O O O O B-Quality O O O O O O O O O O O O O O O O O O O O B-Quality O O O O O B-Organism O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n"
          ]
        }
      ],
      "source": [
        "print(test_outputs[8])\n",
        "print(test_outputs[36])\n",
        "print(test_outputs[43])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List index out of range error\n",
        "for row in predictions:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Phenomena', 'I-Phenomena', 'O', 'O', 'B-Environment', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'O', 'O', 'B-Organism', 'B-Quality', 'I-Quality', 'O']\n",
            "['B-Quality', 'I-Quality', 'I-Quality', 'I-Quality', 'O']\n"
          ]
        }
      ],
      "source": [
        "for row in references:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acronym : SLA Specific leaf area ; Datagroup description : Specific leaf area ; Datagroup description : Specific leaf area Leaf dry matter content ( LDMC ) , mg/g LDMC Leaf dry matter content , LDMC ( LDMC : Leaf dry matter content ) dimensionless real Leaf dry matter content Leaf dry matter content , LDMC Leaf dry matter content Nitrogen ( N ) , mg/g N Nitrogen concentration ( N : Nitrogen content ; Datagroup description : Nitrogen ; Datagroup description : Nitrogen ) dimensionless real Nitrogen Nitrogen concentration Nitrogen content ; Datagroup description : Nitrogen ; Datagroup description : Nitrogen Elemental Analyzer Carbon ( C ) , mg/g C measurements of Carbon such as concentrations , pools , amount ( C : Carbon content ; Instrumentation : Elemental Analyzer ) dimensionless real Carbon measurements of Carbon such as concentrations , pools , amount Carbon content ; Instrumentation : Elemental Analyzer Carbon Nitrogen ratio ( CN ) , g/g CN Carbon Nitrogen ratio ( CN : Carbon to Nitrogen Ratio ; Instrumentation : Elemental Analyzer ) dimensionless real Carbon Nitrogen ratio Carbon Nitrogen ratio Carbon to Nitrogen Ratio ; Instrumentation : Elemental Analyzer Chemical elements ( K ) , ÃŽÂ¼g/g K Elements apart from Nitrogen , Carbon ( K : Kalium content ; Datagroup description : atom absorption spectrometer ; Datagroup description : Chemical elements ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Kalium content ; Datagroup description : atom absorption spectrometer ; Datagroup description : Chemical elements atom absorption spectrometer Chemical elements ( Mg ) , ÃŽÂ¼g/g Mg Elements apart from Nitrogen , Carbon ( Mg : Magnesium content ; Datagroup description : atom absorption spectrometer ; Datagroup description : Chemical elements ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Magnesium content ; Datagroup description : atom absorption spectrometer ; Datagroup description : Chemical elements atom absorption spectrometer Chemical elements ( Ca ) , ÃŽÂ¼g/g Ca Elements apart from Nitrogen , Carbon ( Ca : Calcium content ; Datagroup description : atom absorption spectrometer ; Datagroup description : Chemical elements ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Calcium content ; Datagroup description : atom absorption spectrometer ; Datagroup description : Chemical elements atom absorption spectrometer Chemical elements ( Al ) , ÃŽÂ¼g/g Al Elements apart from Nitrogen , Carbon ( Al : Aluminum content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Aluminum content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Ca2 ) , ÃŽÂ¼g/g Ca2 Elements apart from Nitrogen , Carbon ( Ca2 : Calcium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Calcium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Fe ) , ÃŽÂ¼g/g Fe Elements apart from Nitrogen , Carbon ( Fe : Ferric content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Ferric content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( K2 ) , ÃŽÂ¼g/g K2 Elements apart from Nitrogen , Carbon ( K2 : Potassium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Potassium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Mg2 ) , ÃŽÂ¼g/g Mg2 Elements apart from Nitrogen , Carbon ( Mg2 : Magnesium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Magnesium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Mn ) , ÃŽÂ¼g/g Mn Elements apart from Nitrogen , Carbon ( Mn : Manganese content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Manganese content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Na ) , ÃŽÂ¼g/g Na Elements apart from Nitrogen , Carbon ( Na : Natrium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Natrium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( P ) , ÃŽÂ¼g/g P Elements apart from Nitrogen , Carbon ( P : Phosphorus content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Phosphorus content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( S ) , ÃŽÂ¼g/g S Elements apart from Nitrogen , Carbon ( S : Sulfur content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Sulfur content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Zn ) , ÃŽÂ¼g/g Zn Elements apart from Nitrogen , Carbon ( Zn : Zinc content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Zinc content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Co ) , ÃŽÂ¼g/g Co Elements apart from Nitrogen , Carbon ( Co : Cobalt content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Cobalt content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Cu ) , ÃŽÂ¼g/g Cu Elements apart from Nitrogen , Carbon ( Cu : Copper content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Copper content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Pb ) , ÃŽÂ¼g/g Pb Elements apart from Nitrogen , Carbon ( Pb : Lead content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Lead content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Sr ) , ÃŽÂ¼g/g Sr Elements apart from Nitrogen , Carbon ( Sr : Strontium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Strontium content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Cr ) , ÃŽÂ¼g/g Cr Elements apart from Nitrogen , Carbon ( Cr : Chrome content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Chrome content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Ni ) , ÃŽÂ¼g/g Ni Elements apart from Nitrogen , Carbon ( Ni : Nickel content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Nickel content ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Cd214 ) , ÃŽÂ¼g/g Cd214 Elements apart from Nitrogen , Carbon ( Cd214 : Cadmium content ( at 214nm ) ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Cadmium content ( at 214nm ) ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Chemical elements ( Cd228 ) , ÃŽÂ¼g/g Cd228 Elements apart from Nitrogen , Carbon ( Cd228 : Cadmium content ( at 228nm ) ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer ) dimensionless real Chemical elements Elements apart from Nitrogen , Carbon Cadmium content ( at 228nm ) ; Datagroup description : inductively coupled plasma optical emisssion spectrometer ; Datagroup description : Chemical elements ; Instrumentation : inductively coupled plasma optical emisssion spectrometer atom absorption spectrometer Leaf stomata density ( stomata.density ) , 1/ÃŽÂ¼m stomata.density Leaf stomata density ( stomata.density : average Stomatal density ) dimensionless real Leaf stomata density Leaf stomata density average Stomatal density Microscope Leaf stomata size ( average.length ) , ÃŽÂ¼m average.length Leaf stomata size ( average.length : average Stomatal length ) dimensionless real Leaf stomata size Leaf stomata size average Stomatal length Microscope Leaf stomata size ( average.width ) , ÃŽÂ¼m average.width Leaf stomata size ( average.width : average Stomatal width ) dimensionless real Leaf stomata size Leaf stomata size average Stomatal width Microscope Secondary Metabolites ( Phenolics ) , mg/g Phenolics Secondary metabolites are organic compounds that are not directly involved in the normal growth , development , or reproduction of an organism .\n",
            "1 21332 LÃƒÂ¼neburg Germany 49 ( 0 ) 4131-677-2960 Andreas Schuldt German Centre for Integrative Biodiversity Research ( iDiv ) , Leipzig Deutscher Platz 5e Leipzig Germany 49 ( 0 ) 341 9733232 Michael Staab University of Freiburg , Chair of Nature Conservation and Landscape Ecology Tennenbacher Str .\n",
            "( clay : total clay : < 2ÃŽÂ¼m ) dimensionless real Grain size distribution Wikipedia on soil classification : Engineers , typically geotechnical engineers , classify soils according to their engineering properties as they relate to use for foundation support or building material .\n",
            "very fine sand : 125-63ÃŽÂ¼m sieves and KÃƒÂ¶hn pipette , drying oven , balance Grain size distribution ( csi ) , ... csi Wikipedia on soil classification : Engineers , typically geotechnical engineers , classify soils according to their engineering properties as they relate to use for foundation support or building material .\n"
          ]
        }
      ],
      "source": [
        "# Unequal prediction and reference error\n",
        "print(test_inputs[23])\n",
        "print(test_inputs[47])\n",
        "print(test_inputs[81])\n",
        "print(test_inputs[83])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PwKvxL-mOZj",
        "outputId": "8b568b54-b7b6-4fe9-b2c1-683702a4aecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Phenomena', 'I-Phenomena', 'O', 'O', 'B-Environment', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'O', 'O', 'B-Organism', 'B-Quality', 'I-Quality', 'O']\n",
            "['B-Quality', 'I-Quality', 'I-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'I-Organism', 'O', 'O', 'B-Organism', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Environment', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'B-Location', 'I-Location', 'I-Location', 'B-Location', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Location', 'I-Location', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Environment', 'I-Environment', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Environment', 'O']\n"
          ]
        }
      ],
      "source": [
        "for row in references[:10]:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjbp1ETk5OF",
        "outputId": "87c85879-f062-4d1c-b33c-e4eeac839328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'O', 'O', 'B-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'B-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'I-Organism', 'O', 'O', 'B-Organism', 'I-Organism', 'B-Organism', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'B-Environment', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'O', 'O', 'O', 'O', 'O', 'B-Organism', 'I-Organism', 'O', 'B-Organism', 'I-Organism', 'O', 'B-Organism', 'I-Organism', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'O', 'O', 'B-Quality', 'I-Quality', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Quality', 'I-Quality', 'I-Quality', 'O']\n"
          ]
        }
      ],
      "source": [
        "for row in predictions[:10]:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvBpg0vNapMe"
      },
      "source": [
        "# resultssss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr0HZVnvmX-"
      },
      "source": [
        "Use seqeval framework introduced to calculate scores F1/precision/recall for every class entity and overall score for model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJFXFngWatOH",
        "outputId": "2191362b-d6f1-4485-db09-bbca65149062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.2157\n",
            "Recall: 0.1990\n",
            "F1-Score: 0.2070\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "<pad> Environment       0.00      0.00      0.00         0\n",
            "   <pad> Organism       0.00      0.00      0.00         0\n",
            "    <pad> Quality       0.00      0.00      0.00         0\n",
            "      Environment       0.16      0.04      0.07       268\n",
            "         Location       0.00      0.00      0.00        56\n",
            "           Matter       0.00      0.00      0.00       102\n",
            "         Organism       0.36      0.26      0.30       442\n",
            "        Phenomena       0.00      0.00      0.00       109\n",
            "          Quality       0.22      0.35      0.27       455\n",
            "\n",
            "        micro avg       0.22      0.20      0.21      1432\n",
            "        macro avg       0.08      0.07      0.07      1432\n",
            "     weighted avg       0.21      0.20      0.19      1432\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\shann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "precision = precision_score(references, predictions)\n",
        "recall = recall_score(references, predictions)\n",
        "f1 = f1_score(references, predictions)\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "\n",
        "# You can also print a detailed classification report\n",
        "print(classification_report(references, predictions))\n",
        "\n",
        "# result = seqeval.compute(predictions=predictions, references=references)\n",
        "# resultb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8fmt4UDrG60",
        "outputId": "5065bf98-72ad-49a4-fd1a-e4582ecb31d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209\n"
          ]
        }
      ],
      "source": [
        "print(len(references))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "039fc2da5d194b17b14c448ec256d733": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f63ba8e0204cd987a30927c3c7bf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae20d94212114a5b921a15a26c377402",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e4bae75624447aa8021cb0b89aeb49",
            "value": " 1918/1918 [00:03&lt;00:00, 665.54 examples/s]"
          }
        },
        "1807a557d3db431d90926ea61a1853a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb29d4334a342d2a868c2fd8bd9a185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29fb2306d6404d4e8a517e69b3310da4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34779fe2fcac4f3c9f925f12d83ab174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3679027768db49dc961580d1efb904c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29fb2306d6404d4e8a517e69b3310da4",
            "placeholder": "​",
            "style": "IPY_MODEL_517ecfa0f50e45f4be35081c052d6c1c",
            "value": " 240/240 [00:00&lt;00:00, 429.03 examples/s]"
          }
        },
        "45b35b4492d44a59a6ed50033df03029": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517ecfa0f50e45f4be35081c052d6c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53762e63ddb14378ab6347cfbbcdf2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1807a557d3db431d90926ea61a1853a3",
            "max": 1918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ba39d09760e4f8e91ea8640d8e9233c",
            "value": 1918
          }
        },
        "55c345ce06a148dfbeb44ea35f0ce8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7479ac28ec80431ab399cbfe7b7bb7c0",
              "IPY_MODEL_7928e1b2353745138f0a78a9c0b9947e",
              "IPY_MODEL_9b02de5b63f54267be94812b5f301194"
            ],
            "layout": "IPY_MODEL_5a4edf2b61f742c3b12bbbe314002c44"
          }
        },
        "5a4edf2b61f742c3b12bbbe314002c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef1c56bb5904ed4b39c8c94e5960fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c304e72bda2d4397b99b072027a8d960",
              "IPY_MODEL_fc92bc9cd85a4c2484802990f86f437d",
              "IPY_MODEL_3679027768db49dc961580d1efb904c3"
            ],
            "layout": "IPY_MODEL_d7a2d62fa4b1414e9edaeeb8a4519476"
          }
        },
        "6dd1f2605cfd4d40ba894e5c9f29255a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a87b4753034440fab12c9aef88e4a65e",
              "IPY_MODEL_53762e63ddb14378ab6347cfbbcdf2eb",
              "IPY_MODEL_07f63ba8e0204cd987a30927c3c7bf54"
            ],
            "layout": "IPY_MODEL_923d4b4e8e0a450388c53bfa3691592c"
          }
        },
        "724a2e6ae2bb47958b3fc70aca0b62b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7479ac28ec80431ab399cbfe7b7bb7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f847c9b7ed2a49a198e79f8ee0cc2235",
            "placeholder": "​",
            "style": "IPY_MODEL_ab89ace79da646a2b0f2e624f9d2853a",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "7928e1b2353745138f0a78a9c0b9947e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039fc2da5d194b17b14c448ec256d733",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d572e368014fc08bd332d72f0ddade",
            "value": 240
          }
        },
        "7aac12116a4b496b9ce6dd24bde26378": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ba39d09760e4f8e91ea8640d8e9233c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "923d4b4e8e0a450388c53bfa3691592c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b02de5b63f54267be94812b5f301194": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b35b4492d44a59a6ed50033df03029",
            "placeholder": "​",
            "style": "IPY_MODEL_724a2e6ae2bb47958b3fc70aca0b62b7",
            "value": " 240/240 [00:00&lt;00:00, 289.67 examples/s]"
          }
        },
        "a87b4753034440fab12c9aef88e4a65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34779fe2fcac4f3c9f925f12d83ab174",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc6ea78d1704f58ae4d8248847fbb89",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "ab89ace79da646a2b0f2e624f9d2853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae20d94212114a5b921a15a26c377402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae23cf8b433240adae92dbcfc8a3c475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7e4bae75624447aa8021cb0b89aeb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c304e72bda2d4397b99b072027a8d960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb29d4334a342d2a868c2fd8bd9a185",
            "placeholder": "​",
            "style": "IPY_MODEL_ae23cf8b433240adae92dbcfc8a3c475",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "d7a2d62fa4b1414e9edaeeb8a4519476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc6ea78d1704f58ae4d8248847fbb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3d572e368014fc08bd332d72f0ddade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2a922c40f25457290be9ffe17ec401c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f847c9b7ed2a49a198e79f8ee0cc2235": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc92bc9cd85a4c2484802990f86f437d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a922c40f25457290be9ffe17ec401c",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aac12116a4b496b9ce6dd24bde26378",
            "value": 240
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
